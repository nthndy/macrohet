{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e295e0",
   "metadata": {},
   "source": [
    "# A notebook for creating sc graph animations with glimpses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from cellpose import models\n",
    "from octopuslite import utils, tile\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def view(img):\n",
    "    return napari.Viewer().add_image(img)\n",
    "from napari_animation import Animation\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import btrack\n",
    "import dask.array as da\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.io import imsave, imread\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_palette(\"rocket_r\")\n",
    "\n",
    "def msd_calc(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Displacement calculation for cell movement between frames\n",
    "    \"\"\"\n",
    "    return np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "\n",
    "def update_slider(event):\n",
    "    # only trigger if update comes from first axis (optional)\n",
    "        #ind_lambda = viewer.dims.indices[0]\n",
    "    time = viewer.dims.current_step[0]\n",
    "    viewer.text_overlay.text = f\"{time:1.1f} hours\"\n",
    "text_size = 18\n",
    "napari_scale = [1.4949402023919043e-07, 1.4949402023919043e-07]\n",
    "\n",
    "import glob\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751ef77",
   "metadata": {},
   "source": [
    "### Load all metadata\n",
    "\n",
    "Both the image metadata and the assay layout metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/mnt/DATA/sandbox/pierre_live_cell_data/outputs/Replication_IPSDM_GFP/Images/'\n",
    "image_metadata_fn = '/mnt/DATA/sandbox/pierre_live_cell_data/outputs/Replication_IPSDM_GFP/Index.idx.xml'\n",
    "metadata = utils.read_harmony_metadata(image_metadata_fn)\n",
    "assay_layout_metadata = '/mnt/DATA/sandbox/pierre_live_cell_data/outputs/Replication_IPSDM_GFP/Assaylayout/20210602_Live_cell_IPSDMGFP_ATB.xml'\n",
    "assay_layout = utils.read_harmony_metadata(assay_layout_metadata, assay_layout=True)\n",
    "assay_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae561d",
   "metadata": {},
   "source": [
    "# Iteratively load all tracks\n",
    "\n",
    "and append to a track_dict dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cccf905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks_dict = dict()\n",
    "### iterate over all experimental conditions\n",
    "for (row, column), info in tqdm(assay_layout.iterrows(), \n",
    "                                desc = 'Progress through positions',\n",
    "                                total = len(assay_layout)):\n",
    "    ### load tracks\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "            f\"/mnt/DATA/macrohet/segmentation/tracks_objs/({row},{column})_tracks_rescaled.h5\", \n",
    "            'r', \n",
    "            obj_type = 'obj_type_1', \n",
    "            ) as hdf: \n",
    "            tracks = hdf.tracks\n",
    "            objs = hdf.objects\n",
    "    ### append tracks to dictionary\n",
    "    tracks_dict[(row, column)] = tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c537213",
   "metadata": {},
   "source": [
    "# Compile all full length tracks into dataframe\n",
    "\n",
    "Add extra information such as the MSD of cells between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### list of track info dfs\n",
    "dfs = list()\n",
    "### empty dictionary for filtered tracks\n",
    "filtered_tracks = dict()\n",
    "### iterate over all tracks\n",
    "for key in tracks_dict.keys():\n",
    "    ### extract tracks only with max length\n",
    "    filtered_tracks[key] = [track for track in tracks_dict[key] if len(track) == 75]\n",
    "    ### iterate over full length tracks\n",
    "    for track in filtered_tracks[key]:\n",
    "        ### get info for assay layout\n",
    "        info = assay_layout.loc[key]\n",
    "        ### compile single track dictionary of info\n",
    "        d = {'Time (hours)':track['t'], \n",
    "             'x':track['x'],\n",
    "             'y':track['y'],\n",
    "             'Area':track['area'], \n",
    "             'Intracellular Mtb content':track['mean_intensity-1'],\n",
    "             'Mean Mtb content':[np.nanmean(track['mean_intensity-1']) for i in range(len(track['t']))],\n",
    "             'Macroph. GFP expression':track['mean_intensity-0'],\n",
    "             'Eccentricity':np.sqrt(1-((track['minor_axis_length']**2)/(track['major_axis_length']**2))),\n",
    "             'MSD': [msd_calc(track['x'][i-1], \n",
    "                              track['y'][i-1], \n",
    "                              track['x'][i], \n",
    "                              track['y'][i]) \n",
    "                              if i != 0 else 0\n",
    "                              for i in range(0, len(track))],\n",
    "             'Strain':[info['Strain'] for i in range(len(track['t']))], \n",
    "             'Compound':[info['Compound'] for i in range(len(track['t']))], \n",
    "             'Concentration':[info['ConcentrationEC'] for i in range(len(track['t']))], \n",
    "             'Cell ID':[track.ID for i in range(len(track['t']))],\n",
    "             'Acquisition ID':[key for i in range(len(track['t']))]}\n",
    "        ### append df to list of dfs\n",
    "        dfs.append(pd.DataFrame(d))\n",
    "### concat single track dfs into big df\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "### interpolate missing values as sometimes segmentation drops result in NaN\n",
    "df.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d22d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66b9923",
   "metadata": {},
   "source": [
    "### Add category to discern initial amount of Mtb growth\n",
    "\n",
    "Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10964f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_mtb = df.loc[df['Time (hours)'] == 0, 'Intracellular Mtb content']\n",
    "initial_mtb_quartiles = pd.cut(initial_mtb, bins = [initial_mtb.quantile(.0), \n",
    "                                                    initial_mtb.quantile(.25), \n",
    "                                                    initial_mtb.quantile(0.5), \n",
    "                                                    initial_mtb.quantile(.75),\n",
    "                                                    initial_mtb.quantile(1)], \n",
    "                                                    labels = ['Lower', 'Lower-mid', 'Upper-mid', 'Upper'])\n",
    "df['Initial Mtb load (quartile)'] = initial_mtb_quartiles\n",
    "df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mtb = df.loc[df['Time (hours)'] == 74, 'Intracellular Mtb content']\n",
    "final_mtb_quartiles = pd.cut(final_mtb, bins = [final_mtb.quantile(.0), \n",
    "                                                    final_mtb.quantile(.25), \n",
    "                                                    final_mtb.quantile(0.5), \n",
    "                                                    final_mtb.quantile(.75),\n",
    "                                                    final_mtb.quantile(1)], \n",
    "                                                    labels = ['Lower', 'Lower-mid', 'Upper-mid', 'Upper'])\n",
    "df['Final Mtb load (quartile)'] = final_mtb_quartiles\n",
    "df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc44ea3",
   "metadata": {},
   "source": [
    "Now continuous assessment: ie. the actual value of the Mtb content in the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_mtb = df.loc[df['Time (hours)'] == 0, 'Intracellular Mtb content']\n",
    "df['Initial Mtb load'] = initial_mtb\n",
    "df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5063eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mtb = df.loc[df['Time (hours)'] == 74, 'Intracellular Mtb content']\n",
    "df['Final Mtb load'] = final_mtb\n",
    "df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data = df[df['Compound'] == 'PZA'], \n",
    "            x = 'Time (hours)', \n",
    "            y = 'Intracellular Mtb content', \n",
    "            kind = 'line',\n",
    "            col = 'Concentration',\n",
    "            hue = 'Concentration', \n",
    "            aspect = 0.75,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fc1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_expt_df = df[(df['Compound'] == 'PZA') & (df['Concentration'] == 'EC50')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90defc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_cases = pd.concat([selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.max(selected_expt_df['Mean Mtb content']))],selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.min(selected_expt_df['Mean Mtb content']))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = extreme_cases, \n",
    "            x = 'Time (hours)', \n",
    "            y = 'Intracellular Mtb content', \n",
    "            hue = 'Cell ID', \n",
    "           )\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3104bb",
   "metadata": {},
   "source": [
    "## Pick a single experiment to focus on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996052ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b3cbd",
   "metadata": {},
   "source": [
    "#### pull corresponding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d69933",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, column = extreme_cases['Acquisition ID'].iloc[0]\n",
    "images = tile.compile_mosaic(\n",
    "                             image_dir, \n",
    "                             metadata, \n",
    "                             row, \n",
    "                             column, \n",
    "                             set_plane = 'sum_proj',\n",
    "                             ).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851197c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b79c4c",
   "metadata": {},
   "source": [
    "## Select one cell as a seperate df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc186dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_IDs = list(set(extreme_cases['Cell ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0693018",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_df = extreme_cases[extreme_cases['Cell ID']==cell_IDs[0]]\n",
    "ID = list(extreme_cases['Cell ID'])[0]\n",
    "acq_ID = list(extreme_cases['Acquisition ID'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51409e9",
   "metadata": {},
   "source": [
    "## Make series of glimpses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "### glimpse size\n",
    "size = 500\n",
    "### resized images\n",
    "scale = 6048/1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f005ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "glimpse_stack = list()\n",
    "for row in tqdm(sc_df.iterrows(), total = len(sc_df)):\n",
    "    time, x, y = row[1]['Time (hours)'], row[1]['y'], row[1]['x']\n",
    "    frame = images[time,...]\n",
    "    x1, y1 = x*scale, y*scale\n",
    "#     x1, x2, y1, y2 = x1*scale, x2*scale, y1*scale, y2*scale\n",
    "#     x1, x2, y1, y2 = x1, x2+size, y1, y2+size\n",
    "    x1, x2, y1, y2 = x1, x1+size, y1, y1+size\n",
    "    frame = da.pad(frame, [(0, 0), (size/2, size/2), (size/2, size/2)], 'constant', constant_values = 0) \n",
    "    glimpse = frame[..., int(x1): int(x2), int(y1): int(y2)]# frame[..., int(x1): int(x2), int(y1): int(y2)]\n",
    "\n",
    "    glimpse_stack.append(glimpse)\n",
    "glimpse_stack = np.stack(glimpse_stack, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dfd7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "glimpse_stack = glimpse_stack.compute().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "glimpse_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69468750",
   "metadata": {},
   "source": [
    "### Check glimpse with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], scale = scale\n",
    "                )\n",
    "viewer.theme = 'light'\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'm'\n",
    "viewer.scale_bar.font_size = text_size\n",
    "viewer.text_overlay.visible = True\n",
    "viewer.text_overlay.color = 'black'\n",
    "viewer.text_overlay.position = 'bottom_left'\n",
    "viewer.text_overlay.font_size = text_size\n",
    "viewer.dims.events.current_step.connect(update_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a709ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = viewer.camera.zoom\n",
    "cam_coords = viewer.camera.center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e27864",
   "metadata": {},
   "source": [
    "### Use camera angle for animation/mp4 creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = f'/home/dayn/Videos/tb_mp4s/glimpses/pierre_data/{acq_ID}/{ID}/glimpse_{ID}.mp4'\n",
    "Path(os.path.dirname(fn)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], scale = scale\n",
    "                )\n",
    "viewer.theme = 'light'\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'm'\n",
    "viewer.scale_bar.font_size = text_size\n",
    "viewer.text_overlay.visible = True\n",
    "viewer.text_overlay.color = 'black'\n",
    "viewer.text_overlay.position = 'bottom_left'\n",
    "viewer.text_overlay.font_size = text_size\n",
    "viewer.dims.events.current_step.connect(update_slider)\n",
    "\n",
    "animation = Animation(viewer)\n",
    "viewer.update_console({'animation': animation})\n",
    "# viewer.camera.center = (0, 0, 3024, 3024)\n",
    "viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "viewer.camera.zoom = zoom*0.85\n",
    "animation.capture_keyframe(steps = 100)\n",
    "viewer.dims.current_step = (74.0,  cam_coords[-2], cam_coords[-1])\n",
    "animation.capture_keyframe(steps = 100)\n",
    "\n",
    "animation.animate(fn, \n",
    "                  canvas_only=True,\n",
    "                  fps = 5,\n",
    "                  quality = 9)\n",
    "viewer.close()\n",
    "\n",
    "Path(os.path.dirname(os.path.dirname(fn)+f'/{ID}_glimpse_seq')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], scale = scale\n",
    "                )\n",
    "viewer.theme = 'light'\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'm'\n",
    "viewer.scale_bar.font_size = text_size\n",
    "viewer.text_overlay.visible = True\n",
    "viewer.text_overlay.color = 'black'\n",
    "viewer.text_overlay.position = 'bottom_left'\n",
    "viewer.text_overlay.font_size = text_size\n",
    "viewer.dims.events.current_step.connect(update_slider)\n",
    "\n",
    "for t in tqdm(list(sc_df['Time (hours)'])):\n",
    "    viewer.dims.current_step = (t, cam_coords[-2], cam_coords[-1])\n",
    "    viewer.camera.zoom = zoom*0.85\n",
    "    new_fn = os.path.dirname(fn)+f'/{ID}_glimpse_seq/t_{t}.tiff'\n",
    "    imsave(new_fn, viewer.screenshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b06a77",
   "metadata": {},
   "source": [
    "# Plot animated graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c05bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(os.path.dirname(new_fn).replace('_seq', f'_animated_graph/')).mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "y = list(sc_df['Intracellular Mtb content'].interpolate())\n",
    "y = gaussian_filter1d(y, sigma=1.5)\n",
    "for n, row in tqdm(enumerate(sc_df.iterrows()), total = len(sc_df)):\n",
    "#     x = list(cell_ID_431['Time'].iloc[0:n+1])\n",
    "#     y = list(cell_ID_431['Intracellular Mtb content'].iloc[0:n+1].interpolate())\n",
    "    x = list(sc_df['Time (hours)'].iloc[0:n+1])\n",
    "    \n",
    "    plot_y = y[0:n+1]\n",
    "\n",
    "    t = row[1]['Time (hours)'] \n",
    "    ID = row[1]['Cell ID']\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,8), gridspec_kw={'width_ratios': [1.15, 1]})\n",
    "#     fig.suptitle(f'Cell ID: {ID}')\n",
    "    glimpse_fn = os.path.dirname(new_fn)+f'/t_{t}.tiff'\n",
    "    glimpse_img = imread(glimpse_fn)\n",
    "    ax1.imshow(glimpse_img)\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax2.plot(x, plot_y,)# c = palette[1])\n",
    "    ax2.set_aspect(75/y.max())\n",
    "    ax2.set(xlabel = 'Time (hours)', ylabel = f'Mtb expression (rfp intensity) in cell {ID}', ylim=(y.min()*0.85,y.max()*1.15), xlim = (0,75))\n",
    "    sns.despine()\n",
    "    new_graph_fn = os.path.dirname(new_fn).replace('_seq', f'_animated_graph/smooth_t_{t}.png')\n",
    "    plt.savefig(new_graph_fn, bbox_inches = 'tight', dpi = 314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70010e",
   "metadata": {},
   "source": [
    "## Compile into mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa37a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots = list()\n",
    "for fn in tqdm(natsorted(glob.glob(os.path.dirname(new_graph_fn)+'/smooth_t_*.png')), ):#total = 56):\n",
    "    plot = imread(fn)\n",
    "    plots.append(plot)\n",
    "plots = np.stack(plots, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890945c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fn = os.path.dirname(new_graph_fn)+'.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9482525",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(plots)#, channel_axis = 0, colormap= ['green', 'magenta'], scale = scale\n",
    "            #    )\n",
    "viewer.theme = 'light'\n",
    "# viewer.scale_bar.visible = True\n",
    "# viewer.scale_bar.unit = 'm'\n",
    "# viewer.scale_bar.font_size = text_size\n",
    "# viewer.text_overlay.visible = True\n",
    "# viewer.text_overlay.color = 'black'\n",
    "# viewer.text_overlay.position = 'bottom_left'\n",
    "# viewer.text_overlay.font_size = text_size\n",
    "# viewer.dims.events.current_step.connect(update_slider)\n",
    "\n",
    "animation = Animation(viewer)\n",
    "viewer.update_console({'animation': animation})\n",
    "# # viewer.camera.center = (0, 0, 3024, 3024)\n",
    "viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "viewer.camera.zoom = zoom\n",
    "animation.capture_keyframe(steps = 100)\n",
    "viewer.dims.current_step = (75.0,  cam_coords[-2], cam_coords[-1])\n",
    "animation.capture_keyframe(steps = 100)\n",
    "\n",
    "animation.animate(final_fn, \n",
    "                  canvas_only=True,\n",
    "                  fps = 5,\n",
    "                  quality = 9)\n",
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659d63b",
   "metadata": {},
   "source": [
    "# Iteratively generate glimpses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98388a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### glimpse size\n",
    "size = 500\n",
    "### resized images\n",
    "scale = 6048/1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_expt_df = df[(df['Compound'] == 'PZA') & (df['Concentration'] == 'EC50')]\n",
    "extreme_cases = pd.concat([selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.max(selected_expt_df['Mean Mtb content']))],\n",
    "                           selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.min(selected_expt_df['Mean Mtb content']))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "for assay_info in tqdm(assay_layout.iterrows(), \n",
    "                       total = len(assay_layout), \n",
    "                       desc = 'Iterating over different assays, generating two extreme glimpses per assay'):\n",
    "    ### pull acq ID from assay info\n",
    "    acq_ID = assay_info[0]\n",
    "\n",
    "    ### iterate over different experiments\n",
    "    selected_expt_df = df[(df['Acquisition ID'] == acq_ID)]\n",
    "\n",
    "    ### get extreme cells\n",
    "    extreme_cases = pd.concat([selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.max(selected_expt_df['Mean Mtb content']))],\n",
    "                               selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.min(selected_expt_df['Mean Mtb content']))]])\n",
    "    \n",
    "    ### iterate over two extreme cases in either\n",
    "    for ID in tqdm(extreme_cases['Cell ID'].unique(), \n",
    "                   desc = f'Iterating over two extreme cells in acquisition ID:{acq_ID}'):\n",
    "        ### isolate a single cell ID from df of interesting cells\n",
    "        sc_df = extreme_cases[extreme_cases['Cell ID']==ID]\n",
    "        # ### get cell ID\n",
    "        # ID = sc_df['Cell ID'].iloc[0]\n",
    "        # ### get acquisition ID \n",
    "        # acq_ID = sc_df['Acquisition ID'].iloc[0]\n",
    "        ### use acq ID to pre load correct images\n",
    "        row, column = acq_ID\n",
    "        images = tile.compile_mosaic(\n",
    "                                     image_dir, \n",
    "                                     metadata, \n",
    "                                     row, \n",
    "                                     column, \n",
    "                                     set_plane = 'sum_proj',\n",
    "                                     ).astype(np.uint16)\n",
    "        ### create base dirname\n",
    "        basedir = f'/home/dayn/Videos/tb_mp4s/glimpses/pierre_data/{acq_ID}/{ID}/'\n",
    "        Path(os.path.dirname(basedir)).mkdir(parents=True, exist_ok=True)\n",
    "        ### make glimpse stack of images\n",
    "        print(f'Creating glimpse ID: {acq_ID, ID}')\n",
    "        ### create empty list for stack of images\n",
    "        glimpse_stack = list()\n",
    "        ### iterate over time points from single cell \n",
    "        for row in tqdm(sc_df.iterrows(), total = len(sc_df), desc = f'Creating glimpse ID: {acq_ID, ID}'):\n",
    "            ### get coords\n",
    "            t, x, y = row[1]['Time (hours)'], row[1]['y'], row[1]['x']\n",
    "            ### select proper frame\n",
    "            frame = images[t,...]\n",
    "            ### scale as tracking was done on rescaled images\n",
    "            x1, y1 = x*scale, y*scale\n",
    "            ### create window for glimpse\n",
    "            x1, x2, y1, y2 = x1, x1+size, y1, y1+size\n",
    "            ### add padding for boundary cases\n",
    "            frame = da.pad(frame, [(0, 0), (size/2, size/2), (size/2, size/2)], 'constant', constant_values = 0) \n",
    "            ### create glimpse image by cropping original image\n",
    "            glimpse = frame[..., int(x1): int(x2), int(y1): int(y2)]\n",
    "            ### append to glimpse stack\n",
    "            glimpse_stack.append(glimpse)\n",
    "        ### stack glimpse together\n",
    "        glimpse_stack = np.stack(glimpse_stack, axis = 1)\n",
    "        ### load glimpse into memory\n",
    "        print(f'Loading glimpse stack {acq_ID, ID} into memory (can take several minutes)')\n",
    "        glimpse_stack = glimpse_stack.compute().compute()\n",
    "        ### Check glimpse with labels\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], scale = napari_scale)\n",
    "        viewer.theme = 'light'\n",
    "        viewer.scale_bar.visible = True\n",
    "        viewer.scale_bar.unit = 'm'\n",
    "        viewer.scale_bar.font_size = text_size\n",
    "        viewer.text_overlay.visible = True\n",
    "        viewer.text_overlay.color = 'black'\n",
    "        viewer.text_overlay.position = 'bottom_left'\n",
    "        viewer.text_overlay.font_size = text_size\n",
    "        viewer.dims.events.current_step.connect(update_slider)\n",
    "        zoom = viewer.camera.zoom\n",
    "        cam_coords = viewer.camera.center\n",
    "\n",
    "        ### create glimpse .mp4 filename\n",
    "        mp4_fn = os.path.join(basedir, f'glimpse_{ID}.mp4')\n",
    "        # Path(os.path.dirname(mp4_fn)).mkdir(parents=True, exist_ok=True)\n",
    "        ### launch napari and animate images into mp4\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], scale = napari_scale)\n",
    "        viewer.theme = 'light'\n",
    "        viewer.scale_bar.visible = True\n",
    "        viewer.scale_bar.unit = 'm'\n",
    "        viewer.scale_bar.font_size = text_size\n",
    "        viewer.text_overlay.visible = True\n",
    "        viewer.text_overlay.color = 'black'\n",
    "        viewer.text_overlay.position = 'bottom_left'\n",
    "        viewer.text_overlay.font_size = text_size\n",
    "        viewer.dims.events.current_step.connect(update_slider)\n",
    "        ### initiate animation viewer\n",
    "        animation = Animation(viewer)\n",
    "        viewer.update_console({'animation': animation})\n",
    "        # viewer.camera.center = (0, 0, 3024, 3024)\n",
    "        viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "        viewer.camera.zoom = zoom*0.85\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        viewer.dims.current_step = (74.0,  cam_coords[-2], cam_coords[-1])\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        ### Save glimpse as MP4\n",
    "        print(f'Saving glimpse .mp4 ID: {acq_ID, ID}')\n",
    "        animation.animate(mp4_fn, \n",
    "                          canvas_only=True,\n",
    "                          fps = 5,\n",
    "                          quality = 9)\n",
    "        viewer.close()\n",
    "        ### save glimpse as a series of images\n",
    "        print(f'Creating glimpse image sequence ID: {acq_ID, ID}')\n",
    "        ### create output directory\n",
    "        glimpse_seq_basedir = os.path.join(basedir, f'{ID}_glimpse_seq')\n",
    "        Path(glimpse_seq_basedir).mkdir(parents=True, exist_ok=True)\n",
    "        ### create napari instances and use to save glimpse frames with scale bar and time\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], scale = napari_scale)\n",
    "        viewer.theme = 'light'\n",
    "        viewer.scale_bar.visible = True\n",
    "        viewer.scale_bar.unit = 'm'\n",
    "        viewer.scale_bar.font_size = text_size\n",
    "        viewer.text_overlay.visible = True\n",
    "        viewer.text_overlay.color = 'black'\n",
    "        viewer.text_overlay.position = 'bottom_left'\n",
    "        viewer.text_overlay.font_size = text_size\n",
    "        viewer.dims.events.current_step.connect(update_slider)\n",
    "        ### save image sequence\n",
    "        for t in tqdm(list(sc_df['Time (hours)']), desc = f'Saving glimpse image sequence ID: {acq_ID, ID}'):\n",
    "            viewer.dims.current_step = (t, cam_coords[-2], cam_coords[-1])\n",
    "            viewer.camera.zoom = zoom*0.85\n",
    "            glimpse_seq_fn = os.path.join(glimpse_seq_basedir, f'glimpse_{ID}_t_{t}.tiff')\n",
    "            imsave(glimpse_seq_fn, viewer.screenshot())\n",
    "        viewer.close()\n",
    "        ### create sequence of graph images\n",
    "        print(f'Creating graph image sequence ID: {acq_ID, ID}')\n",
    "        # create graph output folder\n",
    "        glimpse_graph_seq_basedir = os.path.join(basedir, f'{ID}_glimpse_graph_seq')\n",
    "        Path(glimpse_graph_seq_basedir).mkdir(parents = True, exist_ok = True)\n",
    "        ### create graph by interpolating missing y values\n",
    "        y = sc_df['Intracellular Mtb content'].interpolate().values\n",
    "        x = sc_df['Time (hours)'].values\n",
    "        ### smooth graph\n",
    "        y = gaussian_filter1d(y, sigma=1.5)\n",
    "        ### iterate over time points\n",
    "        for n, row in tqdm(enumerate(sc_df.iterrows()), total = len(sc_df), \n",
    "                           desc = f'Saving graph image sequence ID: {acq_ID, ID}'):\n",
    "            ### select portion of data to plot up to current time point iteration\n",
    "            plot_x = sc_df['Time (hours)'].iloc[0:n+1].values\n",
    "            plot_y = y[0:n+1]\n",
    "            ### get time ID for labelling purposes\n",
    "            t = row[1]['Time (hours)']     \n",
    "            ### initiate plot with two components\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5), gridspec_kw={'width_ratios': [1, 1]})\n",
    "            ### label fn with time point\n",
    "            glimpse_seq_fn = os.path.join(glimpse_seq_basedir, f'glimpse_{ID}_t_{t}.tiff')\n",
    "            ### load glimpse image from this timepoint\n",
    "            glimpse_img = imread(glimpse_seq_fn)\n",
    "            ### add glimpse frame to first part of subplot\n",
    "            ax1.imshow(glimpse_img)\n",
    "            ### turn axis off for glimpse\n",
    "            ax1.axis('off')\n",
    "            ### plot portion of graph \n",
    "            ax2.plot(plot_x, plot_y,)# c = palette[1])\n",
    "            ### set aspect\n",
    "            # ax2.set_aspect(75/y.max())\n",
    "            ### label graph properly \n",
    "            ax2.set(xlabel = 'Time (hours)', \n",
    "                    ylabel = f'Mtb content of cell ID: {ID} \\n (raw RFP intensity)', \n",
    "                    ylim=(y.min()*0.85,y.max()*1.15), \n",
    "                    xlim = (0,75))\n",
    "            ### despine plot\n",
    "            sns.despine()\n",
    "            ### new fn for joint glimpse plot\n",
    "            new_graph_fn = os.path.join(glimpse_graph_seq_basedir, f'glimpse_graph_{ID}_t_{t}.tiff')\n",
    "            plt.savefig(new_graph_fn, bbox_inches = 'tight', dpi = 314)\n",
    "\n",
    "        ## Compile single frame graphs into stack for animation\n",
    "        print(f'Creating graph and glimpse image sequence ID: {acq_ID, ID}')\n",
    "        plots = list()\n",
    "        for fn in natsorted(glob.glob(os.path.join(glimpse_graph_seq_basedir, '*.tiff'))):\n",
    "            plot = imread(fn)\n",
    "            plots.append(plot)\n",
    "        plots = np.stack(plots, axis = 0)\n",
    "        ### create final fn\n",
    "        glimpse_graph_fn = os.path.join(basedir, f'glimpse_graph_{ID}.mp4')\n",
    "        ### initiate napari session for animation\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(plots)#, channel_axis = 0, colormap= ['green', 'magenta'], scale = scale\n",
    "        viewer.theme = 'light'\n",
    "        # viewer.scale_bar.visible = True\n",
    "        # viewer.scale_bar.unit = 'm'\n",
    "        # viewer.scale_bar.font_size = text_size\n",
    "        # viewer.text_overlay.visible = True\n",
    "        # viewer.text_overlay.color = 'black'\n",
    "        # viewer.text_overlay.position = 'bottom_left'\n",
    "        # viewer.text_overlay.font_size = text_size\n",
    "        # viewer.dims.events.current_step.connect(update_slider)\n",
    "        animation = Animation(viewer)\n",
    "        viewer.update_console({'animation': animation})\n",
    "        # # viewer.camera.center = (0, 0, 3024, 3024)\n",
    "        viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "        viewer.camera.zoom = 0.23\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        viewer.dims.current_step = (75.0,  cam_coords[-2], cam_coords[-1])\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        print(f'Saving graph and glimpse animation ID: {acq_ID, ID}')\n",
    "        animation.animate(glimpse_graph_fn, \n",
    "                          canvas_only=True,\n",
    "                          fps = 5,\n",
    "                          quality = 9)\n",
    "        viewer.close()\n",
    "        plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "aero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
