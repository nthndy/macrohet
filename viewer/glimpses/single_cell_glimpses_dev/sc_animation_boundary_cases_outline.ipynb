{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e295e0",
   "metadata": {},
   "source": [
    "# A notebook for creating sc graph animations with glimpses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from cellpose import models\n",
    "from octopuslite import utils, tile\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def view(img):\n",
    "    return napari.Viewer().add_image(img)\n",
    "from napari_animation import Animation\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import btrack\n",
    "import dask.array as da\n",
    "\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.io import imsave, imread\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_palette(\"rocket_r\")\n",
    "\n",
    "def msd_calc(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Displacement calculation for cell movement between frames\n",
    "    \"\"\"\n",
    "    return np.sqrt((x1-x2)**2+(y1-y2)**2)\n",
    "\n",
    "def update_slider(event):\n",
    "    # only trigger if update comes from first axis (optional)\n",
    "        #ind_lambda = viewer.dims.indices[0]\n",
    "    time = viewer.dims.current_step[0]\n",
    "    viewer.text_overlay.text = f\"{time:1.1f} hours\"\n",
    "text_size = 24\n",
    "napari_scale = [1.4949402023919043e-07, 1.4949402023919043e-07]\n",
    "\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "\n",
    "label_text_size = 15\n",
    "### glimpse size\n",
    "size = 500\n",
    "### resized images are to this scale\n",
    "scale = 6048/1200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751ef77",
   "metadata": {},
   "source": [
    "### Load all metadata\n",
    "\n",
    "Both the image metadata and the assay layout metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20db67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dir = '/mnt/DATA/sandbox/pierre_live_cell_data/outputs/Replication_IPSDM_GFP/Images/'\n",
    "image_metadata_fn = '/mnt/DATA/sandbox/pierre_live_cell_data/outputs/Replication_IPSDM_GFP/Index.idx.xml'\n",
    "metadata = utils.read_harmony_metadata(image_metadata_fn)\n",
    "assay_layout_metadata = '/mnt/DATA/sandbox/pierre_live_cell_data/outputs/Replication_IPSDM_GFP/Assaylayout/20210602_Live_cell_IPSDMGFP_ATB.xml'\n",
    "assay_layout = utils.read_harmony_metadata(assay_layout_metadata, assay_layout=True)\n",
    "assay_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae561d",
   "metadata": {},
   "source": [
    "# Iteratively load all tracks\n",
    "\n",
    "and append to a track_dict dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2236a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks_dict = dict()\n",
    "segmentation_dict = dict()\n",
    "### iterate over all experimental conditions\n",
    "for (row, column), info in tqdm(assay_layout.iterrows(), \n",
    "                                desc = 'Progress through positions',\n",
    "                                total = len(assay_layout)):\n",
    "    ### load tracks\n",
    "    with btrack.dataio.HDF5FileHandler(\n",
    "            f'/mnt/DATA/macrohet/segmentation/full_localisation/({row},{column}).h5',#\n",
    "            'r', \n",
    "            obj_type = 'obj_type_1', \n",
    "            ) as hdf: \n",
    "            tracks = hdf.tracks\n",
    "            seg = hdf.segmentation\n",
    "            \n",
    "    tracks_dict[(row, column)] = tracks\n",
    "    segmentation_dict[(row, column)] = seg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c537213",
   "metadata": {},
   "source": [
    "# Compile all full length tracks into dataframe\n",
    "\n",
    "Add extra information such as the MSD of cells between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### list of track info dfs\n",
    "dfs = list()\n",
    "### empty dictionary for filtered tracks\n",
    "filtered_tracks = dict()\n",
    "### iterate over all tracks\n",
    "for key in tracks_dict.keys():\n",
    "    ### extract tracks only with max length\n",
    "    filtered_tracks[key] = [track for track in tracks_dict[key] if len(track) == 75]\n",
    "    ### iterate over full length tracks\n",
    "    for track in filtered_tracks[key]:\n",
    "        ### get info for assay layout\n",
    "        info = assay_layout.loc[key]\n",
    "        ### compile single track dictionary of info\n",
    "        d = {'Time (hours)':track['t'], \n",
    "             'x':track['x'],\n",
    "             'y':track['y'],\n",
    "             'Area':track['area'], \n",
    "             'Intracellular Mtb content':track['mean_intensity-1'],\n",
    "             'Mean Mtb content':[np.nanmean(track['mean_intensity-1']) for i in range(len(track['t']))],\n",
    "             'Macroph. GFP expression':track['mean_intensity-0'],\n",
    "             'Eccentricity':np.sqrt(1-((track['minor_axis_length']**2)/(track['major_axis_length']**2))),\n",
    "             'MSD': [msd_calc(track['x'][i-1], \n",
    "                              track['y'][i-1], \n",
    "                              track['x'][i], \n",
    "                              track['y'][i]) \n",
    "                              if i != 0 else 0\n",
    "                              for i in range(0, len(track))],\n",
    "             'Strain':[info['Strain'] for i in range(len(track['t']))], \n",
    "             'Compound':[info['Compound'] for i in range(len(track['t']))], \n",
    "             'Concentration':[info['ConcentrationEC'] for i in range(len(track['t']))], \n",
    "             'Cell ID':[track.ID for i in range(len(track['t']))],\n",
    "             'Acquisition ID':[key for i in range(len(track['t']))]}\n",
    "        ### append df to list of dfs\n",
    "        dfs.append(pd.DataFrame(d))\n",
    "### concat single track dfs into big df\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "### interpolate missing values as sometimes segmentation drops result in NaN\n",
    "df.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69126882",
   "metadata": {},
   "source": [
    "### Add category to discern initial amount of Mtb growth\n",
    "\n",
    "Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_mtb = df.loc[df['Time (hours)'] == 0, 'Intracellular Mtb content']\n",
    "initial_mtb_quartiles = pd.cut(initial_mtb, bins = [initial_mtb.quantile(.0), \n",
    "                                                    initial_mtb.quantile(.25), \n",
    "                                                    initial_mtb.quantile(0.5), \n",
    "                                                    initial_mtb.quantile(.75),\n",
    "                                                    initial_mtb.quantile(1)], \n",
    "                                                    labels = ['Lower', 'Lower-mid', 'Upper-mid', 'Upper'])\n",
    "df['Initial Mtb load (quartile)'] = initial_mtb_quartiles\n",
    "df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mtb = df.loc[df['Time (hours)'] == 74, 'Intracellular Mtb content']\n",
    "final_mtb_quartiles = pd.cut(final_mtb, bins = [final_mtb.quantile(.0), \n",
    "                                                    final_mtb.quantile(.25), \n",
    "                                                    final_mtb.quantile(0.5), \n",
    "                                                    final_mtb.quantile(.75),\n",
    "                                                    final_mtb.quantile(1)], \n",
    "                                                    labels = ['Lower', 'Lower-mid', 'Upper-mid', 'Upper'])\n",
    "df['Final Mtb load (quartile)'] = final_mtb_quartiles\n",
    "df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3483a",
   "metadata": {},
   "source": [
    "Now continuous assessment: ie. the actual value of the Mtb content in the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_mtb = df.loc[df['Time (hours)'] == 0, 'Intracellular Mtb content']\n",
    "df['Initial Mtb load'] = initial_mtb\n",
    "df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mtb = df.loc[df['Time (hours)'] == 74, 'Intracellular Mtb content']\n",
    "df['Final Mtb load'] = final_mtb\n",
    "df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96269d8b",
   "metadata": {},
   "source": [
    "## Pick a single experiment to focus on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159bb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select from conditions\n",
    "selected_expt_df = df[(df['Compound'] == 'PZA') & (df['Concentration'] == 'EC50')]\n",
    "acq_ID = selected_expt_df['Acquisition ID'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89377e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get extreme cells\n",
    "extreme_cases = pd.concat([selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.max(selected_expt_df['Mean Mtb content']))],\n",
    "                           selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.min(selected_expt_df['Mean Mtb content']))]])\n",
    "extreme_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9739a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### isolate a single cell ID from df of interesting cells\n",
    "ID = 300\n",
    "### isolate sc df\n",
    "sc_df = extreme_cases[extreme_cases['Cell ID']==ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9caff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### or manually select from acquisition ID and Cell ID \n",
    "acq_ID = (3, 8)\n",
    "selected_expt_df = df[(df['Acquisition ID'] == acq_ID)]\n",
    "### get cell ID\n",
    "ID = 300\n",
    "### isolate sc df\n",
    "sc_df = extreme_cases[extreme_cases['Cell ID']==ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f07a4",
   "metadata": {},
   "source": [
    "# First assess glimpse with scale bars etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7020610",
   "metadata": {},
   "outputs": [],
   "source": [
    "### use acq ID to pre load correct images\n",
    "row, column = acq_ID\n",
    "images = tile.compile_mosaic(\n",
    "                             image_dir, \n",
    "                             metadata, \n",
    "                             row, \n",
    "                             column, \n",
    "                             set_plane = 'sum_proj',\n",
    "                             ).astype(np.uint16)\n",
    "### create base dirname\n",
    "basedir = f'/mnt/DATA/macrohet/results/glimpses/labelled/{acq_ID}/{ID}/'\n",
    "Path(os.path.dirname(basedir)).mkdir(parents=True, exist_ok=True)\n",
    "### make glimpse stack of images\n",
    "print(f'Creating glimpse ID: {acq_ID, ID}')\n",
    "### create empty list for stack of images\n",
    "glimpse_stack = list()\n",
    "### iterate over time points from single cell \n",
    "for row in tqdm(sc_df.iterrows(), total = len(sc_df), desc = f'Creating glimpse ID: {acq_ID, ID}'):\n",
    "    ### get coords\n",
    "    t, x, y = row[1]['Time (hours)'], row[1]['y'], row[1]['x']\n",
    "    ### select proper frame\n",
    "    frame = images[t,...]\n",
    "    ### scale as tracking was done on rescaled images\n",
    "    x1, y1 = x*scale, y*scale\n",
    "    ### create window for glimpse\n",
    "    x1, x2, y1, y2 = x1, x1+size, y1, y1+size\n",
    "    ### add padding for boundary cases\n",
    "    frame = da.pad(frame, [(0, 0), (size/2, size/2), (size/2, size/2)], 'constant', constant_values = 0) \n",
    "    ### create glimpse image by cropping original image\n",
    "    glimpse = frame[..., int(x1): int(x2), int(y1): int(y2)]\n",
    "    ### append to glimpse stack\n",
    "    glimpse_stack.append(glimpse)\n",
    "    \n",
    "### stack glimpse together\n",
    "glimpse_stack = np.stack(glimpse_stack, axis = 1)\n",
    "### load glimpse into memory\n",
    "print(f'Loading glimpse stack {acq_ID, ID} into memory (can take several minutes)')\n",
    "# glimpse_stack = glimpse_stack.compute().compute()\n",
    "\n",
    "### make glimpse stack of masks\n",
    "print(f'Creating mask glimpse ID: {acq_ID, ID}')\n",
    "### get mask images\n",
    "masks = segmentation_dict[acq_ID]\n",
    "### create empty list for stack of images\n",
    "mask_glimpse_stack = list()\n",
    "coords_stack = list()\n",
    "### iterate over time points from single cell \n",
    "for row in tqdm(sc_df.iterrows(), total = len(sc_df), desc = f'Creating mask glimpse ID: {acq_ID, ID}'):\n",
    "    ### get coords\n",
    "    t, x, y = row[1]['Time (hours)'], row[1]['y'], row[1]['x']\n",
    "    ### select proper frame\n",
    "    frame = masks[t,...]\n",
    "    ### scale as tracking was done on rescaled images\n",
    "    x1, y1 = x, y\n",
    "    ### create window for glimpse\n",
    "    x1, x2, y1, y2 = x1, x1+np.ceil(size/scale), y1, y1+np.ceil(size/scale)\n",
    "    ### add padding for boundary cases\n",
    "    frame = np.pad(frame, [(int(np.ceil(size/scale)/2), int(np.ceil(size/scale)/2)), (int(np.ceil(size/scale)/2), int(np.ceil(size/scale)/2))], 'constant', constant_values = 0) \n",
    "    ### create glimpse image by cropping original image\n",
    "    mask_glimpse = frame[int(x1): int(x2), int(y1): int(y2)]\n",
    "    ### select cell of interest\n",
    "    mask_glimpse = mask_glimpse == mask_glimpse[int(np.ceil(size/scale)/2), int(np.ceil(size/scale)/2)]\n",
    "    ### resize to image size\n",
    "    mask_glimpse = cv2.resize(mask_glimpse.astype(np.uint8), (size,size))\n",
    "    ### get contour\n",
    "    cnts = cv2.findContours(mask_glimpse, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    coords = np.asarray([[t, i[0][1], i[0][0]] for i in cnts[0]])\n",
    "    for c in cnts:\n",
    "        cv2.drawContours(mask_glimpse, [c], -1, (255, 255, 255), thickness=5)\n",
    "    ### change dtype of mask\n",
    "    mask_glimpse = (mask_glimpse == 255).astype(np.uint16)\n",
    "    ### append to mask glimpse stack\n",
    "    mask_glimpse_stack.append(mask_glimpse)\n",
    "    coords_stack.append(coords)\n",
    "### stack mask glimpse together\n",
    "mask_glimpse_stack = np.stack(mask_glimpse_stack, axis = 0)\n",
    "### build coords into shape for napari\n",
    "mask_shapes = np.asarray(coords_stack, )#axis = 0)\n",
    "### get expt info\n",
    "expt_info = sc_df['Strain'].iloc[0],sc_df['Compound'].iloc[0],sc_df['Concentration'].iloc[0], sc_df['Cell ID'].iloc[0]\n",
    "expt_info = ','.join(map(str, expt_info))\n",
    "### create a set of points to anchor labels at\n",
    "label_points = [[t, 0, 500] for t in sc_df['Time (hours)']]\n",
    "### create labels\n",
    "text_overlay = f'cell ID:{acq_ID[0], acq_ID[1], ID}'\n",
    "fixed_labels = {'macrophage':['Macrophage:green' for i in range(len(mask_shapes))],\n",
    "                'mtb':['Mtb:magenta' for i in range(len(mask_shapes))],\n",
    "                'mask':[f'Mask:cyan' for i in range(len(mask_shapes))],\n",
    "                'info':[f'ID:{expt_info}' for i in range(len(mask_shapes))]}\n",
    "### create lists of labels for tidier iteration of adding labels \n",
    "labels_list = list([fixed_labels['macrophage'], fixed_labels['mtb'], fixed_labels['mask'], fixed_labels['info']])\n",
    "offset_list = list([[20,-5], [40,-5], [60,-5], [80,-5]])\n",
    "colour_list = list(['#39FF14', 'magenta', 'cyan', 'white'])\n",
    "\n",
    "# ### Check glimpse with labels\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], scale = napari_scale)\n",
    "# viewer.theme = 'light'\n",
    "# viewer.scale_bar.visible = True\n",
    "# viewer.scale_bar.unit = 'm'\n",
    "# viewer.scale_bar.font_size = text_size\n",
    "# viewer.text_overlay.visible = True\n",
    "# viewer.text_overlay.color = 'black'\n",
    "# viewer.text_overlay.position = 'bottom_left'\n",
    "# viewer.text_overlay.font_size = text_size\n",
    "# viewer.dims.events.current_step.connect(update_slider)\n",
    "\n",
    "# viewer.text_overlay.visible = True\n",
    "# viewer.text_overlay.color = 'black'\n",
    "# viewer.text_overlay.position = 'top_left'\n",
    "# viewer.text_overlay.font_size = text_size\n",
    "# viewer.text_overlay.text = 'test'\n",
    "\n",
    "### new way of checking with overlaid labels etc\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(mask_glimpse_stack, scale = napari_scale, colormap='cyan')\n",
    "# # add the image\n",
    "viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], blending = ['additive', 'additive'],\n",
    "                 scale = napari_scale)\n",
    "# viewer.add_image(mask_glimpse_stack,)# channel_axis = 0, colormap= ['green', 'magenta'], blending = ['translucent', 'additive'],)# scale = napari_scale)\n",
    "viewer.theme = 'light'\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'm'\n",
    "viewer.scale_bar.font_size = text_size\n",
    "viewer.text_overlay.visible = True\n",
    "viewer.text_overlay.color = 'black'\n",
    "viewer.text_overlay.position = 'bottom_left'\n",
    "viewer.text_overlay.font_size = text_size\n",
    "viewer.dims.events.current_step.connect(update_slider)\n",
    "\n",
    "### other way of adding shape contours as mask outline\n",
    "# viewer.add_shapes(\n",
    "#     mask_shapes,\n",
    "#     properties = properties,\n",
    "#     scale = [1, napari_scale[0], napari_scale[1]],\n",
    "# #     features = features,\n",
    "#     shape_type='polygon',\n",
    "#     edge_width=5,\n",
    "#     edge_color='cyan',\n",
    "# #     edge_color_cycle = edge_color_cycle,\n",
    "#     face_color='transparent', \n",
    "#     name = 'mask shapes')\n",
    "\n",
    "for config in zip(labels_list, offset_list, colour_list):\n",
    "    string, offset, colour = config\n",
    "    viewer.add_points(\n",
    "    label_points, \n",
    "    scale = [1, napari_scale[0], napari_scale[1]],\n",
    "    face_color = 'transparent', \n",
    "    edge_color = 'transparent', \n",
    "    text = {'string':string,\n",
    "            'anchor': 'upper_right',\n",
    "            'translation': offset,\n",
    "            'size': text_size,\n",
    "            'color': colour}, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283569f",
   "metadata": {},
   "source": [
    "# Check view "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d18cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overlay_font_size = 26\n",
    "scale_bar_font_size = 26\n",
    "label_font_size = 30\n",
    "text_colour = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = viewer.camera.zoom\n",
    "cam_coords = viewer.camera.center\n",
    "### use this to assess camera angles before proceeding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb77d4",
   "metadata": {},
   "source": [
    "# Then create .mp4 of glimpse and animated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af05b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### create glimpse .mp4 filename\n",
    "mp4_fn = os.path.join(basedir, f'glimpse_{ID}.mp4')\n",
    "# Path(os.path.dirname(mp4_fn)).mkdir(parents=True, exist_ok=True)\n",
    "### launch napari and animate images into mp4\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(mask_glimpse_stack, scale = napari_scale, colormap='cyan')\n",
    "viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], blending = 'additive', scale = napari_scale)\n",
    "viewer.theme = 'light'\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'm'\n",
    "viewer.scale_bar.font_size = scale_bar_font_size\n",
    "viewer.scale_bar.colored = True\n",
    "viewer.scale_bar.color = text_colour\n",
    "viewer.scale_bar.ticks = False\n",
    "viewer.text_overlay.visible = True\n",
    "viewer.text_overlay.color = text_colour\n",
    "viewer.text_overlay.position = 'bottom_left'\n",
    "viewer.text_overlay.font_size = time_overlay_font_size\n",
    "viewer.dims.events.current_step.connect(update_slider)\n",
    "for config in zip(labels_list, offset_list, colour_list):\n",
    "    string, offset, colour = config\n",
    "    viewer.add_points(\n",
    "    label_points, \n",
    "    scale = [1, napari_scale[0], napari_scale[1]],\n",
    "    face_color = 'transparent', \n",
    "    edge_color = 'transparent', \n",
    "    text = {'string':string,\n",
    "            'anchor': 'upper_right',\n",
    "            'translation': offset,\n",
    "            'size': label_font_size,\n",
    "            'color': colour}, )\n",
    "### initiate animation viewer\n",
    "animation = Animation(viewer)\n",
    "viewer.update_console({'animation': animation})\n",
    "# viewer.camera.center = (0, 0, 3024, 3024)\n",
    "viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "viewer.camera.zoom = zoom#*0.85\n",
    "animation.capture_keyframe(steps = 100)\n",
    "viewer.dims.current_step = (74.0,  cam_coords[-2], cam_coords[-1])\n",
    "animation.capture_keyframe(steps = 100)\n",
    "### Save glimpse as MP4\n",
    "print(f'Saving glimpse .mp4 ID: {acq_ID, ID}')\n",
    "animation.animate(mp4_fn, \n",
    "                  canvas_only=True,\n",
    "                  fps = 5,\n",
    "                  quality = 9)\n",
    "viewer.close()\n",
    "### save glimpse as a series of images\n",
    "print(f'Creating glimpse image sequence ID: {acq_ID, ID}')\n",
    "### create output directory\n",
    "glimpse_seq_basedir = os.path.join(basedir, f'{ID}_glimpse_seq')\n",
    "Path(glimpse_seq_basedir).mkdir(parents=True, exist_ok=True)\n",
    "### create napari instances and use to save glimpse frames with scale bar and time\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(mask_glimpse_stack, scale = napari_scale, colormap='cyan')\n",
    "viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], blending = 'additive', scale = napari_scale)\n",
    "viewer.theme = 'light'\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'm'\n",
    "viewer.scale_bar.font_size = scale_bar_font_size\n",
    "viewer.scale_bar.colored = True\n",
    "viewer.scale_bar.color = text_colour\n",
    "viewer.scale_bar.ticks = False\n",
    "viewer.text_overlay.visible = True\n",
    "viewer.text_overlay.color = text_colour\n",
    "viewer.text_overlay.position = 'bottom_left'\n",
    "viewer.text_overlay.font_size = time_overlay_font_size\n",
    "viewer.dims.events.current_step.connect(update_slider)\n",
    "for config in zip(labels_list, offset_list, colour_list):\n",
    "    string, offset, colour = config\n",
    "    viewer.add_points(\n",
    "    label_points, \n",
    "    scale = [1, napari_scale[0], napari_scale[1]],\n",
    "    face_color = 'transparent', \n",
    "    edge_color = 'transparent', \n",
    "    text = {'string':string,\n",
    "            'anchor': 'upper_right',\n",
    "            'translation': offset,\n",
    "            'size': label_font_size,\n",
    "            'color': colour}, )\n",
    "### save image sequence\n",
    "for t in tqdm(list(sc_df['Time (hours)']), desc = f'Saving glimpse image sequence ID: {acq_ID, ID}'):\n",
    "    viewer.dims.current_step = (t, cam_coords[-2], cam_coords[-1])\n",
    "    viewer.camera.zoom = zoom#*0.85\n",
    "    glimpse_seq_fn = os.path.join(glimpse_seq_basedir, f'glimpse_{ID}_t_{t}.tiff')\n",
    "    imsave(glimpse_seq_fn, viewer.screenshot())\n",
    "viewer.close()\n",
    "### create sequence of graph images\n",
    "print(f'Creating graph image sequence ID: {acq_ID, ID}')\n",
    "# create graph output folder\n",
    "glimpse_graph_seq_basedir = os.path.join(basedir, f'{ID}_glimpse_graph_seq')\n",
    "Path(glimpse_graph_seq_basedir).mkdir(parents = True, exist_ok = True)\n",
    "### create graph by interpolating missing y values\n",
    "y = sc_df['Intracellular Mtb content'].interpolate().values\n",
    "x = sc_df['Time (hours)'].values\n",
    "### smooth graph\n",
    "y = gaussian_filter1d(y, sigma=1.5)\n",
    "### iterate over time points\n",
    "for n, row in tqdm(enumerate(sc_df.iterrows()), total = len(sc_df), \n",
    "                   desc = f'Saving graph image sequence ID: {acq_ID, ID}'):\n",
    "    ### select portion of data to plot up to current time point iteration\n",
    "    plot_x = sc_df['Time (hours)'].iloc[0:n+1].values\n",
    "    plot_y = y[0:n+1]\n",
    "    ### get time ID for labelling purposes\n",
    "    t = row[1]['Time (hours)']     \n",
    "    ### initiate plot with two components\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    ### label fn with time point\n",
    "    glimpse_seq_fn = os.path.join(glimpse_seq_basedir, f'glimpse_{ID}_t_{t}.tiff')\n",
    "    ### load glimpse image from this timepoint\n",
    "    glimpse_img = imread(glimpse_seq_fn)\n",
    "    ### add glimpse frame to first part of subplot\n",
    "    ax1.imshow(glimpse_img)\n",
    "    ### turn axis off for glimpse\n",
    "    ax1.axis('off')\n",
    "    ### plot portion of graph \n",
    "    ax2.plot(plot_x, plot_y, c = 'magenta')\n",
    "    ### set aspect\n",
    "    # ax2.set_aspect(75/y.max())\n",
    "    ### label graph properly \n",
    "    ax2.set(xlabel = 'Time (hours)', \n",
    "            ylabel = f'Mtb content of cell ID: {ID} \\n (raw fluorescence intensity)', \n",
    "            ylim=(y.min()*0.85,y.max()*1.15), \n",
    "            xlim = (0,75))\n",
    "    ### despine plot\n",
    "    sns.despine()\n",
    "    ### new fn for joint glimpse plot\n",
    "    new_graph_fn = os.path.join(glimpse_graph_seq_basedir, f'glimpse_graph_{ID}_t_{t}.tiff')\n",
    "    plt.savefig(new_graph_fn, bbox_inches = 'tight', dpi = 314)\n",
    "\n",
    "## Compile single frame graphs into stack for animation\n",
    "print(f'Creating graph and glimpse image sequence ID: {acq_ID, ID}')\n",
    "plots = list()\n",
    "for fn in natsorted(glob.glob(os.path.join(glimpse_graph_seq_basedir, '*.tiff'))):\n",
    "    plot = imread(fn)\n",
    "    plots.append(plot)\n",
    "plots = np.stack(plots, axis = 0)\n",
    "### create final fn\n",
    "glimpse_graph_fn = os.path.join(basedir, f'glimpse_graph_{ID}.mp4')\n",
    "### initiate napari session for animation\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(plots)#, channel_axis = 0, colormap= ['green', 'magenta'], scale = scale\n",
    "viewer.theme = 'light'\n",
    "# viewer.scale_bar.visible = True\n",
    "# viewer.scale_bar.unit = 'm'\n",
    "# viewer.scale_bar.font_size = text_size\n",
    "# viewer.text_overlay.visible = True\n",
    "# viewer.text_overlay.color = 'black'\n",
    "# viewer.text_overlay.position = 'bottom_left'\n",
    "# viewer.text_overlay.font_size = text_size\n",
    "# viewer.dims.events.current_step.connect(update_slider)\n",
    "animation = Animation(viewer)\n",
    "viewer.update_console({'animation': animation})\n",
    "# # viewer.camera.center = (0, 0, 3024, 3024)\n",
    "viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "# viewer.camera.zoom = 0.23\n",
    "animation.capture_keyframe(steps = 100)\n",
    "viewer.dims.current_step = (75.0,  cam_coords[-2], cam_coords[-1])\n",
    "animation.capture_keyframe(steps = 100)\n",
    "print(f'Saving graph and glimpse animation ID: {acq_ID, ID}')\n",
    "animation.animate(glimpse_graph_fn, \n",
    "                  canvas_only=True,\n",
    "                  fps = 5,\n",
    "                  quality = 9)\n",
    "viewer.close()\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659d63b",
   "metadata": {},
   "source": [
    "# Iteratively generate glimpses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "if acq_ID not in [(4, 9), (4, 6), (5, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ffe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imread('/mnt/DATA/macrohet/results/glimpses/labelled/(4, 9)/264/264_glimpse_seq/glimpse_264_t_0.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551adb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f75934",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[...,0], cmap = 'Reds_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[...,1], cmap = 'Greens_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[...,2], cmap = 'Blues_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf1d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(im[...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(im2[...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im2[...,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32245a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = imread('/mnt/DATA/macrohet/results/glimpses/labelled/(4, 9)/17/17_glimpse_seq/glimpse_17_t_0.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d18568",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(basedir, f'{ID}_glimpse_seq', f'glimpse_{ID}_t_{t}.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, assay_info in tqdm(enumerate(assay_layout.iterrows()), \n",
    "                       total = len(assay_layout), \n",
    "                       desc = 'Iterating over different assays, generating two extreme glimpses per assay'):\n",
    "    \n",
    "                          \n",
    "    ### pull acq ID from assay info\n",
    "    acq_ID = assay_info[0]\n",
    "\n",
    "    ### iterate over different experiments\n",
    "    selected_expt_df = df[(df['Acquisition ID'] == acq_ID)]\n",
    "\n",
    "    ### get extreme cells\n",
    "    extreme_cases = pd.concat([selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.max(selected_expt_df['Mean Mtb content']))],\n",
    "                               selected_expt_df[(selected_expt_df['Mean Mtb content'] == np.min(selected_expt_df['Mean Mtb content']))]])\n",
    "    \n",
    "    ### iterate over two extreme cases in either\n",
    "    for ID in tqdm(extreme_cases['Cell ID'].unique(), \n",
    "                   desc = f'Iterating over two extreme cells in acquisition ID:{acq_ID}'):\n",
    "        ### isolate a single cell ID from df of interesting cells\n",
    "        sc_df = extreme_cases[extreme_cases['Cell ID']==ID]\n",
    "        \n",
    "        # ### get cell ID\n",
    "        # ID = sc_df['Cell ID'].iloc[0]\n",
    "        # ### get acquisition ID \n",
    "        # acq_ID = sc_df['Acquisition ID'].iloc[0]\n",
    "        ### use acq ID to pre load correct images\n",
    "        row, column = acq_ID\n",
    "        images = tile.compile_mosaic(\n",
    "                                     image_dir, \n",
    "                                     metadata, \n",
    "                                     row, \n",
    "                                     column, \n",
    "                                     set_plane = 'sum_proj',\n",
    "                                     ).astype(np.uint16)\n",
    "        ### create base dirname\n",
    "        basedir = f'/mnt/DATA/macrohet/results/glimpses/labelled/{acq_ID}/{ID}/'\n",
    "        Path(os.path.dirname(basedir)).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        ### skip certain pos\n",
    "        ### find average value of 4th channel in first image\n",
    "        ### test fn \n",
    "        test_fn = os.path.join(basedir, f'{ID}_glimpse_seq', f'glimpse_{ID}_t_{0}.tiff')\n",
    "        im = imread(test_fn)\n",
    "        mean = np.mean(im[...,3])\n",
    "        if mean >= 255.0:\n",
    "            print(f'Skipping {acq_ID, ID} as seems to already be properly rendered')\n",
    "            continue\n",
    "        else: \n",
    "            print(f'Continuing {acq_ID, ID} as seems to already be falsely rendered')\n",
    "                    \n",
    "        \n",
    "        ### make glimpse stack of images\n",
    "        print(f'Creating glimpse ID: {acq_ID, ID}')\n",
    "        ### create empty list for stack of images\n",
    "        glimpse_stack = list()\n",
    "        ### iterate over time points from single cell \n",
    "        for row in tqdm(sc_df.iterrows(), total = len(sc_df), desc = f'Creating glimpse ID: {acq_ID, ID}'):\n",
    "            ### get coords\n",
    "            t, x, y = row[1]['Time (hours)'], row[1]['y'], row[1]['x']\n",
    "            ### select proper frame\n",
    "            frame = images[t,...]\n",
    "            ### scale as tracking was done on rescaled images\n",
    "            x1, y1 = x*scale, y*scale\n",
    "            ### create window for glimpse\n",
    "            x1, x2, y1, y2 = x1, x1+size, y1, y1+size\n",
    "            ### add padding for boundary cases\n",
    "            frame = da.pad(frame, [(0, 0), (size/2, size/2), (size/2, size/2)], 'constant', constant_values = 0) \n",
    "            ### create glimpse image by cropping original image\n",
    "            glimpse = frame[..., int(x1): int(x2), int(y1): int(y2)]\n",
    "            ### append to glimpse stack\n",
    "            glimpse_stack.append(glimpse)\n",
    "\n",
    "        ### stack glimpse together\n",
    "        glimpse_stack = np.stack(glimpse_stack, axis = 1)\n",
    "        ### load glimpse into memory\n",
    "        print(f'Loading glimpse stack {acq_ID, ID} into memory (can take several minutes)')\n",
    "        glimpse_stack = glimpse_stack.compute().compute()\n",
    "\n",
    "        ### make glimpse stack of masks\n",
    "        print(f'Creating mask glimpse ID: {acq_ID, ID}')\n",
    "        ### get mask images\n",
    "        masks = segmentation_dict[acq_ID]\n",
    "        ### create empty list for stack of images\n",
    "        mask_glimpse_stack = list()\n",
    "        coords_stack = list()\n",
    "        ### iterate over time points from single cell \n",
    "        for row in tqdm(sc_df.iterrows(), total = len(sc_df), desc = f'Creating mask glimpse ID: {acq_ID, ID}'):\n",
    "            ### get coords\n",
    "            t, x, y = row[1]['Time (hours)'], row[1]['y'], row[1]['x']\n",
    "            ### select proper frame\n",
    "            frame = masks[t,...]\n",
    "            ### scale as tracking was done on rescaled images\n",
    "            x1, y1 = x, y\n",
    "            ### create window for glimpse\n",
    "            x1, x2, y1, y2 = x1, x1+np.ceil(size/scale), y1, y1+np.ceil(size/scale)\n",
    "            ### add padding for boundary cases\n",
    "            frame = np.pad(frame, [(int(np.ceil(size/scale)/2), int(np.ceil(size/scale)/2)), (int(np.ceil(size/scale)/2), int(np.ceil(size/scale)/2))], 'constant', constant_values = 0) \n",
    "            ### create glimpse image by cropping original image\n",
    "            mask_glimpse = frame[int(x1): int(x2), int(y1): int(y2)]\n",
    "            ### select cell of interest\n",
    "            mask_glimpse = mask_glimpse == mask_glimpse[int(np.ceil(size/scale)/2), int(np.ceil(size/scale)/2)]\n",
    "            ### resize to image size\n",
    "            mask_glimpse = cv2.resize(mask_glimpse.astype(np.uint8), (size,size))\n",
    "            ### get contour\n",
    "            cnts = cv2.findContours(mask_glimpse, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "            coords = np.asarray([[t, i[0][1], i[0][0]] for i in cnts[0]])\n",
    "            for c in cnts:\n",
    "                cv2.drawContours(mask_glimpse, [c], -1, (255, 255, 255), thickness=5)\n",
    "            ### change dtype of mask\n",
    "            mask_glimpse = (mask_glimpse == 255).astype(np.uint16)\n",
    "            ### append to mask glimpse stack\n",
    "            mask_glimpse_stack.append(mask_glimpse)\n",
    "            coords_stack.append(coords)\n",
    "        ### stack mask glimpse together\n",
    "        mask_glimpse_stack = np.stack(mask_glimpse_stack, axis = 0)\n",
    "        ### build coords into shape for napari\n",
    "        mask_shapes = np.asarray(coords_stack, )#axis = 0)\n",
    "        ### get expt info\n",
    "        expt_info = sc_df['Strain'].iloc[0],sc_df['Compound'].iloc[0],sc_df['Concentration'].iloc[0], sc_df['Cell ID'].iloc[0]\n",
    "        expt_info = ','.join(map(str, expt_info))\n",
    "        ### create a set of points to anchor labels at\n",
    "        label_points = [[t, 0, 500] for t in sc_df['Time (hours)']]\n",
    "        ### create labels\n",
    "        text_overlay = f'cell ID:{acq_ID[0], acq_ID[1], ID}'\n",
    "        fixed_labels = {'macrophage':['Macrophage:green' for i in range(len(mask_shapes))],\n",
    "                        'mtb':['Mtb:magenta' for i in range(len(mask_shapes))],\n",
    "                        'mask':[f'Mask:cyan' for i in range(len(mask_shapes))],\n",
    "                        'info':[f'ID:{expt_info}' for i in range(len(mask_shapes))]}\n",
    "        ### create lists of labels for tidier iteration of adding labels \n",
    "        labels_list = list([fixed_labels['macrophage'], fixed_labels['mtb'], fixed_labels['mask'], fixed_labels['info']])\n",
    "        offset_list = list([[20,-5], [40,-5], [60,-5], [80,-5]])\n",
    "        colour_list = list(['#39FF14', 'magenta', 'cyan', 'white'])\n",
    "\n",
    "        ### create glimpse .mp4 filename\n",
    "        mp4_fn = os.path.join(basedir, f'glimpse_{ID}.mp4')\n",
    "        # Path(os.path.dirname(mp4_fn)).mkdir(parents=True, exist_ok=True)\n",
    "        ### launch napari and animate images into mp4\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(mask_glimpse_stack, scale = napari_scale, colormap='cyan')\n",
    "        viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], blending = 'additive', scale = napari_scale)\n",
    "        viewer.theme = 'light'\n",
    "        viewer.scale_bar.visible = True\n",
    "        viewer.scale_bar.unit = 'm'\n",
    "        viewer.scale_bar.font_size = scale_bar_font_size\n",
    "        viewer.scale_bar.colored = True\n",
    "        viewer.scale_bar.color = text_colour\n",
    "        viewer.scale_bar.ticks = False\n",
    "        viewer.text_overlay.visible = True\n",
    "        viewer.text_overlay.color = text_colour\n",
    "        viewer.text_overlay.position = 'bottom_left'\n",
    "        viewer.text_overlay.font_size = time_overlay_font_size\n",
    "        viewer.dims.events.current_step.connect(update_slider)\n",
    "        for config in zip(labels_list, offset_list, colour_list):\n",
    "            string, offset, colour = config\n",
    "            viewer.add_points(\n",
    "            label_points, \n",
    "            scale = [1, napari_scale[0], napari_scale[1]],\n",
    "            face_color = 'transparent', \n",
    "            edge_color = 'transparent', \n",
    "            text = {'string':string,\n",
    "                    'anchor': 'upper_right',\n",
    "                    'translation': offset,\n",
    "                    'size': label_font_size,\n",
    "                    'color': colour}, )\n",
    "        ### initiate animation viewer\n",
    "        animation = Animation(viewer)\n",
    "        viewer.update_console({'animation': animation})\n",
    "        # viewer.camera.center = (0, 0, 3024, 3024)\n",
    "        viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "        viewer.camera.zoom = zoom#*0.85\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        viewer.dims.current_step = (74.0,  cam_coords[-2], cam_coords[-1])\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        ### Save glimpse as MP4\n",
    "        print(f'Saving glimpse .mp4 ID: {acq_ID, ID}')\n",
    "        animation.animate(mp4_fn, \n",
    "                          canvas_only=True,\n",
    "                          fps = 5,\n",
    "                          quality = 9)\n",
    "        viewer.close()\n",
    "        ### save glimpse as a series of images\n",
    "        print(f'Creating glimpse image sequence ID: {acq_ID, ID}')\n",
    "        ### create output directory\n",
    "        glimpse_seq_basedir = os.path.join(basedir, f'{ID}_glimpse_seq')\n",
    "        Path(glimpse_seq_basedir).mkdir(parents=True, exist_ok=True)\n",
    "        ### create napari instances and use to save glimpse frames with scale bar and time\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(mask_glimpse_stack, scale = napari_scale, colormap='cyan')\n",
    "        viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], blending = 'additive', scale = napari_scale)\n",
    "        viewer.theme = 'light'\n",
    "        viewer.scale_bar.visible = True\n",
    "        viewer.scale_bar.unit = 'm'\n",
    "        viewer.scale_bar.font_size = scale_bar_font_size\n",
    "        viewer.scale_bar.colored = True\n",
    "        viewer.scale_bar.color = text_colour\n",
    "        viewer.scale_bar.ticks = False\n",
    "        viewer.text_overlay.visible = True\n",
    "        viewer.text_overlay.color = text_colour\n",
    "        viewer.text_overlay.position = 'bottom_left'\n",
    "        viewer.text_overlay.font_size = time_overlay_font_size\n",
    "        viewer.dims.events.current_step.connect(update_slider)\n",
    "        for config in zip(labels_list, offset_list, colour_list):\n",
    "            string, offset, colour = config\n",
    "            viewer.add_points(\n",
    "            label_points, \n",
    "            scale = [1, napari_scale[0], napari_scale[1]],\n",
    "            face_color = 'transparent', \n",
    "            edge_color = 'transparent', \n",
    "            text = {'string':string,\n",
    "                    'anchor': 'upper_right',\n",
    "                    'translation': offset,\n",
    "                    'size': label_font_size,\n",
    "                    'color': colour}, )\n",
    "        ### save image sequence\n",
    "        for t in tqdm(list(sc_df['Time (hours)']), desc = f'Saving glimpse image sequence ID: {acq_ID, ID}'):\n",
    "            viewer.dims.current_step = (t, cam_coords[-2], cam_coords[-1])\n",
    "            viewer.camera.zoom = zoom#*0.85\n",
    "            glimpse_seq_fn = os.path.join(glimpse_seq_basedir, f'glimpse_{ID}_t_{t}.tiff')\n",
    "            imsave(glimpse_seq_fn, viewer.screenshot())\n",
    "        viewer.close()\n",
    "        ### create sequence of graph images\n",
    "        print(f'Creating graph image sequence ID: {acq_ID, ID}')\n",
    "        # create graph output folder\n",
    "        glimpse_graph_seq_basedir = os.path.join(basedir, f'{ID}_glimpse_graph_seq')\n",
    "        Path(glimpse_graph_seq_basedir).mkdir(parents = True, exist_ok = True)\n",
    "        ### create graph by interpolating missing y values\n",
    "        y = sc_df['Intracellular Mtb content'].interpolate().values\n",
    "        x = sc_df['Time (hours)'].values\n",
    "        ### smooth graph\n",
    "        y = gaussian_filter1d(y, sigma=1.5)\n",
    "        ### iterate over time points\n",
    "        for n, row in tqdm(enumerate(sc_df.iterrows()), total = len(sc_df), \n",
    "                           desc = f'Saving graph image sequence ID: {acq_ID, ID}'):\n",
    "            ### select portion of data to plot up to current time point iteration\n",
    "            plot_x = sc_df['Time (hours)'].iloc[0:n+1].values\n",
    "            plot_y = y[0:n+1]\n",
    "            ### get time ID for labelling purposes\n",
    "            t = row[1]['Time (hours)']     \n",
    "            ### initiate plot with two components\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5), gridspec_kw={'width_ratios': [1, 1]})\n",
    "            ### label fn with time point\n",
    "            glimpse_seq_fn = os.path.join(glimpse_seq_basedir, f'glimpse_{ID}_t_{t}.tiff')\n",
    "            ### load glimpse image from this timepoint\n",
    "            glimpse_img = imread(glimpse_seq_fn)\n",
    "            ### add glimpse frame to first part of subplot\n",
    "            ax1.imshow(glimpse_img)\n",
    "            ### turn axis off for glimpse\n",
    "            ax1.axis('off')\n",
    "            ### plot portion of graph \n",
    "            ax2.plot(plot_x, plot_y, c = 'magenta')\n",
    "            ### set aspect\n",
    "            # ax2.set_aspect(75/y.max())\n",
    "            ### label graph properly \n",
    "            ax2.set(xlabel = 'Time (hours)', \n",
    "                    ylabel = f'Mtb content of cell ID: {ID} \\n (raw fluorescence intensity)', \n",
    "                    ylim=(y.min()*0.85,y.max()*1.15), \n",
    "                    xlim = (0,75))\n",
    "            ### despine plot\n",
    "            sns.despine()\n",
    "            ### new fn for joint glimpse plot\n",
    "            new_graph_fn = os.path.join(glimpse_graph_seq_basedir, f'glimpse_graph_{ID}_t_{t}.tiff')\n",
    "            plt.savefig(new_graph_fn, bbox_inches = 'tight', dpi = 314)\n",
    "\n",
    "        ## Compile single frame graphs into stack for animation\n",
    "        print(f'Creating graph and glimpse image sequence ID: {acq_ID, ID}')\n",
    "        plots = list()\n",
    "        for fn in natsorted(glob.glob(os.path.join(glimpse_graph_seq_basedir, '*.tiff'))):\n",
    "            plot = imread(fn)\n",
    "            plots.append(plot)\n",
    "        plots = np.stack(plots, axis = 0)\n",
    "        ### create final fn\n",
    "        glimpse_graph_fn = os.path.join(basedir, f'glimpse_graph_{ID}.mp4')\n",
    "        ### initiate napari session for animation\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.add_image(plots)#, channel_axis = 0, colormap= ['green', 'magenta'], scale = scale\n",
    "        viewer.theme = 'light'\n",
    "        # viewer.scale_bar.visible = True\n",
    "        # viewer.scale_bar.unit = 'm'\n",
    "        # viewer.scale_bar.font_size = text_size\n",
    "        # viewer.text_overlay.visible = True\n",
    "        # viewer.text_overlay.color = 'black'\n",
    "        # viewer.text_overlay.position = 'bottom_left'\n",
    "        # viewer.text_overlay.font_size = text_size\n",
    "        # viewer.dims.events.current_step.connect(update_slider)\n",
    "        animation = Animation(viewer)\n",
    "        viewer.update_console({'animation': animation})\n",
    "        # # viewer.camera.center = (0, 0, 3024, 3024)\n",
    "        viewer.dims.current_step = (0, cam_coords[-2], cam_coords[-1])\n",
    "        # viewer.camera.zoom = 0.23\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        viewer.dims.current_step = (75.0,  cam_coords[-2], cam_coords[-1])\n",
    "        animation.capture_keyframe(steps = 100)\n",
    "        print(f'Saving graph and glimpse animation ID: {acq_ID, ID}')\n",
    "        animation.animate(glimpse_graph_fn, \n",
    "                          canvas_only=True,\n",
    "                          fps = 5,\n",
    "                          quality = 9)\n",
    "        viewer.close()\n",
    "        # plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa60332",
   "metadata": {},
   "source": [
    "# Check view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aefa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(viewer.scale_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overlay_font_size = 26\n",
    "scale_bar_font_size = 20\n",
    "label_font_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d75dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.camera.zoom = zoom*0.85\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(mask_glimpse_stack, scale = napari_scale, colormap='cyan')\n",
    "viewer.add_image(glimpse_stack, channel_axis = 0, colormap= ['green', 'magenta'], blending = 'additive', scale = napari_scale)\n",
    "viewer.theme = 'light'\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.scale_bar.unit = 'm'\n",
    "viewer.scale_bar.ticks = False\n",
    "viewer.scale_bar.font_size = scale_bar_font_size\n",
    "viewer.scale_bar.position = 'bottom_right'\n",
    "\n",
    "viewer.text_overlay.visible = True\n",
    "viewer.text_overlay.color = 'black'\n",
    "viewer.text_overlay.position = 'bottom_left'\n",
    "viewer.text_overlay.font_size = time_overlay_font_size\n",
    "viewer.dims.events.current_step.connect(update_slider)\n",
    "for config in zip(labels_list, offset_list, colour_list):\n",
    "    string, offset, colour = config\n",
    "    viewer.add_points(\n",
    "    label_points, \n",
    "    scale = [1, napari_scale[0], napari_scale[1]],\n",
    "    face_color = 'transparent', \n",
    "    edge_color = 'transparent', \n",
    "    text = {'string':string,\n",
    "            'anchor': 'upper_right',\n",
    "            'translation': offset,\n",
    "            'size': label_font_size,\n",
    "            'color': colour}, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d785ca",
   "metadata": {},
   "source": [
    "# Alternate way of compiling mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files = [os.path.join(root, f) for root, dirs, files in os.walk('/mnt/DATA/macrohet/results/glimpses/labelled/') for f in files if f.endswith('.mp4') and 'hq' not in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b357c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "for file in tqdm(mp4_files):\n",
    "    \n",
    "    # Split the file path into directory, filename, and extension\n",
    "    directory, filename_ext = os.path.split(file)\n",
    "    filename, ext = os.path.splitext(filename_ext)\n",
    "\n",
    "    # Extract the last numbers from the filename\n",
    "    last_numbers = \"\".join(filter(str.isdigit, filename))\n",
    "\n",
    "    # Build the new filename and file path\n",
    "    new_filename = f\"{last_numbers}_{filename.replace(last_numbers, '')}seq\"\n",
    "    new_path = os.path.join(directory, new_filename)   \n",
    "    \n",
    "    # Set the directory path containing the images\n",
    "    image_folder = new_path\n",
    "\n",
    "    # Set the output video file name\n",
    "    video_name = os.path.join(directory, f'hq_{filename}.mp4')\n",
    "    \n",
    "    if os.path.exists(video_name):\n",
    "        continue\n",
    "\n",
    "    # Set the frame rate of the output video\n",
    "    frame_rate = 3\n",
    "\n",
    "    # Get the list of images in the directory\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith('.tiff')]\n",
    "\n",
    "    # Sort the images in alphabetical order\n",
    "    images.sort()\n",
    "\n",
    "    # Get the first image to get the size of the video\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, channels = frame.shape\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(video_name, fourcc, frame_rate, (width, height))\n",
    "\n",
    "    # Loop through the images and add them to the video\n",
    "    for image in images:\n",
    "        img_path = os.path.join(image_folder, image)\n",
    "        frame = cv2.imread(img_path)\n",
    "\n",
    "        # Write the frame to the video\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    # Release the VideoWriter object\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory path containing the images\n",
    "image_folder = '/mnt/DATA/macrohet/results/glimpses/labelled/multi_plot/(3, 8)/300/300_glimpse_seq'\n",
    "\n",
    "# Set the output video file name\n",
    "video_name = '/mnt/DATA/macrohet/results/glimpses/labelled/multi_plot/(3, 8)/300/hq_glimpse_300.mp4'\n",
    "\n",
    "# Set the frame rate of the output video\n",
    "frame_rate = 3\n",
    "\n",
    "# Get the list of images in the directory\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith('.tiff')]\n",
    "\n",
    "# Sort the images in alphabetical order\n",
    "images.sort()\n",
    "\n",
    "# Get the first image to get the size of the video\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, channels = frame.shape\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(video_name, fourcc, frame_rate, (width, height))\n",
    "\n",
    "# Loop through the images and add them to the video\n",
    "for image in images:\n",
    "    img_path = os.path.join(image_folder, image)\n",
    "    frame = cv2.imread(img_path)\n",
    "\n",
    "    # Write the frame to the video\n",
    "    video_writer.write(frame)\n",
    "\n",
    "# Release the VideoWriter object\n",
    "video_writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "aero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
