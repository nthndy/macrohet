{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e295e0",
   "metadata": {},
   "source": [
    "# Segment, localise and track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bec1a4-27f1-4cd4-b841-81b1ee878e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45641d0-7da5-4c89-84a0-bcdf26987d96",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66424cf0-e941-4183-9bcc-71483d319215",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path('/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34459913-b69c-40a1-9cac-16c88ad93a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process images using zarr\n",
    "image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "zarr_store = zarr.open(image_dir, mode='r')\n",
    "images = zarr_store.images\n",
    "# create a max projection\n",
    "images = np.max(images, axis = 2)\n",
    "\n",
    "log_progress(acq_ID, \"Images loaded and stacked\")\n",
    "\n",
    "# check if already segmented using m2 model\n",
    "#     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}.h5')):\n",
    "#         continue\n",
    "#     else:\n",
    "log_progress(acq_ID, \"Starting segmentation\")\n",
    "\n",
    "#     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5')):\n",
    "\n",
    "# # Define the path for saving masks\n",
    "# output_file_path = os.path.join(base_dir, f'labels/{output_dirname}/{row, column}_cpv3_mask_backup.h5')\n",
    "\n",
    "# # Load existing masks\n",
    "# masks = load_masks(output_file_path)\n",
    "\n",
    "# # Check if the required number of masks are already present\n",
    "# if len(masks) < len(images):\n",
    "#     for i, frame in enumerate(tqdm(images[:, gfp_channel, ...], desc='Segmenting')):\n",
    "#         if i >= len(masks):\n",
    "#             mask = segment(frame, model)\n",
    "#             masks.append(mask)\n",
    "#             save_masks(output_file_path, np.array(masks), overwrite=True)\n",
    "#     log_progress(acq_ID, \"Finished segmentation\")\n",
    "# else:\n",
    "#     log_progress(acq_ID, f\"Skipped segmentation, found {len(masks)} masks\")\n",
    "\n",
    "\n",
    "# segment images from gfp channel only\n",
    "masks = np.stack([segment(frame) \n",
    "                  for frame in tqdm(images[:,gfp_channel,...],  # segmenting the GFP channel \n",
    "                                    desc = 'Segmenting')])\n",
    "\n",
    "log_progress(acq_ID, \"Finished segmentation\")\n",
    "\n",
    "with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}_cpv3_mask_backup.h5'), \n",
    "                                   'w', \n",
    "                                   obj_type='obj_type_1'\n",
    "                                   ) as writer:\n",
    "#             writer.write_objects(objects)\n",
    "        # writer.write_tracks(tracks)\n",
    "        writer.write_segmentation(masks)\n",
    "    \n",
    "log_progress(acq_ID, \"Saved out masks\")  \n",
    "\n",
    "log_progress(acq_ID, \"Measuring Mtb area\")       \n",
    "\n",
    "# characterise Mtb growth using Otsu segmentation\n",
    "# otsu_mtb = otsu_threshold(images[:,1,...]) # time consuming and non-deterministic when compared to hardcoded, could result in different thresholds for same image? \n",
    "# characterise Mtb growth using hardcoded threshold :S\n",
    "manual_mtb_thresh = np.where(images[:,mtb_channel,...] >= Mtb_load_thresh, True, False)\n",
    "log_progress(acq_ID, \"Creating intensity image for localisation\")  \n",
    "# reshape intensity image to be gfp, rfp on last axis for regionprops\n",
    "intensity_image = np.stack([images[:,0,...], \n",
    "                            images[:,1,...],  \n",
    "#                                 otsu_mtb, \n",
    "                            manual_mtb_thresh], axis = -1)\n",
    "log_progress(acq_ID, \"Localising objects\")  \n",
    "# localise objects\n",
    "objects = localise(masks, \n",
    "                   intensity_image, \n",
    "                   )\n",
    "log_progress(acq_ID, \"Filtering small objects\")  \n",
    "# filter out small objects\n",
    "objects = [o for o in objects if o.properties['area'] > segment_size_thresh]\n",
    "\n",
    "log_progress(acq_ID, \"Adding infection labels to objects\")  \n",
    "# add label for infection\n",
    "for obj in objects:\n",
    "    obj.properties = ({\"Infected\": True} \n",
    "                        if obj.properties['mean_intensity'][manual_mtb_thresh_channel] > 0 # index 2 for manual mtb channel \n",
    "                        else {\"Infected\": False})\n",
    "    obj.properties = ({\"Mtb area px\": obj.properties['mean_intensity'][manual_mtb_thresh_channel]*obj.properties['area']})\n",
    "\n",
    "with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/backup/{row, column}_cpv3_objects_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "                writer.write_objects(objects)\n",
    "                # writer.write_tracks(tracks)\n",
    "\n",
    "log_progress(acq_ID, \"Beginning tracking\")  \n",
    "# track on upscaled config fn\n",
    "tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "log_progress(acq_ID, \"Saving tracking\")  \n",
    "# save out \n",
    "with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/backup/{row, column}_cpv3_tracks_backup.h5'), \n",
    "                                   'w', \n",
    "                                   obj_type='obj_type_1'\n",
    "                                   ) as writer:\n",
    "#             writer.write_objects(objects)\n",
    "        writer.write_tracks(tracks)\n",
    "        # writer.write_segmentation(masks)\n",
    "# Log successful completion\n",
    "\n",
    "with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}.h5'), \n",
    "                                   'w', \n",
    "                                   obj_type='obj_type_1'\n",
    "                                   ) as writer:\n",
    "            writer.write_tracks(tracks)\n",
    "            writer.write_segmentation(masks)\n",
    "# Log successful completion\n",
    "log_progress(acq_ID, \"Processing completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5793a12-06e1-4825-a491-f30b3f5dcf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from macrohet import dataio, tile\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from cellpose import models\n",
    "import btrack \n",
    "import torch\n",
    "import os\n",
    "import dask.array as da\n",
    "import glob\n",
    "import zarr\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988f1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA RTX A6000\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellpose.core:** TORCH CUDA version installed and working. **\n",
      "INFO:cellpose.core:>>>> using GPU (CUDA)\n",
      "INFO:cellpose.models:>> cyto3 << model set to be used\n",
      "INFO:cellpose.models:>>>> loading model /home/dayn/.cellpose/models/cyto3\n",
      "INFO:cellpose.models:>>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "# # defining personal trained cellpose model to use\n",
    "model_path = 'models/segmentation_mdoel'\n",
    "model = models.CellposeModel(gpu=True, \n",
    "                             pretrained_model=model_path)\n",
    "\n",
    "# ORRRR test the new cellpose model\n",
    "# model = models.Cellpose(gpu=True, model_type='cyto3')\n",
    "\n",
    "# Initialize the logging configuration\n",
    "log_dir = \"logs\"  # Specify the directory where logs will be saved\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s]: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "logging.getLogger('cellpose').setLevel(logging.WARNING)\n",
    "\n",
    "# Add a FileHandler to save logs to a file in the specified directory\n",
    "log_file = os.path.join(log_dir, \"assay_processing.log\")\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s [%(levelname)s]: %(message)s\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(file_handler)\n",
    "\n",
    "# Define a function to log progress and potential errors\n",
    "def log_progress(position, message):\n",
    "    logging.info(f\"Position {position}: {message}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76982865",
   "metadata": {},
   "source": [
    "### Define functions to tidy up main block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65275f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds\n",
    "segment_size_thresh = 5000\n",
    "Mtb_load_thresh = 480\n",
    "\n",
    "# define tracking scale factor\n",
    "scale_factor = 1/5.04\n",
    "\n",
    "# define features to use for tracking \n",
    "features = [\n",
    "  \"area\",\n",
    "  \"major_axis_length\",\n",
    "  \"minor_axis_length\",\n",
    "  \"orientation\",\n",
    "  \"mean_intensity\",\n",
    "    ]\n",
    "\n",
    "# define tracker config fn to use, using a prob_not_assign = 0.1\n",
    "config_fn = 'models/tracking_model.json'\n",
    "\n",
    "def segment(frame, model = model, channels = [0,0], diameter = 350, #250 #325\n",
    "            min_size = 5000, model_type = 'pretrained'\n",
    "           ):\n",
    "    \n",
    "    if model_type == 'pretrained':\n",
    "        \n",
    "        masks, flows, styles, diams = model.eval(frame, # for default models\n",
    "                                                 channels = channels, \n",
    "                                                 diameter = diameter, \n",
    "                                                 min_size = min_size, \n",
    "                                                 )\n",
    "        \n",
    "        \n",
    "    else:\n",
    "\n",
    "        masks, flows, styles = model.eval(frame, # for personal model\n",
    "                                          channels = channels, \n",
    "                                          diameter = diameter, \n",
    "                                          min_size = min_size, \n",
    "                                          )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def localise(masks, intensity_image, properties=tuple(features), use_weighted_centroid = False):\n",
    "    \n",
    "    # localise objs in images\n",
    "    objects = btrack.utils.segmentation_to_objects(segmentation=masks,\n",
    "                                                   intensity_image=intensity_image, \n",
    "                                                   properties=properties,\n",
    "                                                   scale=(scale_factor,scale_factor),\n",
    "                                                   use_weighted_centroid=use_weighted_centroid, \n",
    "                                                   )\n",
    "                                                   \n",
    "    return objects\n",
    "\n",
    "\n",
    "def track(objects, masks, config_fn, search_radius = 20):\n",
    "\n",
    "    # initialise a tracker session using a context manager\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure(config_fn)\n",
    "        # set max search radius\n",
    "        tracker.max_search_radius = search_radius\n",
    "        # define tracking method\n",
    "        tracker.tracking_updates = [\"MOTION\", \"VISUAL\"]\n",
    "        # redefine features so that both channels are included in track measurements\n",
    "        tracker.features = list(objects[0].properties.keys())\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects)\n",
    "        # set the tracking volume\n",
    "        tracker.volume=((0, masks.shape[-2]*scale_factor), (0, masks.shape[-1]*scale_factor))\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=25)\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "        # store the tracks\n",
    "        tracks = tracker.tracks\n",
    "\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def save_masks(file_path, masks, overwrite=False):\n",
    "    with btrack.io.HDF5FileHandler(file_path, 'w', obj_type='obj_type_1') as writer:\n",
    "        writer.write_segmentation(masks)\n",
    "\n",
    "def load_masks(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with btrack.io.HDF5FileHandler(file_path, 'r') as reader:\n",
    "            return reader.segmentation\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751ef77",
   "metadata": {},
   "source": [
    "### Load experiment of choice\n",
    "\n",
    "The Opera Phenix is a high-throughput confocal microscope that acquires very large 5-dimensional (TCZXY) images over several fields of view in any one experiment. Therefore, a lazy-loading approach is chosen to mosaic, view and annotate these images. This approach depends upon Dask and DaskFusion. The first step is to load the main metadata file (typically called `Index.idx.xml` and located in the main `Images` directory) that contains the image filenames and associated TCXZY information used to organise the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d20db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bde85a92e64b439dd0d35180eb9a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>State</th>\n",
       "      <th>URL</th>\n",
       "      <th>Row</th>\n",
       "      <th>Col</th>\n",
       "      <th>FieldID</th>\n",
       "      <th>PlaneID</th>\n",
       "      <th>TimepointID</th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>FlimID</th>\n",
       "      <th>...</th>\n",
       "      <th>PositionZ</th>\n",
       "      <th>AbsPositionZ</th>\n",
       "      <th>MeasurementTimeOffset</th>\n",
       "      <th>AbsTime</th>\n",
       "      <th>MainExcitationWavelength</th>\n",
       "      <th>MainEmissionWavelength</th>\n",
       "      <th>ObjectiveMagnification</th>\n",
       "      <th>ObjectiveNA</th>\n",
       "      <th>ExposureTime</th>\n",
       "      <th>OrientationMatrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0303K1F1P1R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c03f01p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135257497</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-06T18:14:34.337+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0303K1F1P1R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c03f01p01-ch2sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135257497</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-06T18:14:34.57+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0303K1F1P2R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c03f01p02-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135259494</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-06T18:14:34.913+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0303K1F1P2R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c03f01p02-ch2sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135259494</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-06T18:14:35.133+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0303K1F1P3R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c03f01p03-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4E-06</td>\n",
       "      <td>0.135261506</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-10-06T18:14:35.477+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31093</th>\n",
       "      <td>0404K192F9P1R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r04c04f09p01-ch2sk192fk1fl1.tiff</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135189295</td>\n",
       "      <td>57306.39</td>\n",
       "      <td>2024-10-07T10:10:41.33+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31094</th>\n",
       "      <td>0404K192F9P2R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r04c04f09p02-ch1sk192fk1fl1.tiff</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135191306</td>\n",
       "      <td>57306.39</td>\n",
       "      <td>2024-10-07T10:10:41.677+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31095</th>\n",
       "      <td>0404K192F9P2R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r04c04f09p02-ch2sk192fk1fl1.tiff</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135191306</td>\n",
       "      <td>57306.39</td>\n",
       "      <td>2024-10-07T10:10:41.893+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31096</th>\n",
       "      <td>0404K192F9P3R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r04c04f09p03-ch1sk192fk1fl1.tiff</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4E-06</td>\n",
       "      <td>0.135193303</td>\n",
       "      <td>57306.39</td>\n",
       "      <td>2024-10-07T10:10:42.237+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31097</th>\n",
       "      <td>0404K192F9P3R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r04c04f09p03-ch2sk192fk1fl1.tiff</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4E-06</td>\n",
       "      <td>0.135193303</td>\n",
       "      <td>57306.39</td>\n",
       "      <td>2024-10-07T10:10:42.47+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31098 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id State                               URL Row Col FieldID  \\\n",
       "0        0303K1F1P1R1    Ok    r03c03f01p01-ch1sk1fk1fl1.tiff   3   3       1   \n",
       "1        0303K1F1P1R2    Ok    r03c03f01p01-ch2sk1fk1fl1.tiff   3   3       1   \n",
       "2        0303K1F1P2R1    Ok    r03c03f01p02-ch1sk1fk1fl1.tiff   3   3       1   \n",
       "3        0303K1F1P2R2    Ok    r03c03f01p02-ch2sk1fk1fl1.tiff   3   3       1   \n",
       "4        0303K1F1P3R1    Ok    r03c03f01p03-ch1sk1fk1fl1.tiff   3   3       1   \n",
       "...               ...   ...                               ...  ..  ..     ...   \n",
       "31093  0404K192F9P1R2    Ok  r04c04f09p01-ch2sk192fk1fl1.tiff   4   4       9   \n",
       "31094  0404K192F9P2R1    Ok  r04c04f09p02-ch1sk192fk1fl1.tiff   4   4       9   \n",
       "31095  0404K192F9P2R2    Ok  r04c04f09p02-ch2sk192fk1fl1.tiff   4   4       9   \n",
       "31096  0404K192F9P3R1    Ok  r04c04f09p03-ch1sk192fk1fl1.tiff   4   4       9   \n",
       "31097  0404K192F9P3R2    Ok  r04c04f09p03-ch2sk192fk1fl1.tiff   4   4       9   \n",
       "\n",
       "      PlaneID TimepointID ChannelID FlimID  ... PositionZ AbsPositionZ  \\\n",
       "0           1           0         1      1  ...         0  0.135257497   \n",
       "1           1           0         2      1  ...         0  0.135257497   \n",
       "2           2           0         1      1  ...     2E-06  0.135259494   \n",
       "3           2           0         2      1  ...     2E-06  0.135259494   \n",
       "4           3           0         1      1  ...     4E-06  0.135261506   \n",
       "...       ...         ...       ...    ...  ...       ...          ...   \n",
       "31093       1         191         2      1  ...         0  0.135189295   \n",
       "31094       2         191         1      1  ...     2E-06  0.135191306   \n",
       "31095       2         191         2      1  ...     2E-06  0.135191306   \n",
       "31096       3         191         1      1  ...     4E-06  0.135193303   \n",
       "31097       3         191         2      1  ...     4E-06  0.135193303   \n",
       "\n",
       "      MeasurementTimeOffset                        AbsTime  \\\n",
       "0                         0  2024-10-06T18:14:34.337+01:00   \n",
       "1                         0   2024-10-06T18:14:34.57+01:00   \n",
       "2                         0  2024-10-06T18:14:34.913+01:00   \n",
       "3                         0  2024-10-06T18:14:35.133+01:00   \n",
       "4                         0  2024-10-06T18:14:35.477+01:00   \n",
       "...                     ...                            ...   \n",
       "31093              57306.39   2024-10-07T10:10:41.33+01:00   \n",
       "31094              57306.39  2024-10-07T10:10:41.677+01:00   \n",
       "31095              57306.39  2024-10-07T10:10:41.893+01:00   \n",
       "31096              57306.39  2024-10-07T10:10:42.237+01:00   \n",
       "31097              57306.39   2024-10-07T10:10:42.47+01:00   \n",
       "\n",
       "      MainExcitationWavelength MainEmissionWavelength ObjectiveMagnification  \\\n",
       "0                          640                    706                     40   \n",
       "1                          488                    522                     40   \n",
       "2                          640                    706                     40   \n",
       "3                          488                    522                     40   \n",
       "4                          640                    706                     40   \n",
       "...                        ...                    ...                    ...   \n",
       "31093                      488                    522                     40   \n",
       "31094                      640                    706                     40   \n",
       "31095                      488                    522                     40   \n",
       "31096                      640                    706                     40   \n",
       "31097                      488                    522                     40   \n",
       "\n",
       "      ObjectiveNA ExposureTime  \\\n",
       "0             1.1          0.2   \n",
       "1             1.1          0.1   \n",
       "2             1.1          0.2   \n",
       "3             1.1          0.1   \n",
       "4             1.1          0.2   \n",
       "...           ...          ...   \n",
       "31093         1.1          0.1   \n",
       "31094         1.1          0.2   \n",
       "31095         1.1          0.1   \n",
       "31096         1.1          0.2   \n",
       "31097         1.1          0.1   \n",
       "\n",
       "                                       OrientationMatrix  \n",
       "0      [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "1      [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "2      [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "3      [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "4      [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "...                                                  ...  \n",
       "31093  [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "31094  [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "31095  [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "31096  [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "31097  [[0.999498,0,0,-8.1],[0,-0.999498,0,-1.0],[0,0...  \n",
       "\n",
       "[31098 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '/mnt/SYNO/macrohet_syno/data/ND0005/'\n",
    "metadata_fn = os.path.join(base_dir, 'acquisition/Images/Index.idx.xml')\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739b419",
   "metadata": {},
   "source": [
    "### View assay layout and mask information (optional)\n",
    "\n",
    "The Opera Phenix acquires many time lapse series from a range of positions. The first step is to inspect the image metadata, presented in the form of an `Assaylayout/experiment_ID.xml` file, to show which positions correspond to which experimental assays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c540d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n",
      "Extracting metadata complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>ConcentrationEC</th>\n",
       "      <th>Replicate #</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>UNI</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNI</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">4</th>\n",
       "      <th>3</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">5</th>\n",
       "      <th>3</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">6</th>\n",
       "      <th>3</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Strain Compound Concentration ConcentrationEC  Replicate #\n",
       "Row Column                                                           \n",
       "3   1         UNI     CTRL             0             EC0            1\n",
       "    2         UNI     CTRL             0             EC0            2\n",
       "    3          WT     CTRL             0             EC0            1\n",
       "    4          WT     CTRL             0             EC0            2\n",
       "    5          WT      PZA            60            EC50            1\n",
       "    6          WT      PZA            60            EC50            2\n",
       "    7          WT      RIF           0.1            EC50            1\n",
       "    8          WT      RIF           0.1            EC50            2\n",
       "    9          WT      INH          0.04            EC50            1\n",
       "    10         WT      INH          0.04            EC50            2\n",
       "    11         WT      BDQ          0.02            EC50            1\n",
       "    12         WT      BDQ          0.02            EC50            2\n",
       "4   3          WT     CTRL             0             EC0            3\n",
       "    4          WT     CTRL             0             EC0            4\n",
       "    5          WT      PZA           400            EC99            1\n",
       "    6          WT      PZA           400            EC99            2\n",
       "    7          WT      RIF             2            EC99            1\n",
       "    8          WT      RIF             2            EC99            2\n",
       "    9          WT      INH             2            EC99            1\n",
       "    10         WT      INH             2            EC99            2\n",
       "    11         WT      BDQ           2.5            EC99            1\n",
       "    12         WT      BDQ           2.5            EC99            2\n",
       "5   3         RD1     CTRL             0             EC0            1\n",
       "    4         RD1     CTRL             0             EC0            2\n",
       "    5         RD1      PZA            60            EC50            1\n",
       "    6         RD1      PZA            60            EC50            2\n",
       "    7         RD1      RIF           0.1            EC50            1\n",
       "    8         RD1      RIF           0.1            EC50            2\n",
       "    9         RD1      INH          0.04            EC50            1\n",
       "    10        RD1      INH          0.04            EC50            2\n",
       "    11        RD1      BDQ          0.02            EC50            1\n",
       "    12        RD1      BDQ          0.02            EC50            2\n",
       "6   3         RD1     CTRL             0             EC0            3\n",
       "    4         RD1     CTRL             0             EC0            4\n",
       "    5         RD1      PZA           400            EC99            1\n",
       "    6         RD1      PZA           400            EC99            2\n",
       "    7         RD1      RIF             2            EC99            1\n",
       "    8         RD1      RIF             2            EC99            2\n",
       "    9         RD1      INH             2            EC99            1\n",
       "    10        RD1      INH             2            EC99            2\n",
       "    11        RD1      BDQ           2.5            EC99            1\n",
       "    12        RD1      BDQ           2.5            EC99            2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "assay_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45221981",
   "metadata": {},
   "source": [
    "# Segment, localise and track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451353a1-ce0a-46d6-aef0-377f9c3a017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_channel = 0\n",
    "gfp_channel = 1\n",
    "manual_mtb_thresh_channel = 2\n",
    "output_dirname = 'cpv3' #'cpv3_smaller_diam' #'cpv3'\n",
    "# make output directory and subdirs \n",
    "os.makedirs(os.path.join(base_dir, f'labels/{output_dirname}/backup'), exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d746c3b-a9b8-49a7-9f80-81501d8ef9a5",
   "metadata": {},
   "source": [
    "# Iterate over all positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7290f4e4-3031-418e-aa6d-ef532d0a2af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a54d0e05de242d2b5f029ea44413e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress through positions:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Position (3, 1): Starting new acquisition\n",
      "INFO:root:Position (3, 1): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 2): Starting new acquisition\n",
      "INFO:root:Position (3, 2): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 3): Starting new acquisition\n",
      "INFO:root:Position (3, 3): Skipping already processed\n",
      "INFO:root:Position (3, 4): Starting new acquisition\n",
      "INFO:root:Position (3, 4): Skipping already processed\n",
      "INFO:root:Position (3, 5): Starting new acquisition\n",
      "INFO:root:Position (3, 5): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 6): Starting new acquisition\n",
      "INFO:root:Position (3, 6): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 7): Starting new acquisition\n",
      "INFO:root:Position (3, 7): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 8): Starting new acquisition\n",
      "INFO:root:Position (3, 8): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 9): Starting new acquisition\n",
      "INFO:root:Position (3, 9): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 10): Starting new acquisition\n",
      "INFO:root:Position (3, 10): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 11): Starting new acquisition\n",
      "INFO:root:Position (3, 11): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (3, 12): Starting new acquisition\n",
      "INFO:root:Position (3, 12): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 3): Starting new acquisition\n",
      "INFO:root:Position (4, 3): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 4): Starting new acquisition\n",
      "INFO:root:Position (4, 4): Images loaded and stacked\n",
      "INFO:root:Position (4, 4): Starting segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9dd342de54431682b8b19e0a6bd26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Segmenting:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Position (4, 4): Finished segmentation\n",
      "[INFO][2024/10/22 01:21:22 PM] Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4)_cpv3_mask_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4)_cpv3_mask_backup.h5...\n",
      "[INFO][2024/10/22 01:22:56 PM] Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4)_cpv3_mask_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4)_cpv3_mask_backup.h5\n",
      "INFO:root:Position (4, 4): Saved out masks\n",
      "INFO:root:Position (4, 4): Measuring Mtb area\n",
      "INFO:root:Position (4, 4): Creating intensity image for localisation\n",
      "INFO:root:Position (4, 4): Localising objects\n",
      "[INFO][2024/10/22 01:23:30 PM] Localizing objects from segmentation...\n",
      "INFO:btrack.io._localization:Localizing objects from segmentation...\n",
      "[WARNING][2024/10/22 01:23:30 PM] Multichannel intensity image detected, using unweighted centroid.\n",
      "WARNING:btrack.io._localization:Multichannel intensity image detected, using unweighted centroid.\n",
      "progress: 100%|██████████████████████████████████████████████████████████████████████| 192/192 [08:50<00:00,  2.76s/it]\n",
      "[INFO][2024/10/22 01:32:20 PM] Objects are of type: <class 'dict'>\n",
      "INFO:btrack.io.utils:Objects are of type: <class 'dict'>\n",
      "[INFO][2024/10/22 01:32:21 PM] ...Found 79043 objects in 192 frames.\n",
      "INFO:btrack.io._localization:...Found 79043 objects in 192 frames.\n",
      "INFO:root:Position (4, 4): Filtering small objects\n",
      "INFO:root:Position (4, 4): Adding infection labels to objects\n",
      "[INFO][2024/10/22 01:32:21 PM] Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_objects_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_objects_backup.h5...\n",
      "[INFO][2024/10/22 01:32:22 PM] Writing objects/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing objects/obj_type_1\n",
      "[INFO][2024/10/22 01:32:22 PM] Writing labels/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing labels/obj_type_1\n",
      "[INFO][2024/10/22 01:32:22 PM] Loading objects/obj_type_1 (70967, 5) (70967 filtered: None)\n",
      "INFO:btrack.io.hdf:Loading objects/obj_type_1 (70967, 5) (70967 filtered: None)\n",
      "[INFO][2024/10/22 01:32:23 PM] Writing properties/obj_type_1/area (70967,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/area (70967,)\n",
      "[INFO][2024/10/22 01:32:23 PM] Writing properties/obj_type_1/major_axis_length (70967,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/major_axis_length (70967,)\n",
      "[INFO][2024/10/22 01:32:23 PM] Writing properties/obj_type_1/minor_axis_length (70967,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/minor_axis_length (70967,)\n",
      "[INFO][2024/10/22 01:32:23 PM] Writing properties/obj_type_1/orientation (70967,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/orientation (70967,)\n",
      "[INFO][2024/10/22 01:32:23 PM] Writing properties/obj_type_1/mean_intensity (70967, 3)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/mean_intensity (70967, 3)\n",
      "[INFO][2024/10/22 01:32:23 PM] Writing properties/obj_type_1/Infected (70967,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/Infected (70967,)\n",
      "[INFO][2024/10/22 01:32:23 PM] Writing properties/obj_type_1/Mtb area px (70967,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/Mtb area px (70967,)\n",
      "[INFO][2024/10/22 01:32:23 PM] Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_objects_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_objects_backup.h5\n",
      "INFO:root:Position (4, 4): Beginning tracking\n",
      "[INFO][2024/10/22 01:32:23 PM] Loaded btrack: /home/dayn/analysis/btrack/btrack/libs/libtracker.so\n",
      "INFO:btrack.libwrapper:Loaded btrack: /home/dayn/analysis/btrack/btrack/libs/libtracker.so\n",
      "[INFO][2024/10/22 01:32:23 PM] Starting BayesianTracker session\n",
      "INFO:btrack.core:Starting BayesianTracker session\n",
      "[INFO][2024/10/22 01:32:23 PM] Loading configuration file: /home/dayn/analysis/models/btrack/particle_config_pnassign.json\n",
      "INFO:btrack.config:Loading configuration file: /home/dayn/analysis/models/btrack/particle_config_pnassign.json\n",
      "[INFO][2024/10/22 01:32:23 PM] Objects are of type: <class 'list'>\n",
      "INFO:btrack.io.utils:Objects are of type: <class 'list'>\n",
      "[INFO][2024/10/22 01:32:25 PM] Starting tracking... \n",
      "INFO:btrack.core:Starting tracking... \n",
      "[INFO][2024/10/22 01:32:25 PM] Update using: ['VISUAL', 'MOTION']\n",
      "INFO:btrack.core:Update using: ['VISUAL', 'MOTION']\n",
      "[INFO][2024/10/22 01:32:25 PM] Tracking objects in frames 0 to 24 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 0 to 24 (of 192)...\n",
      "[INFO][2024/10/22 01:32:29 PM]  - Timing (Bayesian updates: 43.86ms, Linking: 2.41ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 43.86ms, Linking: 2.41ms)\n",
      "[INFO][2024/10/22 01:32:29 PM]  - Probabilities (Link: 1.00000, Lost: 0.97890)\n",
      "INFO:btrack.utils: - Probabilities (Link: 1.00000, Lost: 0.97890)\n",
      "[INFO][2024/10/22 01:32:29 PM]  - Stats (Active: 644, Lost: 2587, Conflicts resolved: 3417)\n",
      "INFO:btrack.utils: - Stats (Active: 644, Lost: 2587, Conflicts resolved: 3417)\n",
      "[INFO][2024/10/22 01:32:29 PM] Tracking objects in frames 25 to 49 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 25 to 49 (of 192)...\n",
      "[INFO][2024/10/22 01:32:33 PM]  - Timing (Bayesian updates: 49.27ms, Linking: 2.41ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 49.27ms, Linking: 2.41ms)\n",
      "[INFO][2024/10/22 01:32:33 PM]  - Probabilities (Link: 0.99996, Lost: 0.99188)\n",
      "INFO:btrack.utils: - Probabilities (Link: 0.99996, Lost: 0.99188)\n",
      "[INFO][2024/10/22 01:32:33 PM]  - Stats (Active: 667, Lost: 5108, Conflicts resolved: 6926)\n",
      "INFO:btrack.utils: - Stats (Active: 667, Lost: 5108, Conflicts resolved: 6926)\n",
      "[INFO][2024/10/22 01:32:33 PM] Tracking objects in frames 50 to 74 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 50 to 74 (of 192)...\n",
      "[INFO][2024/10/22 01:32:37 PM]  - Timing (Bayesian updates: 54.49ms, Linking: 2.78ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 54.49ms, Linking: 2.78ms)\n",
      "[INFO][2024/10/22 01:32:37 PM]  - Probabilities (Link: 0.99157, Lost: 0.99027)\n",
      "INFO:btrack.utils: - Probabilities (Link: 0.99157, Lost: 0.99027)\n",
      "[INFO][2024/10/22 01:32:37 PM]  - Stats (Active: 606, Lost: 7541, Conflicts resolved: 10291)\n",
      "INFO:btrack.utils: - Stats (Active: 606, Lost: 7541, Conflicts resolved: 10291)\n",
      "[INFO][2024/10/22 01:32:37 PM] Tracking objects in frames 75 to 99 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 75 to 99 (of 192)...\n",
      "[INFO][2024/10/22 01:32:40 PM]  - Timing (Bayesian updates: 41.72ms, Linking: 2.32ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 41.72ms, Linking: 2.32ms)\n",
      "[INFO][2024/10/22 01:32:40 PM]  - Probabilities (Link: 1.00000, Lost: 0.99997)\n",
      "INFO:btrack.utils: - Probabilities (Link: 1.00000, Lost: 0.99997)\n",
      "[INFO][2024/10/22 01:32:40 PM]  - Stats (Active: 618, Lost: 10035, Conflicts resolved: 13589)\n",
      "INFO:btrack.utils: - Stats (Active: 618, Lost: 10035, Conflicts resolved: 13589)\n",
      "[INFO][2024/10/22 01:32:40 PM] Tracking objects in frames 100 to 124 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 100 to 124 (of 192)...\n",
      "[INFO][2024/10/22 01:32:44 PM]  - Timing (Bayesian updates: 49.87ms, Linking: 2.90ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 49.87ms, Linking: 2.90ms)\n",
      "[INFO][2024/10/22 01:32:44 PM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "INFO:btrack.utils: - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2024/10/22 01:32:44 PM]  - Stats (Active: 577, Lost: 12472, Conflicts resolved: 16783)\n",
      "INFO:btrack.utils: - Stats (Active: 577, Lost: 12472, Conflicts resolved: 16783)\n",
      "[INFO][2024/10/22 01:32:44 PM] Tracking objects in frames 125 to 149 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 125 to 149 (of 192)...\n",
      "[INFO][2024/10/22 01:32:48 PM]  - Timing (Bayesian updates: 37.77ms, Linking: 2.26ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 37.77ms, Linking: 2.26ms)\n",
      "[INFO][2024/10/22 01:32:48 PM]  - Probabilities (Link: 0.94280, Lost: 1.00000)\n",
      "INFO:btrack.utils: - Probabilities (Link: 0.94280, Lost: 1.00000)\n",
      "[INFO][2024/10/22 01:32:48 PM]  - Stats (Active: 574, Lost: 14851, Conflicts resolved: 19851)\n",
      "INFO:btrack.utils: - Stats (Active: 574, Lost: 14851, Conflicts resolved: 19851)\n",
      "[INFO][2024/10/22 01:32:48 PM] Tracking objects in frames 150 to 174 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 150 to 174 (of 192)...\n",
      "[INFO][2024/10/22 01:32:51 PM]  - Timing (Bayesian updates: 49.43ms, Linking: 2.76ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 49.43ms, Linking: 2.76ms)\n",
      "[INFO][2024/10/22 01:32:52 PM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "INFO:btrack.utils: - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2024/10/22 01:32:52 PM]  - Stats (Active: 580, Lost: 17175, Conflicts resolved: 23072)\n",
      "INFO:btrack.utils: - Stats (Active: 580, Lost: 17175, Conflicts resolved: 23072)\n",
      "[INFO][2024/10/22 01:32:52 PM] Tracking objects in frames 175 to 192 (of 192)...\n",
      "INFO:btrack.core:Tracking objects in frames 175 to 192 (of 192)...\n",
      "[INFO][2024/10/22 01:32:54 PM]  - Timing (Bayesian updates: 45.65ms, Linking: 2.87ms)\n",
      "INFO:btrack.utils: - Timing (Bayesian updates: 45.65ms, Linking: 2.87ms)\n",
      "[INFO][2024/10/22 01:32:54 PM]  - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "INFO:btrack.utils: - Probabilities (Link: 1.00000, Lost: 1.00000)\n",
      "[INFO][2024/10/22 01:32:54 PM] SUCCESS.\n",
      "INFO:btrack.core:SUCCESS.\n",
      "[INFO][2024/10/22 01:32:54 PM]  - Found 7490 tracks in 192 frames (in 0.0s)\n",
      "INFO:btrack.core: - Found 7490 tracks in 192 frames (in 0.0s)\n",
      "[INFO][2024/10/22 01:32:54 PM]  - Inserted 17712 dummy objects to fill tracking gaps\n",
      "INFO:btrack.core: - Inserted 17712 dummy objects to fill tracking gaps\n",
      "[INFO][2024/10/22 01:32:54 PM] Loading hypothesis model: particle_hypothesis\n",
      "INFO:btrack.core:Loading hypothesis model: particle_hypothesis\n",
      "[INFO][2024/10/22 01:32:54 PM] Calculating hypotheses (relax: True)...\n",
      "INFO:btrack.core:Calculating hypotheses (relax: True)...\n",
      "[INFO][2024/10/22 01:32:54 PM] Setting up constraints matrix for global optimisation...\n",
      "INFO:btrack.optimise.optimiser:Setting up constraints matrix for global optimisation...\n",
      "[INFO][2024/10/22 01:32:54 PM] Optimizing...\n",
      "INFO:btrack.optimise.optimiser:Optimizing...\n",
      "[INFO][2024/10/22 01:32:59 PM] Optimization complete. (Solution: optimal)\n",
      "INFO:btrack.optimise.optimiser:Optimization complete. (Solution: optimal)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.FALSE_POSITIVE: 2737 (of 7490)\n",
      "INFO:btrack.core: - Fates.FALSE_POSITIVE: 2737 (of 7490)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.LINK: 1880 (of 2845)\n",
      "INFO:btrack.core: - Fates.LINK: 1880 (of 2845)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.INITIALIZE_BORDER: 298 (of 654)\n",
      "INFO:btrack.core: - Fates.INITIALIZE_BORDER: 298 (of 654)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.INITIALIZE_FRONT: 425 (of 595)\n",
      "INFO:btrack.core: - Fates.INITIALIZE_FRONT: 425 (of 595)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.INITIALIZE_LAZY: 2150 (of 6241)\n",
      "INFO:btrack.core: - Fates.INITIALIZE_LAZY: 2150 (of 6241)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.TERMINATE_BORDER: 292 (of 649)\n",
      "INFO:btrack.core: - Fates.TERMINATE_BORDER: 292 (of 649)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.TERMINATE_BACK: 412 (of 549)\n",
      "INFO:btrack.core: - Fates.TERMINATE_BACK: 412 (of 549)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - Fates.TERMINATE_LAZY: 2169 (of 6292)\n",
      "INFO:btrack.core: - Fates.TERMINATE_LAZY: 2169 (of 6292)\n",
      "[INFO][2024/10/22 01:32:59 PM]  - TOTAL: 25315 hypotheses\n",
      "INFO:btrack.core: - TOTAL: 25315 hypotheses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer 5.0\n",
      "29960 rows, 25315 columns, 35650 non-zeros\n",
      "25315 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "14980 rows, 25315 columns, 35650 non-zeros\n",
      "25315 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 14980\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "14980 rows, 25315 columns, 35650 non-zeros\n",
      "*     0: obj =   8.889736243e+04 inf =   0.000e+00 (6439)\n",
      "Perturbing LP to avoid stalling [2531]...\n",
      "Removing LP perturbation [6523]...\n",
      "*  6523: obj =   4.725548782e+04 inf =   0.000e+00 (0) 1\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+  6523: mip =     not found yet >=              -inf        (1; 0)\n",
      "+  6523: >>>>>   4.725548782e+04 >=   4.725548782e+04   0.0% (1; 0)\n",
      "+  6523: mip =   4.725548782e+04 >=     tree is empty   0.0% (0; 1)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024/10/22 01:32:59 PM] Completed optimization with 5610 tracks\n",
      "INFO:btrack.core:Completed optimization with 5610 tracks\n",
      "[INFO][2024/10/22 01:32:59 PM] Ending BayesianTracker session\n",
      "INFO:btrack.core:Ending BayesianTracker session\n",
      "INFO:root:Position (4, 4): Saving tracking\n",
      "[INFO][2024/10/22 01:32:59 PM] Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_tracks_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_tracks_backup.h5...\n",
      "[INFO][2024/10/22 01:33:00 PM] Writing objects/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing objects/obj_type_1\n",
      "[INFO][2024/10/22 01:33:00 PM] Writing labels/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing labels/obj_type_1\n",
      "[INFO][2024/10/22 01:33:00 PM] Loading objects/obj_type_1 (63358, 5) (63358 filtered: None)\n",
      "INFO:btrack.io.hdf:Loading objects/obj_type_1 (63358, 5) (63358 filtered: None)\n",
      "[INFO][2024/10/22 01:33:01 PM] Writing properties/obj_type_1/area (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/area (63358,)\n",
      "[INFO][2024/10/22 01:33:01 PM] Writing properties/obj_type_1/major_axis_length (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/major_axis_length (63358,)\n",
      "[INFO][2024/10/22 01:33:01 PM] Writing properties/obj_type_1/minor_axis_length (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/minor_axis_length (63358,)\n",
      "[INFO][2024/10/22 01:33:01 PM] Writing properties/obj_type_1/orientation (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/orientation (63358,)\n",
      "[INFO][2024/10/22 01:33:01 PM] Writing properties/obj_type_1/mean_intensity (63358, 3)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/mean_intensity (63358, 3)\n",
      "[INFO][2024/10/22 01:33:02 PM] Writing properties/obj_type_1/Infected (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/Infected (63358,)\n",
      "[INFO][2024/10/22 01:33:02 PM] Writing properties/obj_type_1/Mtb area px (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/Mtb area px (63358,)\n",
      "[INFO][2024/10/22 01:33:02 PM] Writing tracks/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing tracks/obj_type_1\n",
      "[INFO][2024/10/22 01:33:02 PM] Writing dummies/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing dummies/obj_type_1\n",
      "[INFO][2024/10/22 01:33:02 PM] Writing LBEP/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing LBEP/obj_type_1\n",
      "[INFO][2024/10/22 01:33:02 PM] Writing fates/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing fates/obj_type_1\n",
      "[INFO][2024/10/22 01:33:02 PM] Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_tracks_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/backup/(4, 4)_cpv3_tracks_backup.h5\n",
      "[INFO][2024/10/22 01:33:02 PM] Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4).h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4).h5...\n",
      "[INFO][2024/10/22 01:33:03 PM] Writing objects/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing objects/obj_type_1\n",
      "[INFO][2024/10/22 01:33:03 PM] Writing labels/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing labels/obj_type_1\n",
      "[INFO][2024/10/22 01:33:03 PM] Loading objects/obj_type_1 (63358, 5) (63358 filtered: None)\n",
      "INFO:btrack.io.hdf:Loading objects/obj_type_1 (63358, 5) (63358 filtered: None)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing properties/obj_type_1/area (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/area (63358,)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing properties/obj_type_1/major_axis_length (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/major_axis_length (63358,)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing properties/obj_type_1/minor_axis_length (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/minor_axis_length (63358,)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing properties/obj_type_1/orientation (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/orientation (63358,)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing properties/obj_type_1/mean_intensity (63358, 3)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/mean_intensity (63358, 3)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing properties/obj_type_1/Infected (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/Infected (63358,)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing properties/obj_type_1/Mtb area px (63358,)\n",
      "INFO:btrack.io.hdf:Writing properties/obj_type_1/Mtb area px (63358,)\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing tracks/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing tracks/obj_type_1\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing dummies/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing dummies/obj_type_1\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing LBEP/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing LBEP/obj_type_1\n",
      "[INFO][2024/10/22 01:33:04 PM] Writing fates/obj_type_1\n",
      "INFO:btrack.io.hdf:Writing fates/obj_type_1\n",
      "[INFO][2024/10/22 01:34:36 PM] Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4).h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0005/labels/cpv3/(4, 4).h5\n",
      "INFO:root:Position (4, 4): Processing completed successfully\n",
      "INFO:root:Position (4, 5): Starting new acquisition\n",
      "INFO:root:Position (4, 5): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 6): Starting new acquisition\n",
      "INFO:root:Position (4, 6): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 7): Starting new acquisition\n",
      "INFO:root:Position (4, 7): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 8): Starting new acquisition\n",
      "INFO:root:Position (4, 8): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 9): Starting new acquisition\n",
      "INFO:root:Position (4, 9): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 10): Starting new acquisition\n",
      "INFO:root:Position (4, 10): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 11): Starting new acquisition\n",
      "INFO:root:Position (4, 11): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (4, 12): Starting new acquisition\n",
      "INFO:root:Position (4, 12): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 3): Starting new acquisition\n",
      "INFO:root:Position (5, 3): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 4): Starting new acquisition\n",
      "INFO:root:Position (5, 4): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 5): Starting new acquisition\n",
      "INFO:root:Position (5, 5): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 6): Starting new acquisition\n",
      "INFO:root:Position (5, 6): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 7): Starting new acquisition\n",
      "INFO:root:Position (5, 7): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 8): Starting new acquisition\n",
      "INFO:root:Position (5, 8): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 9): Starting new acquisition\n",
      "INFO:root:Position (5, 9): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 10): Starting new acquisition\n",
      "INFO:root:Position (5, 10): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 11): Starting new acquisition\n",
      "INFO:root:Position (5, 11): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (5, 12): Starting new acquisition\n",
      "INFO:root:Position (5, 12): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 3): Starting new acquisition\n",
      "INFO:root:Position (6, 3): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 4): Starting new acquisition\n",
      "INFO:root:Position (6, 4): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 5): Starting new acquisition\n",
      "INFO:root:Position (6, 5): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 6): Starting new acquisition\n",
      "INFO:root:Position (6, 6): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 7): Starting new acquisition\n",
      "INFO:root:Position (6, 7): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 8): Starting new acquisition\n",
      "INFO:root:Position (6, 8): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 9): Starting new acquisition\n",
      "INFO:root:Position (6, 9): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 10): Starting new acquisition\n",
      "INFO:root:Position (6, 10): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 11): Starting new acquisition\n",
      "INFO:root:Position (6, 11): Processing failed: nothing found at path ''\n",
      "INFO:root:Position (6, 12): Starting new acquisition\n",
      "INFO:root:Position (6, 12): Processing failed: nothing found at path ''\n",
      "INFO:root:Processing completed\n"
     ]
    }
   ],
   "source": [
    "# Inside your loop, use the log_progress function to log progress and errors\n",
    "for (row, column), info in tqdm(assay_layout.iterrows(), desc='Progress through positions', total=len(assay_layout)):\n",
    "    try:\n",
    "        acq_ID = (row, column)\n",
    "        log_progress(acq_ID, \"Starting new acquisition\")\n",
    "        \n",
    "        # if info['Strain'] == 'UNI':\n",
    "        #     log_progress(acq_ID, \"Skipping uninfected acquisition for now\")\n",
    "        #     continue\n",
    "        # if acq_ID in already_processed_acq_IDs:\n",
    "        #     log_progress(acq_ID, \"Skipping already processed\")\n",
    "        #     continue\n",
    "        if os.path.exists(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}.h5')):\n",
    "            log_progress(acq_ID, \"Skipping already processed\")\n",
    "            continue\n",
    "\n",
    "        # process images using zarr\n",
    "        image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "        zarr_store = zarr.open(image_dir, mode='r')\n",
    "        images = zarr_store.images\n",
    "        # create a max projection\n",
    "        images = np.max(images, axis = 2)\n",
    "        \n",
    "        log_progress(acq_ID, \"Images loaded and stacked\")\n",
    "        \n",
    "        # check if already segmented using m2 model\n",
    "        #     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}.h5')):\n",
    "        #         continue\n",
    "        #     else:\n",
    "        log_progress(acq_ID, \"Starting segmentation\")\n",
    "        \n",
    "        #     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5')):\n",
    "\n",
    "        # # Define the path for saving masks\n",
    "        # output_file_path = os.path.join(base_dir, f'labels/{output_dirname}/{row, column}_cpv3_mask_backup.h5')\n",
    "        \n",
    "        # # Load existing masks\n",
    "        # masks = load_masks(output_file_path)\n",
    "        \n",
    "        # # Check if the required number of masks are already present\n",
    "        # if len(masks) < len(images):\n",
    "        #     for i, frame in enumerate(tqdm(images[:, gfp_channel, ...], desc='Segmenting')):\n",
    "        #         if i >= len(masks):\n",
    "        #             mask = segment(frame, model)\n",
    "        #             masks.append(mask)\n",
    "        #             save_masks(output_file_path, np.array(masks), overwrite=True)\n",
    "        #     log_progress(acq_ID, \"Finished segmentation\")\n",
    "        # else:\n",
    "        #     log_progress(acq_ID, f\"Skipped segmentation, found {len(masks)} masks\")\n",
    "\n",
    "        \n",
    "        # segment images from gfp channel only\n",
    "        masks = np.stack([segment(frame) \n",
    "                          for frame in tqdm(images[:,gfp_channel,...],  # segmenting the GFP channel \n",
    "                                            desc = 'Segmenting')])\n",
    "        \n",
    "        log_progress(acq_ID, \"Finished segmentation\")\n",
    "        \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}_cpv3_mask_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "        #             writer.write_objects(objects)\n",
    "                # writer.write_tracks(tracks)\n",
    "                writer.write_segmentation(masks)\n",
    "            \n",
    "        log_progress(acq_ID, \"Saved out masks\")  \n",
    "        \n",
    "        log_progress(acq_ID, \"Measuring Mtb area\")       \n",
    "        \n",
    "        # characterise Mtb growth using Otsu segmentation\n",
    "        # otsu_mtb = otsu_threshold(images[:,1,...]) # time consuming and non-deterministic when compared to hardcoded, could result in different thresholds for same image? \n",
    "        # characterise Mtb growth using hardcoded threshold :S\n",
    "        manual_mtb_thresh = np.where(images[:,mtb_channel,...] >= Mtb_load_thresh, True, False)\n",
    "        log_progress(acq_ID, \"Creating intensity image for localisation\")  \n",
    "        # reshape intensity image to be gfp, rfp on last axis for regionprops\n",
    "        intensity_image = np.stack([images[:,0,...], \n",
    "                                    images[:,1,...],  \n",
    "        #                                 otsu_mtb, \n",
    "                                    manual_mtb_thresh], axis = -1)\n",
    "        log_progress(acq_ID, \"Localising objects\")  \n",
    "        # localise objects\n",
    "        objects = localise(masks, \n",
    "                           intensity_image, \n",
    "                           )\n",
    "        log_progress(acq_ID, \"Filtering small objects\")  \n",
    "        # filter out small objects\n",
    "        objects = [o for o in objects if o.properties['area'] > segment_size_thresh]\n",
    "        \n",
    "        log_progress(acq_ID, \"Adding infection labels to objects\")  \n",
    "        # add label for infection\n",
    "        for obj in objects:\n",
    "            obj.properties = ({\"Infected\": True} \n",
    "                                if obj.properties['mean_intensity'][manual_mtb_thresh_channel] > 0 # index 2 for manual mtb channel \n",
    "                                else {\"Infected\": False})\n",
    "            obj.properties = ({\"Mtb area px\": obj.properties['mean_intensity'][manual_mtb_thresh_channel]*obj.properties['area']})\n",
    "        \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/backup/{row, column}_cpv3_objects_backup.h5'), \n",
    "                                                   'w', \n",
    "                                                   obj_type='obj_type_1'\n",
    "                                                   ) as writer:\n",
    "                        writer.write_objects(objects)\n",
    "                        # writer.write_tracks(tracks)\n",
    "        \n",
    "        log_progress(acq_ID, \"Beginning tracking\")  \n",
    "        # track on upscaled config fn\n",
    "        tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "        log_progress(acq_ID, \"Saving tracking\")  \n",
    "        # save out \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/backup/{row, column}_cpv3_tracks_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "        #             writer.write_objects(objects)\n",
    "                writer.write_tracks(tracks)\n",
    "                # writer.write_segmentation(masks)\n",
    "        # Log successful completion\n",
    "        \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "                    writer.write_tracks(tracks)\n",
    "                    writer.write_segmentation(masks)\n",
    "        # Log successful completion\n",
    "        log_progress(acq_ID, \"Processing completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log errors\n",
    "        log_progress(acq_ID, f\"Processing failed: {str(e)}\")\n",
    "\n",
    "# You can also log information before and after the loop\n",
    "logging.info(\"Processing completed\")\n",
    "\n",
    "# Notify if required\n",
    "# notify.send_sms(\"Processing completed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macrohet",
   "language": "python",
   "name": "macrohet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
