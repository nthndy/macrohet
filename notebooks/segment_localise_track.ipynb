{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e295e0",
   "metadata": {},
   "source": [
    "# Segment, localise and track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00bec1a4-27f1-4cd4-b841-81b1ee878e45",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cellpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mzarr\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcellpose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# setting device on GPU if available, else CPU\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cellpose'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import zarr\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from cellpose import models\n",
    "\n",
    "import btrack\n",
    "import btrack.io\n",
    "import btrack.utils\n",
    "\n",
    "from macrohet.label import segment, localise, track\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45641d0-7da5-4c89-84a0-bcdf26987d96",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f99d78-2129-43a9-8aa6-a6937964448a",
   "metadata": {},
   "source": [
    "# WIP - deciding which example data and how to host it \n",
    "\n",
    "think downsizing the images by a factor of 5 will make sharing and archiving over github/zenodo much more practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66424cf0-e941-4183-9bcc-71483d319215",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_path = Path(\"../data/example_data.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef2a16a-c9a9-433a-b650-6535558c61c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m zarr_root \u001b[38;5;241m=\u001b[39m zarr\u001b[38;5;241m.\u001b[39mopen_group(zarr_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# important: open_group, not open_array\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image_array \u001b[38;5;241m=\u001b[39m \u001b[43mzarr_root\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# now this will work\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/macrohet/lib/python3.10/site-packages/zarr/hierarchy.py:511\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(item)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(item)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'images'"
     ]
    }
   ],
   "source": [
    "zarr_root = zarr.open_group(zarr_path, mode=\"r\")  # important: open_group, not open_array\n",
    "images = zarr_root[\"images\"]  # now this will work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed050f-fc69-4c7b-8bad-7e4e57477edd",
   "metadata": {},
   "source": [
    "### Create segmentation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c51dd6-ffc2-4b41-8921-6caefbb24b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.stack([segment(frame, model=model) \n",
    "                  for frame in tqdm(images[:,0,...],  # segmenting the GFP channel \n",
    "                                    desc = 'Segmenting')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6d9af-beec-477b-b7af-3fb92348e470",
   "metadata": {},
   "source": [
    "### Save segmentation out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3f3fd-034e-4c4e-98c2-5dccec0cc6e6",
   "metadata": {},
   "source": [
    "#### Option 1: using btrack and h5 compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835a3ee-45e5-43ee-9b38-3c4224b67902",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_output_fn = '../data/segmentation.h5'\n",
    "\n",
    "with btrack.io.HDF5FileHandler(segmentation_fn, \n",
    "                                   'w', \n",
    "                                   obj_type='obj_type_1'\n",
    "                                   ) as writer:\n",
    "        writer.write_segmentation(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a0ec9-0536-4c7f-8d9a-d5b7e7c94e67",
   "metadata": {},
   "source": [
    "#### Option 2: using Zarr (NGFF-style layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515174d7-9c76-4aaa-880b-cc846ad987e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_output_fn = '../data/example_data.zarr'\n",
    "label_group_path = Path(segmentation_output_fn) / 'labels' / '0'\n",
    "\n",
    "label_group_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "zarr.save_array(\n",
    "    store=label_group_path,\n",
    "    arr=masks,  # this should be your stacked segmentation array\n",
    "    compressor=zarr.Blosc(cname='zstd', clevel=5),\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# attach NGFF label metadata to Zarr root\n",
    "zarr_root = zarr.open_group(segmentation_output_fn, mode='a')\n",
    "zarr_root.attrs['labels'] = [{\"path\": \"labels/0\", \"type\": \"label\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb0f22-3429-4703-8f65-de53dc9232b5",
   "metadata": {},
   "source": [
    "### Quantify intracellular Mtb for each cell segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684cf88b-56e5-404e-ae66-4f78f9ef838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds\n",
    "segment_size_thresh = 5000\n",
    "mtb_load_thresh = 480 # determined via blind thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e4f686-66b8-4a6e-b351-1671ecb3fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine thresholded Mtb presence across the specified Mtb channel\n",
    "manual_mtb_thresh = images[:, mtb_channel, ...] >= mtb_load_thresh\n",
    "\n",
    "# Construct a composite intensity image with GFP, RFP, and thresholded Mtb signal\n",
    "# Shape: (T, Y, X, 3) â€” last axis channels: GFP, RFP, Mtb mask for regionprops \n",
    "intensity_image = np.stack([\n",
    "    images[:, 0, ...],                # GFP channel\n",
    "    images[:, 1, ...],                # RFP channel\n",
    "    manual_mtb_thresh.astype(bool)    # Thresholded Mtb presence (binary)\n",
    "], axis=-1)\n",
    "\n",
    "# localise objects\n",
    "objects = localise(masks, \n",
    "                   intensity_image, \n",
    "                   )\n",
    "\n",
    "# filter out objects that are too small to be cells\n",
    "objects = [o for o in objects if o.properties['area'] > segment_size_thresh]\n",
    "\n",
    "# add label for infection\n",
    "for obj in objects:\n",
    "    obj.properties = ({\"Infected\": True} \n",
    "                        if obj.properties['mean_intensity'][2] > 0 # index 2 for manual mtb channel \n",
    "                        else {\"Infected\": False})\n",
    "    obj.properties = ({\"Mtb area px\": obj.properties['mean_intensity'][2]*obj.properties['area']}) # index 2 for manual mtb channel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfb430-3213-4878-a690-a9e38629364e",
   "metadata": {},
   "source": [
    "### Save out single-cell quantifications prior to tracking across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0186e-0459-4e75-a389-1a3e90b4e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_output_fn = '../data/objects.h5'\n",
    "with btrack.io.HDF5FileHandler(objects_output_fn), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "                writer.write_objects(objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af455b-a2cb-48ce-b113-f788e55950b7",
   "metadata": {},
   "source": [
    "### Track single-cell objects across the time lapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b256b9-52dd-41d6-ac92-f2f51219a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fn = '../models/tracking_model.json'\n",
    "tracks = track(objects, masks, config_fn, search_radius = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf59a72-0aa7-48c7-99e4-1d1693a79807",
   "metadata": {},
   "source": [
    "### Save out tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a888e-3ded-48f7-a63e-dbaf3ba39ccf",
   "metadata": {},
   "source": [
    "#### Option 1: using btrack and h5 compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34459913-b69c-40a1-9cac-16c88ad93a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_output_fn = '../data/tracks.h5'\n",
    "with btrack.io.HDF5FileHandler(tracks_output_fn), \n",
    "                                   'w', \n",
    "                                   obj_type='obj_type_1'\n",
    "                                   ) as writer:\n",
    "        writer.write_tracks(tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d757f797-529f-4067-b5f1-0e3d67c3d808",
   "metadata": {},
   "source": [
    "#### Option 2: using Zarr (NGFF-style layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4bf27-c034-46f7-ae5a-3d11eac37245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten all timepoints from all tracks\n",
    "tracklets = [\n",
    "    (track_id, p.t, p.y, p.x, p.properties)\n",
    "    for track_id, track in enumerate(tracks)\n",
    "    for p in track\n",
    "]\n",
    "\n",
    "# Extract main track array: [track_id, t, y, x]\n",
    "track_array = np.array([\n",
    "    (tid, t, y, x)\n",
    "    for tid, t, y, x, _ in tracklets\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Extract features\n",
    "features = {\n",
    "    \"area\": np.array([p[\"area\"] for _, _, _, _, p in tracklets], dtype=np.float32),\n",
    "    \"orientation\": np.array([p[\"orientation\"] for _, _, _, _, p in tracklets], dtype=np.float32),\n",
    "    \"major_axis_length\": np.array([p[\"major_axis_length\"] for _, _, _, _, p in tracklets], dtype=np.float32),\n",
    "    \"minor_axis_length\": np.array([p[\"minor_axis_length\"] for _, _, _, _, p in tracklets], dtype=np.float32),\n",
    "    \"mean_intensity\": np.stack([p[\"mean_intensity\"] for _, _, _, _, p in tracklets]).astype(np.float32)\n",
    "}\n",
    "\n",
    "# Write to Zarr\n",
    "store = zarr.open(zarr_path, mode=\"a\")\n",
    "\n",
    "# Main Napari-compatible tracks array\n",
    "store.create_dataset(\"tracks\", data=track_array, compressor=zarr.Blosc(), overwrite=True)\n",
    "\n",
    "# Features group\n",
    "feat_grp = store.require_group(\"features\")\n",
    "for key, arr in features.items():\n",
    "    feat_grp.create_dataset(key, data=arr, compressor=zarr.Blosc(), overwrite=True)\n",
    "\n",
    "# Add Napari track metadata\n",
    "store.attrs[\"tracks_metadata\"] = {\n",
    "    \"format_version\": \"0.1\",\n",
    "    \"type\": \"napari_tracks\",\n",
    "    \"columns\": [\"track_id\", \"time\", \"y\", \"x\"]\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macrohet",
   "language": "python",
   "name": "macrohet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
