{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db2372a-7f8d-417b-9b58-140baf6830b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a60b3d0-6a76-4657-afd9-bccbeab47fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n",
      "Wed Oct 30 10:34:09 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:65:00.0  On |                  Off |\n",
      "| 30%   41C    P8             35W /  300W |     809MiB /  49140MiB |     36%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2462      G   /usr/lib/xorg/Xorg                            338MiB |\n",
      "|    0   N/A  N/A      4164      G   /usr/bin/gnome-shell                          155MiB |\n",
      "|    0   N/A  N/A     11914      G   ...AAAAAAAACAAAAAAAAAA= --shared-files        152MiB |\n",
      "|    0   N/A  N/A     40603      G   ...42,262144 --variations-seed-version         81MiB |\n",
      "|    0   N/A  N/A     47641      G   /usr/bin/totem                                 20MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellpose.core:Neither TORCH CUDA nor MPS version not installed/working.\n",
      "INFO:cellpose.core:Neither TORCH CUDA nor MPS version not installed/working.\n",
      "INFO:cellpose.core:>>>> using CPU\n",
      "INFO:cellpose.core:>>>> using CPU\n",
      "INFO:cellpose.models:>> cyto << model set to be used\n",
      "INFO:cellpose.core:WARNING: MKL version on torch not working/installed - CPU version will be slightly slower.\n",
      "INFO:cellpose.core:see https://pytorch.org/docs/stable/backends.html?highlight=mkl\n",
      "INFO:cellpose.models:>>>> loading model /home/dayn/.cellpose/models/cytotorch_0\n",
      "INFO:cellpose.models:>>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? NO\n",
      "/home/dayn/.trackastra/.models/general_2d already downloaded, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trackastra.model.model:Loading model state from /home/dayn/.trackastra/.models/general_2d/model.pt\n",
      "INFO:trackastra.model.model_api:Using device cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Load a pretrained model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m trackastra_model \u001b[38;5;241m=\u001b[39m \u001b[43mTrackastra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeneral_2d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:85\u001b[0m, in \u001b[0;36mTrackastra.from_pretrained\u001b[0;34m(cls, name, device, download_dir)\u001b[0m\n\u001b[1;32m     83\u001b[0m folder \u001b[38;5;241m=\u001b[39m download_pretrained(name, download_dir)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# download zip from github to location/name, then unzip\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:76\u001b[0m, in \u001b[0;36mTrackastra.from_folder\u001b[0;34m(cls, dir, device)\u001b[0m\n\u001b[1;32m     74\u001b[0m transformer \u001b[38;5;241m=\u001b[39m TrackingTransformer\u001b[38;5;241m.\u001b[39mfrom_folder(\u001b[38;5;28mdir\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m train_args \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m), Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mFullLoader)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:68\u001b[0m, in \u001b[0;36mTrackastra.__init__\u001b[0;34m(self, transformer, train_args, device)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_args \u001b[38;5;241m=\u001b[39m train_args\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "import btrack\n",
    "import zarr\n",
    "import os\n",
    "import napari\n",
    "from macrohet import dataio\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from trackastra.model import Trackastra\n",
    "from trackastra.tracking import graph_to_ctc, graph_to_napari_tracks\n",
    "\n",
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "cellpose_model = models.Cellpose(gpu=True, model_type='cyto')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load a pretrained model\n",
    "trackastra_model = Trackastra.from_pretrained(\"general_2d\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7b13b-0d5c-4f95-8c87-c9ba1a2dcc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# # Assuming 'segmentation' is your numpy array\n",
    "# with h5py.File(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/z3_cpv3/{acq_ID}.h5', 'w') as f:\n",
    "#     # Save the array with compression for efficient storage\n",
    "#     f.create_dataset('segmentation', data=tracking_input_segmentation, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324fd59-2759-4d7a-9a23-533e04562d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ID = 'ND0004'\n",
    "base_dir = f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/'\n",
    "acq_ID = (4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32b375-7576-4239-85c5-d4d503de52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with h5py.File(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/z3_cpv3/{acq_ID}.h5', 'r') as f:\n",
    "    tracking_input_segmentation = f['segmentation'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd12f0-9d7a-4691-bd17-4f81354676eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "zarr_group = zarr.open(image_dir, mode='r')\n",
    "segmentation_input = zarr_group.images[:,1,2,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ad5a2-fd91-4300-b76b-f788769494f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = zarr_group.images[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4a43d-75dc-479c-81c3-a9c717e37923",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(segmentation_input[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e0949-0488-4860-bb74-a3115868bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the first frame is blank and, if so, copy from the first non-blank frame\n",
    "if np.all(tracking_input_segmentation[0] == 0):\n",
    "    # Find the first non-blank frame\n",
    "    first_non_blank_found = False\n",
    "    for j in range(1, tracking_input_segmentation.shape[0]):\n",
    "        if not np.all(tracking_input_segmentation[j] == 0):  # Check if frame j is non-blank\n",
    "            tracking_input_segmentation[0] = tracking_input_segmentation[j]\n",
    "            first_non_blank_found = True\n",
    "            print(f\"First frame was blank. Copied from frame {j}.\")\n",
    "            break\n",
    "    if not first_non_blank_found:\n",
    "        error_log.append(\"All frames are blank. Skipping segmentation processing.\")\n",
    "        print(\"Error: All frames are blank. No processing will be done.\")\n",
    "        # Exit if all frames are blank since there's nothing to process\n",
    "        raise ValueError(\"Segmentation data is entirely blank.\")\n",
    " # Iterate over frames and check for blank frames, starting from the second frame\n",
    "for i in range(1, tracking_input_segmentation.shape[0]):\n",
    "    if np.all(tracking_input_segmentation[i] == 0):  # Check if the current frame is blank\n",
    "        # Copy the previous non-blank frame if available\n",
    "        if np.all(tracking_input_segmentation[i-1] == 0):\n",
    "            error_log.append(f\"Frame {i} and previous frames are blank, unable to copy.\")\n",
    "            print(f\"Error: Frame {i} is blank and cannot be copied from previous frames.\")\n",
    "            continue\n",
    "        else:\n",
    "            tracking_input_segmentation[i] = tracking_input_segmentation[i-1]\n",
    "            print(f\"Frame {i} was blank. Copied from frame {i-1}.\")\n",
    "    else:\n",
    "        # Track the last non-blank frame as we go\n",
    "        last_non_blank_frame = tracking_input_segmentation[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92db16e-4427-47d4-959b-babbfaca205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'segmentation' is your numpy array\n",
    "with h5py.File(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/z3_cpv3/{acq_ID}.h5', 'w') as f:\n",
    "    # Save the array with compression for efficient storage\n",
    "    f.create_dataset('segmentation', data=tracking_input_segmentation, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23988211-4e45-482e-a40f-a3fa89686030",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_graph = trackastra_model.track(segmentation_input, tracking_input_segmentation, mode=\"greedy_nodiv\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "\n",
    "tracks, napari_tracks_graph, _ = graph_to_napari_tracks(track_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf644d03-7f9f-4511-ace8-95cad5d75540",
   "metadata": {},
   "outputs": [],
   "source": [
    "mphi_channel_ID = 1\n",
    "mtb_channel_ID = 0\n",
    "mtb_load_thresh = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d6112-22df-4970-98ce-0c3a7b8e9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3fa0b8-cfda-4ddf-a329-255aba5f1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_channel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f558ec3-2d08-47c9-b6bc-9d1867ab6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mphi_channel = np.max(images[:,mphi_channel_ID,...], axis=1)\n",
    "mtb_channel = np.max(images[:,mtb_channel_ID,...], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e4326a-9e21-4da4-8f20-322cc6096abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original cellpose segmentation\n",
    "with btrack.io.HDF5FileHandler(os.path.join(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/cpv3/{acq_ID}.h5'), #macrohet_seg_model \n",
    "                                           'r', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as reader:\n",
    "                original_segmentation = reader.segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba4e25-3ae4-49b6-aa35-6530237d8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expt_ID = 'ND0004'\n",
    "base_dir = f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/'\n",
    "metadata_fn = glob.glob(os.path.join(base_dir, 'acquisition/Images/Index*xml'))[0]\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,replicate_number=True)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "image_resolution = float(metadata['ImageResolutionX'].iloc[0])\n",
    "meters_area_per_pixel = image_resolution**2\n",
    "mum_sq_scale_factor = (1E-6)**2\n",
    "pixel_to_mum_sq_scale_factor = meters_area_per_pixel/mum_sq_scale_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ac295-f5ca-4ebd-aff8-6db1cbf7f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34558480-429f-47ea-b5d6-38ec40153785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tracks with length greater than 75\n",
    "tracks = tracks.groupby('ID').filter(lambda x: len(x) > 75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2864e6-ee56-41d3-b35c-57ee7f2b3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ec42b-c55a-4182-9711-cab9bd5936b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tracks with length greater than 75\n",
    "tracks = tracks.groupby('ID').filter(lambda x: len(x) > 75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeddd0a-9a40-46f3-9e5b-b6e9d8627ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tracks = pd.DataFrame(tracks, columns=['ID', 't', 'x', 'y']).astype(int)\n",
    "# # split channels\n",
    "# mphi_channel = np.max(images[:,mphi_channel_ID,...], axis=1)\n",
    "# mtb_channel = np.max(images[:,mtb_channel_ID,...], axis = 1)\n",
    "# thresholded_mtb_channel = mtb_channel >= mtb_load_thresh\n",
    "# now measure properties from prior segmentation?\n",
    "for cell_ID, track in tqdm(tracks.groupby('ID'), desc = 'iterating over tracks', total = len(tracks.ID.unique()), leave = False):\n",
    "    track = track.sort_values(by='t')\n",
    "    # Extract coordinates and time\n",
    "    times = track['t'].to_numpy() / 2  # Assuming you want to halve the time\n",
    "    frames = track['t'].to_numpy() \n",
    "\n",
    "    x_coords = track['x'].to_numpy().astype(int)\n",
    "    y_coords = track['y'].to_numpy().astype(int)\n",
    "\n",
    "\n",
    "    mtb_areas = []\n",
    "    mphi_areas = []\n",
    "    mean_intensities = []\n",
    "    # calculate the mtb pixel area and µm area\n",
    "    for i, frame in tqdm(enumerate(frames), desc = f'Iterating over frames for track ID {cell_ID}', total = len(frames), leave = False):\n",
    "        frame = frame - 1\n",
    "        segmentation_input_ID = original_segmentation[frame][x_coords[i], y_coords[i]]\n",
    "        if segmentation_input_ID == 0:  # Ignore background (assuming 0 is the background ID)\n",
    "                mtb_area_pixels = np.nan\n",
    "                mphi_area_pixels = np.nan\n",
    "        else:\n",
    "            \n",
    "            mask = original_segmentation[frame] == segmentation_input_ID  # Create a mask for the segment with 'seg_id'\n",
    "            \n",
    "            # chop up images into segments here\n",
    "            # image_segment = images[frame][:][mask]\n",
    "            thresholded_image_segment = thresholded_mtb_channel[frame][mask]\n",
    "    \n",
    "            # meaure segment\n",
    "            mtb_area_pixels = np.sum(thresholded_image_segment)\n",
    "            mphi_area_pixels = np.sum(mask)\n",
    "            # mean_intensity = np.mean(image_segment)\n",
    "\n",
    "        # store measurements\n",
    "        mtb_areas.append(mtb_area_pixels)\n",
    "        mphi_areas.append(mphi_area_pixels)\n",
    "        # mean_intensities.append(mean_intensity)\n",
    "\n",
    "    track['Mtb Area (µm)'] = np.array(mtb_areas) * pixel_to_mum_sq_scale_factor\n",
    "    track['Mphi Area (µm)'] = np.array(mphi_areas) * pixel_to_mum_sq_scale_factor\n",
    "    # track['RFP'] = mean_intensities[mtb_channel_ID]\n",
    "    # track['GFP'] = mean_intensities[mphi_channel_ID]\n",
    "    # Compute MSD in a vectorized way\n",
    "    # track['MSD'] = calculate_msd(x_coords, y_coords)\n",
    "    \n",
    "    # infection statuses\n",
    "    track['Infection Status'] = track['Mtb Area (µm)'] > 0\n",
    "\n",
    "    track['Initial Infection Status'] = track['Mtb Area (µm)'].iloc[0] > 0 \n",
    "    track['Final Infection Status'] = track['Mtb Area (µm)'].iloc[-1] > 0 \n",
    "    track['ID'] = cell_ID\n",
    "    track['Unique_ID'] = f'{cell_ID}.{acq_ID[0]}.{acq_ID[1]}.{expt_ID}'\n",
    "\n",
    "    track_dfs.append(track)\n",
    "\n",
    "# Concatenate all track DataFrames into the larger 'df' DataFrame\n",
    "df = pd.concat(track_dfs, ignore_index=True)\n",
    "\n",
    "df.to_pickle(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/sc_df_{acq_ID[0]}.{acq_ID[1]}.{expt_ID}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2b233-872a-426c-96c4-7368cd0f3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_mtb_channel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731742f-2c95-45a7-baf4-cdf15ff61584",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(thresholded_mtb_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6e71a-5153-4547-8fa9-c395b42e1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387df5f-a73a-43ea-8463-4d3b6f9cf12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(segmentation_input)\n",
    "viewer.add_labels(tracking_input_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576871f0-2fb0-4f73-907f-020c9902d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_tracks(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb349c-b42c-4a67-b9d0-02c2a9af2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba268dd-e95e-4ec6-8c8d-5c5d6ff367ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari.Viewer().add_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6fbe32-5e33-49a0-98c9-642aaf3b5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ID = 'ND0004'\n",
    "base_dir = f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/'\n",
    "metadata_fn = glob.glob(os.path.join(base_dir, 'acquisition/Images/Index*xml'))[0]\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,replicate_number=True)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "acq_ID = (4, 7)\n",
    "image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "zarr_group = zarr.open(image_dir, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1768b5f4-7be5-4791-8abe-3bd4f888cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "images = zarr_group.images[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab36ac6-47cc-46d8-9687-ddbd11fb0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(title = 'iterate testing trackastra')\n",
    "\n",
    "viewer.add_image(segmentation_input)\n",
    "viewer.add_labels(tracking_input_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f866db-a919-4a51-ac5c-0bc9d6290a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.io.HDF5FileHandler(os.path.join(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/cpv3/{acq_ID}.h5'), #macrohet_seg_model \n",
    "                                           'r', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as reader:\n",
    "                segmentation = reader.segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3884a-daac-4a6c-8f48-713cc3891be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('/mnt/SYNO/macrohet_syno/data/ND0004/labels/testing_trackastra/ztracks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878020e-8501-4730-bcdf-8dd296867d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks[tracks.groupby('ID')['T'].transform('count') >= 130]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7825e-e10b-4206-ba20-c38c50498a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "images = np.max(images, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e8434-952e-402a-8de2-69f119853a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a4779-ec73-4bb5-aca5-4e5cc72790af",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(title = 'testing nd4 segmentation and tracking')\n",
    "\n",
    "viewer.add_image(images, channel_axis = 1, \n",
    "                 colormap=['magenta', 'green'],\n",
    "                 blending = 'additive', \n",
    "                 contrast_limits=[[0, 1000], [0, 2400]])\n",
    "viewer.add_labels(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9b8ef-cb1b-4ac8-8d53-d74c049156ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = (1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1461c9-20c4-408a-ab71-2be847bf7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by = 'ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb57ed8-4cb4-4bff-9661-c795f7b5fb5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize relabeled array\n",
    "relabeled = np.zeros_like(segmentation)\n",
    "\n",
    "# Iterate over each track, grouped by 'ID'\n",
    "for cell_ID, track in tqdm(tracks.groupby('ID'), desc = 'Iterating over tracks', total = len(tracks.ID.unique())):\n",
    "    track = track.sort_values(by='T')\n",
    "    times = (track['T'].to_numpy()).astype(int)  # Time (T) halved and converted to int\n",
    "    x_coords = (track['X'].to_numpy() * scale[0]).astype(int)\n",
    "    y_coords = (track['Y'].to_numpy() * scale[1]).astype(int)\n",
    "\n",
    "    # Iterate over each time point\n",
    "    for i, t in enumerate(times):\n",
    "        # Ensure we are within the segmentation time bounds\n",
    "        if t >= segmentation.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Handle 2D segmentation\n",
    "        old_id = segmentation[t][x_coords[i], y_coords[i]]\n",
    "        if old_id == 0:  # Ignore background (assuming 0 is the background ID)\n",
    "                continue\n",
    "        # Recolor segmentation by the chosen property (ID in this case)\n",
    "        old_id_mask = segmentation[t] == old_id\n",
    "        # print(old_id)\n",
    "        # Recolor all pixels in this mask with the new ID\n",
    "        new_id = int(cell_ID)\n",
    "        relabeled[t][old_id_mask] = new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a330082-c7bc-47ed-a294-b4ecf1b64276",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(relabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cc13f-ecb8-4514-8373-2d1d06906099",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff16c93-9f9b-444e-be4e-18265fbbbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5b97f-1c81-48aa-885b-c749bc98bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_tracks(tracks[['ID','t','x','y']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee50e449-c7e8-428a-944e-3e4e0a03aab9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing new approach\n",
    "\n",
    "Segment the top z slice of the green channel... can always expand the masks later on to try and capture the mtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042347d-36a9-455e-9659-f9905f68665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_group.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52046cdc-35f6-445e-abaf-5806c39bbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "segmentation_input = zarr_group.images[:,1,2,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89158251-a504-460d-be47-3d557e547ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f55ff4-d67f-4eea-a0f6-14bd2705c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(segmentation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa599ab6-8d62-40bf-a7b6-eb9bd3b2167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_stack = []\n",
    "for frame in tqdm(segmentation_input, total = len(segmentation_input)):\n",
    "    masks, flows, styles, diams = model.eval(frame, \n",
    "                                         diameter=150, \n",
    "                                         channels=[0,0],)\n",
    "\n",
    "    mask_stack.append(masks)\n",
    "cellpose_segmentation = np.stack(mask_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4769f3-2d37-4475-8350-fc06947c9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the NumPy array to a file\n",
    "np.save('/mnt/SYNO/macrohet_syno/temp_cellpose_masks.npy', cellpose_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67599e-86ff-42bd-a710-9cd880a4e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(cellpose_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5d555-3c4c-4478-9ef3-c15f51eed947",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(segmentation_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2329dc-8653-49b0-8b7f-ad6485f7d1da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Trackastra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f628687-8865-4319-8731-fb111b794000",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load a pretrained model\n",
    "trackastra_model = Trackastra.from_pretrained(\"general_2d\", device=device)\n",
    "\n",
    "# or from a local folder\n",
    "# model = Trackastra.from_folder('path/my_model_folder/', device=device)\n",
    "\n",
    "# Track the cells\n",
    "track_graph = trackastra_model.track(segmentation_input, cellpose_segmentation, mode=\"greedy_nodiv\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "\n",
    "\n",
    "# # Write to cell tracking challenge format\n",
    "# ctc_tracks, masks_tracked = graph_to_ctc(\n",
    "#       track_graph,\n",
    "#       masks,\n",
    "#       outdir=\"tracked\",\n",
    "# )\n",
    "\n",
    "# Visualise in napari\n",
    "tracks, napari_tracks_graph, _ = graph_to_napari_tracks(track_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd6c31-1c23-4df9-b9fd-746ccb3a3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = viewer.layers['tracks'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ea3d8-2338-4ef9-87cb-a54ca7a22f2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5764b6-d9d5-423c-b05a-e77ced5b4dfe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## uniting z3 cellpose and trackastra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c1e15-130a-4d6f-8984-90ee8a2b878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds\n",
    "segment_size_thresh = 5000\n",
    "mtb_load_thresh = 480\n",
    "mtb_channel = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293131e-81cd-4f78-841a-4c53790afc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_channel_ID = 0\n",
    "mphi_channel_ID = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94191b56-2ccb-4aea-8d28-d5b3ba60d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mphi_channel = images[:,mphi_channel,...]\n",
    "mtb_channel = images[:,mtb_channel,...]\n",
    "thresholded_mtb_channel = mtb_channel >= mtb_load_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65243ecb-98b7-4783-90e5-40984c3a781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(thresholded_mtb_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e105ba-ce65-4758-a72e-7261154fe936",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.io.HDF5FileHandler(os.path.join(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/cpv3/{acq_ID}.h5'), #macrohet_seg_model \n",
    "                                           'r', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as reader:\n",
    "                segmentation = reader.segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c6fbe-0fda-4490-8e21-bea30cb3b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_msd(x, y):\n",
    "    # Calculate the displacement between successive frames\n",
    "    dx = np.diff(x, prepend=x[0])\n",
    "    dy = np.diff(y, prepend=y[0])\n",
    "    msd = np.sqrt(dx**2 + dy**2)\n",
    "    return msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e1305-c80a-4ca6-8e3e-bea278a23616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have an 'image' that corresponds to your segmentation\n",
    "def measure_segment_intensity(image, segmentation, ID):\n",
    "    \"\"\"Measure intensity of pixels under a specific segment in the image.\"\"\"\n",
    "    mask = segmentation == ID  # Create a mask for the segment with 'seg_id'\n",
    "    segment_intensity = image[mask]  # Extract pixel values under the segment mask\n",
    "    return np.mean(segment_intensity) #, np.sum(segment_intensity)  # Example measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6de28-c1b4-402e-99d4-6b19ff4bbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_channel = 0\n",
    "mphi_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e160f5-be3d-483d-a246-099c3e5590f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tracks['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903c75e-9317-44e0-8eb5-8c602e700b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.rename(columns={'T': 't', 'X': 'x', 'Y': 'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9ca8f-c186-43cd-81a2-7c3ab6e6aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.astype(int)\n",
    "\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138c02f-7f91-4bd8-aa50-27d7eb3e4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b165c19-da07-4ec2-aa7f-7a8aed536969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#technical replicate\n",
    "technical_replicate = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Replicate #']\n",
    "#biological replicate\n",
    "biological_replicate = 4\n",
    "#strain\n",
    "strain = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Strain']\n",
    "#compound\n",
    "compound = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Strain']\n",
    "#concentration\n",
    "concentration = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Concentration']\n",
    "\n",
    "# load the original cellpose segmentation\n",
    "segmentation = segmentation\n",
    "# calculate the new cellpose segmentation\n",
    "tracking_input_segmentation = None\n",
    "# track using new segmentation\n",
    "tracks = tracks\n",
    "# load images and max project them\n",
    "images = images\n",
    "# split channels\n",
    "mphi_channel = images[:,mphi_channel_ID,...]\n",
    "mtb_channel = images[:,mtb_channel_ID,...]\n",
    "thresholded_mtb_channel = mtb_channel >= mtb_load_thresh\n",
    "\n",
    "track_dfs = []\n",
    "# now measure properties from prior segmentation?\n",
    "for cell_ID, track in tqdm(tracks.groupby('ID'), desc = 'iterating over tracks', total = len(tracks.ID.unique())):\n",
    "    track = track.sort_values(by='t')\n",
    "    # Extract coordinates and time\n",
    "    times = track['t'].to_numpy() / 2  # Assuming you want to halve the time\n",
    "    frames = track['t'].to_numpy() \n",
    "\n",
    "    x_coords = track['x'].to_numpy().astype(int)\n",
    "    y_coords = track['y'].to_numpy().astype(int)\n",
    "\n",
    "\n",
    "    mtb_areas = []\n",
    "    mphi_areas = []\n",
    "    mean_intensities = []\n",
    "    # calculate the mtb pixel area and µm area\n",
    "    for i, frame in tqdm(enumerate(frames), desc = f'Iterating over frames for track ID {cell_ID}', total = len(frames), leave = False):\n",
    "        frame = frame - 1\n",
    "        segmentation_input_ID = segmentation[frame][x_coords[i], y_coords[i]]\n",
    "        if segmentation_input_ID == 0:  # Ignore background (assuming 0 is the background ID)\n",
    "                mtb_area_pixels = np.nan\n",
    "                mphi_area_pixels = np.nan\n",
    "        else:\n",
    "            \n",
    "            mask = segmentation[frame] == segmentation_input_ID  # Create a mask for the segment with 'seg_id'\n",
    "            \n",
    "            # chop up images into segments here\n",
    "            # image_segment = images[frame][:][mask]\n",
    "            thresholded_image_segment = thresholded_mtb_channel[frame][mask]\n",
    "    \n",
    "            # meaure segment\n",
    "            mtb_area_pixels = np.sum(thresholded_image_segment)\n",
    "            mphi_area_pixels = np.sum(mask)\n",
    "            # mean_intensity = np.mean(image_segment)\n",
    "\n",
    "        # store measurements\n",
    "        mtb_areas.append(mtb_area_pixels)\n",
    "        mphi_areas.append(mphi_area_pixels)\n",
    "        # mean_intensities.append(mean_intensity)\n",
    "\n",
    "    track['Mtb Area (µm)'] = np.array(mtb_areas) * pixel_to_mum_sq_scale_factor\n",
    "    track['Mphi Area (µm)'] = np.array(mphi_areas) * pixel_to_mum_sq_scale_factor\n",
    "    # track['RFP'] = mean_intensities[mtb_channel_ID]\n",
    "    # track['GFP'] = mean_intensities[mphi_channel_ID]\n",
    "    # Compute MSD in a vectorized way\n",
    "    # track['MSD'] = calculate_msd(x_coords, y_coords)\n",
    "    \n",
    "    # infection statuses\n",
    "    track['Infection Status'] = track['Mtb Area (µm)'] > 0\n",
    "\n",
    "    track['Initial Infection Status'] = track['Mtb Area (µm)'].iloc[0] > 0 \n",
    "    track['Final Infection Status'] = track['Mtb Area (µm)'].iloc[-1] > 0 \n",
    "\n",
    "    track['ID'] = f'{cell_ID}.{acq_ID[0]}.{acq_ID[1]}.{expt_ID}'\n",
    "    \n",
    "    track_dfs.append(track)\n",
    "\n",
    "# Concatenate all track DataFrames into the larger 'df' DataFrame\n",
    "df = pd.concat(track_dfs, ignore_index=True)\n",
    "\n",
    "df.to_pickle(f'sc_df_{acq_ID[0]}.{acq_ID[1]}.{expt_ID}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80ee2c-a6e2-4bf2-8ead-e268aaf02aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords[151]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f317bf-5d31-47ae-b34d-48d93d48ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bffe2a-246a-4a75-9546-42ad3cf8c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067e825-46b7-4a87-a96d-18c555029896",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ID = 'ND0004'\n",
    "base_dir = f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/'\n",
    "metadata_fn = glob.glob(os.path.join(base_dir, 'acquisition/Images/Index*xml'))[0]\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,replicate_number=True)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "image_resolution = float(metadata['ImageResolutionX'].iloc[0])\n",
    "meters_area_per_pixel = image_resolution**2\n",
    "mum_sq_scale_factor = (1E-6)**2\n",
    "pixel_to_mum_sq_scale_factor = meters_area_per_pixel/mum_sq_scale_factor\n",
    "\n",
    "\n",
    "# Sort by custom order of the Compound and ConcentrationEC\n",
    "compound_order = ['RIF', 'PZA', 'INH', 'CTRL', 'BDQ']\n",
    "concentration_order = ['EC99', 'EC50', 'EC0']\n",
    "\n",
    "# Define custom sort logic for the DataFrame\n",
    "assay_layout['compound_sort'] = assay_layout['Compound'].apply(lambda x: compound_order.index(x) if x in compound_order else len(compound_order))\n",
    "assay_layout['concentration_sort'] = assay_layout['ConcentrationEC'].apply(lambda x: concentration_order.index(x) if x in concentration_order else len(concentration_order))\n",
    "assay_layout['strain_sort'] = assay_layout['Strain'].apply(lambda x: 0 if x == 'WT' else (1 if x == 'RD1' else 2))\n",
    "\n",
    "# Sort the DataFrame based on the defined sort order\n",
    "assay_layout_sorted = assay_layout.sort_values(by=['concentration_sort', 'compound_sort', 'strain_sort'])\n",
    "\n",
    "# Extract the row-column tuples from the sorted DataFrame index\n",
    "row_col_order = list(assay_layout_sorted.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8526f9-fa9d-48a4-aacc-b17fb7fd496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_input.shape, tracking_input_segmentation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ef111-3ea4-4d7c-9398-5ffabf1d02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_graph = trackastra_model.track(segmentation_input, tracking_input_segmentation, mode=\"greedy_nodiv\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3418c29-52ad-422d-8a83-58856657ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(title = 'iterate testing trackastra')\n",
    "\n",
    "viewer.add_image(segmentation_input)\n",
    "viewer.add_labels(tracking_input_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9dbd7-f25b-4160-ab65-51d5e85f4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# # Assuming 'segmentation' is your numpy array\n",
    "# with h5py.File(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/z3_cpv3/{acq_ID}.h5', 'w') as f:\n",
    "#     # Save the array with compression for efficient storage\n",
    "#     f.create_dataset('segmentation', data=tracking_input_segmentation, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645b984-3271-42e4-bc99-831d2e7ad433",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ID = 'ND0004'\n",
    "acq_ID = (4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe4947-12d1-48a6-b253-933e8dca0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with h5py.File(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/z3_cpv3/{acq_ID}.h5', 'r') as f:\n",
    "    test = f['segmentation'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e9133-2b9f-4f1d-9bda-89d7181a436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b04dde-3e35-483f-9f5a-285154d4b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari.Viewer().add_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00901110-e9bc-4439-9d6f-1427069d0382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track using new segmentation\n",
    "# Track the cells\n",
    "track_graph = trackastra_model.track(segmentation_input, tracking_input_segmentation, mode=\"greedy_nodiv\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "\n",
    "\n",
    "# Visualise in napari\n",
    "tracks, napari_tracks_graph, _ = graph_to_napari_tracks(track_graph)\n",
    "tracks = pd.DataFrame(tracks, columns=['ID', 't', 'x', 'y']).astype(int)\n",
    "# split channels\n",
    "mphi_channel = images[:,mphi_channel_ID,...]\n",
    "mtb_channel = images[:,mtb_channel_ID,...]\n",
    "thresholded_mtb_channel = mtb_channel >= mtb_load_thresh\n",
    "# now measure properties from prior segmentation?\n",
    "for cell_ID, track in tqdm(tracks.groupby('ID'), desc = 'iterating over tracks', total = len(tracks.ID.unique()), leave = False):\n",
    "    track = track.sort_values(by='t')\n",
    "    # Extract coordinates and time\n",
    "    times = track['t'].to_numpy() / 2  # Assuming you want to halve the time\n",
    "    frames = track['t'].to_numpy() \n",
    "\n",
    "    x_coords = track['x'].to_numpy().astype(int)\n",
    "    y_coords = track['y'].to_numpy().astype(int)\n",
    "\n",
    "\n",
    "    mtb_areas = []\n",
    "    mphi_areas = []\n",
    "    mean_intensities = []\n",
    "    # calculate the mtb pixel area and µm area\n",
    "    for i, frame in tqdm(enumerate(frames), desc = f'Iterating over frames for track ID {cell_ID}', total = len(frames), leave = False):\n",
    "        frame = frame - 1\n",
    "        segmentation_input_ID = segmentation[frame][x_coords[i], y_coords[i]]\n",
    "        if segmentation_input_ID == 0:  # Ignore background (assuming 0 is the background ID)\n",
    "                mtb_area_pixels = np.nan\n",
    "                mphi_area_pixels = np.nan\n",
    "        else:\n",
    "            \n",
    "            mask = segmentation[frame] == segmentation_input_ID  # Create a mask for the segment with 'seg_id'\n",
    "            \n",
    "            # chop up images into segments here\n",
    "            # image_segment = images[frame][:][mask]\n",
    "            thresholded_image_segment = thresholded_mtb_channel[frame][mask]\n",
    "    \n",
    "            # meaure segment\n",
    "            mtb_area_pixels = np.sum(thresholded_image_segment)\n",
    "            mphi_area_pixels = np.sum(mask)\n",
    "            # mean_intensity = np.mean(image_segment)\n",
    "\n",
    "        # store measurements\n",
    "        mtb_areas.append(mtb_area_pixels)\n",
    "        mphi_areas.append(mphi_area_pixels)\n",
    "        # mean_intensities.append(mean_intensity)\n",
    "\n",
    "    track['Mtb Area (µm)'] = np.array(mtb_areas) * pixel_to_mum_sq_scale_factor\n",
    "    track['Mphi Area (µm)'] = np.array(mphi_areas) * pixel_to_mum_sq_scale_factor\n",
    "    # track['RFP'] = mean_intensities[mtb_channel_ID]\n",
    "    # track['GFP'] = mean_intensities[mphi_channel_ID]\n",
    "    # Compute MSD in a vectorized way\n",
    "    # track['MSD'] = calculate_msd(x_coords, y_coords)\n",
    "    \n",
    "    # infection statuses\n",
    "    track['Infection Status'] = track['Mtb Area (µm)'] > 0\n",
    "\n",
    "    track['Initial Infection Status'] = track['Mtb Area (µm)'].iloc[0] > 0 \n",
    "    track['Final Infection Status'] = track['Mtb Area (µm)'].iloc[-1] > 0 \n",
    "    track['ID'] = cell_ID\n",
    "    track['Unique_ID'] = f'{cell_ID}.{acq_ID[0]}.{acq_ID[1]}.{expt_ID}'\n",
    "    \n",
    "    track_dfs.append(track)\n",
    "\n",
    "# Concatenate all track DataFrames into the larger 'df' DataFrame\n",
    "df = pd.concat(track_dfs, ignore_index=True)\n",
    "\n",
    "df.to_pickle(f'sc_df_{acq_ID[0]}.{acq_ID[1]}.{expt_ID}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e328525-bc56-4016-830b-cd7bbd1d7834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for acq_ID in tqdm(row_col_order, total = len(row_col_order), desc = 'Iterating over individual wells'):\n",
    "    \n",
    "    if os.path.exists(f'sc_df_{acq_ID[0]}.{acq_ID[1]}.{expt_ID}.pkl'):\n",
    "        print(f'skipping acq ID {acq_ID}')\n",
    "        continue\n",
    "    #technical replicate\n",
    "    technical_replicate = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Replicate #']\n",
    "    #biological replicate\n",
    "    biological_replicate = 4\n",
    "    #strain\n",
    "    strain = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Strain']\n",
    "    #compound\n",
    "    compound = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Strain']\n",
    "    #concentration\n",
    "    concentration = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Concentration']\n",
    "    # load images and max project them\n",
    "    image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "    zarr_group = zarr.open(image_dir, mode='r')\n",
    "    images = zarr_group.images[...]\n",
    "    # load the original cellpose segmentation\n",
    "    with btrack.io.HDF5FileHandler(os.path.join(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/cpv3/{acq_ID}.h5'), #macrohet_seg_model \n",
    "                                               'r', \n",
    "                                               obj_type='obj_type_1'\n",
    "                                               ) as reader:\n",
    "                    segmentation = reader.segmentation\n",
    "    # calculate the new cellpose segmentation\n",
    "    segmentation_input = images[:,1,2,...]\n",
    "    mask_stack = []\n",
    "    for frame in tqdm(segmentation_input, total = len(segmentation_input)):\n",
    "        masks, flows, styles, diams = cellpose_model.eval(frame, \n",
    "                                                 diameter=150, \n",
    "                                                 channels=[0,0],)\n",
    "    \n",
    "        mask_stack.append(masks)\n",
    "    tracking_input_segmentation = np.stack(mask_stack, axis = 0)\n",
    "    \n",
    "    # track using new segmentation\n",
    "    # Track the cells\n",
    "    track_graph = trackastra_model.track(segmentation_input, tracking_input_segmentation, mode=\"greedy_nodiv\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "    \n",
    "    \n",
    "    # Visualise in napari\n",
    "    tracks, napari_tracks_graph, _ = graph_to_napari_tracks(track_graph)\n",
    "    tracks = pd.DataFrame(tracks, columns=['ID', 't', 'x', 'y']).astype(int)\n",
    "    # split channels\n",
    "    mphi_channel = images[:,mphi_channel_ID,...]\n",
    "    mtb_channel = images[:,mtb_channel_ID,...]\n",
    "    thresholded_mtb_channel = mtb_channel >= mtb_load_thresh\n",
    "    # now measure properties from prior segmentation?\n",
    "    for cell_ID, track in tqdm(tracks.groupby('ID'), desc = 'iterating over tracks', total = len(tracks.ID.unique()), leave = False):\n",
    "        track = track.sort_values(by='t')\n",
    "        # Extract coordinates and time\n",
    "        times = track['t'].to_numpy() / 2  # Assuming you want to halve the time\n",
    "        frames = track['t'].to_numpy() \n",
    "    \n",
    "        x_coords = track['x'].to_numpy().astype(int)\n",
    "        y_coords = track['y'].to_numpy().astype(int)\n",
    "    \n",
    "    \n",
    "        mtb_areas = []\n",
    "        mphi_areas = []\n",
    "        mean_intensities = []\n",
    "        # calculate the mtb pixel area and µm area\n",
    "        for i, frame in tqdm(enumerate(frames), desc = f'Iterating over frames for track ID {cell_ID}', total = len(frames), leave = False):\n",
    "            frame = frame - 1\n",
    "            segmentation_input_ID = segmentation[frame][x_coords[i], y_coords[i]]\n",
    "            if segmentation_input_ID == 0:  # Ignore background (assuming 0 is the background ID)\n",
    "                    mtb_area_pixels = np.nan\n",
    "                    mphi_area_pixels = np.nan\n",
    "            else:\n",
    "                \n",
    "                mask = segmentation[frame] == segmentation_input_ID  # Create a mask for the segment with 'seg_id'\n",
    "                \n",
    "                # chop up images into segments here\n",
    "                # image_segment = images[frame][:][mask]\n",
    "                thresholded_image_segment = thresholded_mtb_channel[frame][mask]\n",
    "        \n",
    "                # meaure segment\n",
    "                mtb_area_pixels = np.sum(thresholded_image_segment)\n",
    "                mphi_area_pixels = np.sum(mask)\n",
    "                # mean_intensity = np.mean(image_segment)\n",
    "    \n",
    "            # store measurements\n",
    "            mtb_areas.append(mtb_area_pixels)\n",
    "            mphi_areas.append(mphi_area_pixels)\n",
    "            # mean_intensities.append(mean_intensity)\n",
    "    \n",
    "        track['Mtb Area (µm)'] = np.array(mtb_areas) * pixel_to_mum_sq_scale_factor\n",
    "        track['Mphi Area (µm)'] = np.array(mphi_areas) * pixel_to_mum_sq_scale_factor\n",
    "        # track['RFP'] = mean_intensities[mtb_channel_ID]\n",
    "        # track['GFP'] = mean_intensities[mphi_channel_ID]\n",
    "        # Compute MSD in a vectorized way\n",
    "        # track['MSD'] = calculate_msd(x_coords, y_coords)\n",
    "        \n",
    "        # infection statuses\n",
    "        track['Infection Status'] = track['Mtb Area (µm)'] > 0\n",
    "    \n",
    "        track['Initial Infection Status'] = track['Mtb Area (µm)'].iloc[0] > 0 \n",
    "        track['Final Infection Status'] = track['Mtb Area (µm)'].iloc[-1] > 0 \n",
    "        track['ID'] = cell_ID\n",
    "        track['Unique_ID'] = f'{cell_ID}.{acq_ID[0]}.{acq_ID[1]}.{expt_ID}'\n",
    "    \n",
    "        track_dfs.append(track)\n",
    "    \n",
    "    # Concatenate all track DataFrames into the larger 'df' DataFrame\n",
    "    df = pd.concat(track_dfs, ignore_index=True)\n",
    "    \n",
    "    df.to_pickle(f'sc_df_{acq_ID[0]}.{acq_ID[1]}.{expt_ID}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd31a3d-b0d2-43ed-a306-afe309766c9b",
   "metadata": {},
   "source": [
    "# Process the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a0ded3-a887-429e-b24a-3baaf04af011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n",
      "Wed Oct 30 13:07:04 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:65:00.0  On |                  Off |\n",
      "| 30%   42C    P5             37W /  300W |     852MiB /  49140MiB |     18%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2462      G   /usr/lib/xorg/Xorg                            330MiB |\n",
      "|    0   N/A  N/A      4164      G   /usr/bin/gnome-shell                          185MiB |\n",
      "|    0   N/A  N/A     11914      G   ...AAAAAAAACAAAAAAAAAA= --shared-files        152MiB |\n",
      "|    0   N/A  N/A     40603      G   ...42,262144 --variations-seed-version         98MiB |\n",
      "|    0   N/A  N/A     47641      G   /usr/bin/totem                                 24MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellpose.core:Neither TORCH CUDA nor MPS version not installed/working.\n",
      "INFO:cellpose.core:Neither TORCH CUDA nor MPS version not installed/working.\n",
      "INFO:cellpose.core:>>>> using CPU\n",
      "INFO:cellpose.core:>>>> using CPU\n",
      "INFO:cellpose.models:>> cyto << model set to be used\n",
      "INFO:cellpose.core:WARNING: MKL version on torch not working/installed - CPU version will be slightly slower.\n",
      "INFO:cellpose.core:see https://pytorch.org/docs/stable/backends.html?highlight=mkl\n",
      "INFO:cellpose.models:>>>> loading model /home/dayn/.cellpose/models/cytotorch_0\n",
      "INFO:cellpose.models:>>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? NO\n",
      "/home/dayn/.trackastra/.models/general_2d already downloaded, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trackastra.model.model:Loading model state from /home/dayn/.trackastra/.models/general_2d/model.pt\n",
      "INFO:trackastra.model.model_api:Using device cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load a pretrained model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m trackastra_model \u001b[38;5;241m=\u001b[39m \u001b[43mTrackastra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeneral_2d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:85\u001b[0m, in \u001b[0;36mTrackastra.from_pretrained\u001b[0;34m(cls, name, device, download_dir)\u001b[0m\n\u001b[1;32m     83\u001b[0m folder \u001b[38;5;241m=\u001b[39m download_pretrained(name, download_dir)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# download zip from github to location/name, then unzip\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:76\u001b[0m, in \u001b[0;36mTrackastra.from_folder\u001b[0;34m(cls, dir, device)\u001b[0m\n\u001b[1;32m     74\u001b[0m transformer \u001b[38;5;241m=\u001b[39m TrackingTransformer\u001b[38;5;241m.\u001b[39mfrom_folder(\u001b[38;5;28mdir\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m train_args \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m), Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mFullLoader)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:68\u001b[0m, in \u001b[0;36mTrackastra.__init__\u001b[0;34m(self, transformer, train_args, device)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_args \u001b[38;5;241m=\u001b[39m train_args\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "import btrack\n",
    "import zarr\n",
    "import os\n",
    "import napari\n",
    "from macrohet import dataio\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from trackastra.model import Trackastra\n",
    "from trackastra.tracking import graph_to_ctc, graph_to_napari_tracks\n",
    "import h5py\n",
    "\n",
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "cellpose_model = models.Cellpose(gpu=True, model_type='cyto')\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Load a pretrained model\n",
    "trackastra_model = Trackastra.from_pretrained(\"general_2d\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2c2d5-a222-44f1-9ce5-51f5c3bc9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ID = 'ND0004'\n",
    "base_dir = f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/'\n",
    "metadata_fn = glob.glob(os.path.join(base_dir, 'acquisition/Images/Index*xml'))[0]\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,replicate_number=True)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f018a6d-667b-4ef3-87a5-24da008342df",
   "metadata": {},
   "source": [
    "# uniting z3 cellpose and trackastra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff1c58-edd1-4415-ac5a-cb4cd9d7c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds\n",
    "segment_size_thresh = 5000\n",
    "mtb_load_thresh = 480\n",
    "\n",
    "mtb_channel_ID = 0\n",
    "mphi_channel_ID = 1\n",
    "\n",
    "def calculate_msd(x, y):\n",
    "    # Calculate the displacement between successive frames\n",
    "    dx = np.diff(x, prepend=x[0])\n",
    "    dy = np.diff(y, prepend=y[0])\n",
    "    msd = np.sqrt(dx**2 + dy**2)\n",
    "    return msd\n",
    "\n",
    "# Assuming you have an 'image' that corresponds to your segmentation\n",
    "def measure_segment_intensity(image, segmentation, ID):\n",
    "    \"\"\"Measure intensity of pixels under a specific segment in the image.\"\"\"\n",
    "    mask = segmentation == ID  # Create a mask for the segment with 'seg_id'\n",
    "    segment_intensity = image[mask]  # Extract pixel values under the segment mask\n",
    "    return np.mean(segment_intensity) #, np.sum(segment_intensity)  # Example measurements\n",
    "\n",
    "\n",
    "expt_ID = 'ND0004'\n",
    "base_dir = f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/'\n",
    "metadata_fn = glob.glob(os.path.join(base_dir, 'acquisition/Images/Index*xml'))[0]\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,replicate_number=True)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "image_resolution = float(metadata['ImageResolutionX'].iloc[0])\n",
    "meters_area_per_pixel = image_resolution**2\n",
    "mum_sq_scale_factor = (1E-6)**2\n",
    "pixel_to_mum_sq_scale_factor = meters_area_per_pixel/mum_sq_scale_factor\n",
    "\n",
    "\n",
    "# Sort by custom order of the Compound and ConcentrationEC\n",
    "compound_order = ['RIF', 'PZA', 'INH', 'CTRL', 'BDQ']\n",
    "concentration_order = ['EC99', 'EC50', 'EC0']\n",
    "\n",
    "# Define custom sort logic for the DataFrame\n",
    "assay_layout['compound_sort'] = assay_layout['Compound'].apply(lambda x: compound_order.index(x) if x in compound_order else len(compound_order))\n",
    "assay_layout['concentration_sort'] = assay_layout['ConcentrationEC'].apply(lambda x: concentration_order.index(x) if x in concentration_order else len(concentration_order))\n",
    "assay_layout['strain_sort'] = assay_layout['Strain'].apply(lambda x: 0 if x == 'WT' else (1 if x == 'RD1' else 2))\n",
    "\n",
    "# Sort the DataFrame based on the defined sort order\n",
    "assay_layout_sorted = assay_layout.sort_values(by=['concentration_sort', 'compound_sort', 'strain_sort'])\n",
    "\n",
    "# Extract the row-column tuples from the sorted DataFrame index\n",
    "row_col_order = list(assay_layout_sorted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c81db5-f221-48be-a3f2-40fbdf857c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only wild-type\n",
    "row_col_order = list(assay_layout_sorted[assay_layout_sorted['Strain'] == 'WT'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a922c93-bc7a-40b0-b0f7-903eeeef702e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for acq_ID in tqdm(row_col_order, total = len(row_col_order), desc = 'Iterating over individual wells'):\n",
    "    \n",
    "    if os.path.exists(f'/mnt/SYNO/macrohet_syno/results/dfs/{expt_ID}/sc_df_{acq_ID[0]}.{acq_ID[1]}.{expt_ID}.pkl'):\n",
    "        print(f'skipping acq ID {acq_ID}')\n",
    "        continue\n",
    "\n",
    "        \n",
    "    #technical replicate\n",
    "    technical_replicate = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Replicate #']\n",
    "    #biological replicate\n",
    "    biological_replicate = 4\n",
    "    #strain\n",
    "    strain = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Strain']\n",
    "    #compound\n",
    "    compound = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Strain']\n",
    "    #concentration\n",
    "    concentration = assay_layout.loc[(acq_ID[0], acq_ID[1])]['Concentration']\n",
    "    # load images and max project them\n",
    "    image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "    zarr_group = zarr.open(image_dir, mode='r')\n",
    "    images = zarr_group.images[...]\n",
    "    # load the original cellpose segmentation\n",
    "    with btrack.io.HDF5FileHandler(os.path.join(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/cpv3/{acq_ID}.h5'), #macrohet_seg_model \n",
    "                                               'r', \n",
    "                                               obj_type='obj_type_1'\n",
    "                                               ) as reader:\n",
    "                    original_segmentation = reader.segmentation\n",
    "    # calculate the new cellpose segmentation\n",
    "    segmentation_input = images[:,1,2,...]\n",
    "    mask_stack = []\n",
    "    for frame in tqdm(segmentation_input, total = len(segmentation_input)):\n",
    "        masks, flows, styles, diams = cellpose_model.eval(frame, \n",
    "                                                 diameter=150, \n",
    "                                                 channels=[0,0],)\n",
    "    \n",
    "        mask_stack.append(masks)\n",
    "    tracking_input_segmentation = np.stack(mask_stack, axis = 0)\n",
    "    # perform checks on segmentation\n",
    "    error_log = []\n",
    "    # Check if the first frame is blank and, if so, copy from the first non-blank frame\n",
    "    if np.all(tracking_input_segmentation[0] == 0):\n",
    "        # Find the first non-blank frame\n",
    "        first_non_blank_found = False\n",
    "        for j in range(1, tracking_input_segmentation.shape[0]):\n",
    "            if not np.all(tracking_input_segmentation[j] == 0):  # Check if frame j is non-blank\n",
    "                tracking_input_segmentation[0] = tracking_input_segmentation[j]\n",
    "                first_non_blank_found = True\n",
    "                print(f\"First frame was blank. Copied from frame {j}.\")\n",
    "                break\n",
    "        if not first_non_blank_found:\n",
    "            error_log.append(\"All frames are blank. Skipping segmentation processing.\")\n",
    "            print(\"Error: All frames are blank. No processing will be done.\")\n",
    "            # Exit if all frames are blank since there's nothing to process\n",
    "            raise ValueError(\"Segmentation data is entirely blank.\")\n",
    "     # Iterate over frames and check for blank frames, starting from the second frame\n",
    "    for i in range(1, tracking_input_segmentation.shape[0]):\n",
    "        if np.all(tracking_input_segmentation[i] == 0):  # Check if the current frame is blank\n",
    "            # Copy the previous non-blank frame if available\n",
    "            if np.all(tracking_input_segmentation[i-1] == 0):\n",
    "                error_log.append(f\"Frame {i} and previous frames are blank, unable to copy.\")\n",
    "                print(f\"Error: Frame {i} is blank and cannot be copied from previous frames.\")\n",
    "                continue\n",
    "            else:\n",
    "                tracking_input_segmentation[i] = tracking_input_segmentation[i-1]\n",
    "                print(f\"Frame {i} was blank. Copied from frame {i-1}.\")\n",
    "        else:\n",
    "            # Track the last non-blank frame as we go\n",
    "            last_non_blank_frame = tracking_input_segmentation[i]\n",
    "    # Log the error messages and proceed with the loop\n",
    "    if error_log:\n",
    "        for error in error_log:\n",
    "            print(error)\n",
    "        print(\"Segmentation completed with some frames skipped due to consecutive blank frames.\")\n",
    "\n",
    "    # Assuming 'segmentation' is your numpy array\n",
    "    with h5py.File(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/z3_cpv3/{acq_ID}.h5', 'w') as f:\n",
    "        # Save the array with compression for efficient storage\n",
    "        f.create_dataset('segmentation', data=tracking_input_segmentation, compression=\"gzip\")\n",
    "    # track using new segmentation\n",
    "    # Track the cells\n",
    "    track_graph = trackastra_model.track(segmentation_input, tracking_input_segmentation, mode=\"greedy_nodiv\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "    \n",
    "    # Visualise in napari\n",
    "    tracks, napari_tracks_graph, _ = graph_to_napari_tracks(track_graph)\n",
    "    tracks = pd.DataFrame(tracks, columns=['ID', 't', 'x', 'y']).astype(int)\n",
    "    # Filter tracks with length greater than 75\n",
    "    tracks = tracks.groupby('ID').filter(lambda x: len(x) > 75)\n",
    "    \n",
    "    # split channels\n",
    "    mphi_channel = np.max(images[:,mphi_channel_ID,...], axis=1)\n",
    "    mtb_channel = np.max(images[:,mtb_channel_ID,...], axis = 1)\n",
    "    thresholded_mtb_channel = mtb_channel >= mtb_load_thresh\n",
    "    track_dfs = []\n",
    "    # now measure properties from prior segmentation?\n",
    "    for cell_ID, track in tqdm(tracks.groupby('ID'), desc = 'iterating over tracks', total = len(tracks.ID.unique()), leave = False):\n",
    "        track = track.sort_values(by='t')\n",
    "        # Extract coordinates and time\n",
    "        times = track['t'].to_numpy() / 2  # Assuming you want to halve the time\n",
    "        frames = track['t'].to_numpy() \n",
    "    \n",
    "        x_coords = track['x'].to_numpy().astype(int)\n",
    "        y_coords = track['y'].to_numpy().astype(int)\n",
    "    \n",
    "    \n",
    "        mtb_areas = []\n",
    "        mphi_areas = []\n",
    "        mean_intensities = []\n",
    "        # calculate the mtb pixel area and µm area\n",
    "        for i, frame in tqdm(enumerate(frames), desc = f'Iterating over frames for track ID {cell_ID}', total = len(frames), leave = False):\n",
    "            frame = frame - 1\n",
    "            segmentation_input_ID = original_segmentation[frame][x_coords[i], y_coords[i]]\n",
    "            if segmentation_input_ID == 0:  # Ignore background (assuming 0 is the background ID)\n",
    "                    mtb_area_pixels = np.nan\n",
    "                    mphi_area_pixels = np.nan\n",
    "            else:\n",
    "                \n",
    "                mask = original_segmentation[frame] == segmentation_input_ID  # Create a mask for the segment with 'seg_id'\n",
    "                \n",
    "                # chop up images into segments here\n",
    "                # image_segment = images[frame][:][mask]\n",
    "                thresholded_image_segment = thresholded_mtb_channel[frame][mask]\n",
    "        \n",
    "                # meaure segment\n",
    "                mtb_area_pixels = np.sum(thresholded_image_segment)\n",
    "                mphi_area_pixels = np.sum(mask)\n",
    "                # mean_intensity = np.mean(image_segment)\n",
    "    \n",
    "            # store measurements\n",
    "            mtb_areas.append(mtb_area_pixels)\n",
    "            mphi_areas.append(mphi_area_pixels)\n",
    "            # mean_intensities.append(mean_intensity)\n",
    "    \n",
    "        track['Mtb Area (µm)'] = np.array(mtb_areas) * pixel_to_mum_sq_scale_factor\n",
    "        track['Mphi Area (µm)'] = np.array(mphi_areas) * pixel_to_mum_sq_scale_factor\n",
    "        # track['RFP'] = mean_intensities[mtb_channel_ID]\n",
    "        # track['GFP'] = mean_intensities[mphi_channel_ID]\n",
    "        # Compute MSD in a vectorized way\n",
    "        # track['MSD'] = calculate_msd(x_coords, y_coords)\n",
    "        \n",
    "        # infection statuses\n",
    "        track['Infection Status'] = track['Mtb Area (µm)'] > 0\n",
    "    \n",
    "        track['Initial Infection Status'] = track['Mtb Area (µm)'].iloc[0] > 0 \n",
    "        track['Final Infection Status'] = track['Mtb Area (µm)'].iloc[-1] > 0 \n",
    "        track['ID'] = cell_ID\n",
    "        track['Unique_ID'] = f'{cell_ID}.{acq_ID[0]}.{acq_ID[1]}.{expt_ID}'\n",
    "    \n",
    "        track_dfs.append(track)\n",
    "    \n",
    "    # Concatenate all track DataFrames into the larger 'df' DataFrame\n",
    "    df = pd.concat(track_dfs, ignore_index=True)\n",
    "    \n",
    "    df.to_pickle(f'/mnt/SYNO/macrohet_syno/results/dfs/{expt_ID}/sc_df_{acq_ID[0]}.{acq_ID[1]}.{expt_ID}.pkl')\n",
    "\n",
    "\n",
    "    try:\n",
    "        del original_segmentation, images, segmentation_input, tracking_input_segmentation, track_graph, tracks, napari_tracks_graph\n",
    "    except:\n",
    "\n",
    "        print('couldnt clear memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1700f6-bfea-4667-ab24-9fe911541aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godspeed",
   "language": "python",
   "name": "godspeed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
