{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a60b3d0-6a76-4657-afd9-bccbeab47fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import btrack\n",
    "import zarr\n",
    "import os\n",
    "import napari\n",
    "from macrohet import dataio\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6fbe32-5e33-49a0-98c9-642aaf3b5839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112af1057b0a4a65bd771c1bdfc1a315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata complete!\n",
      "Reading metadata XML file...\n",
      "Extracting metadata complete!\n"
     ]
    }
   ],
   "source": [
    "expt_ID = 'ND0004'\n",
    "base_dir = f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/'\n",
    "metadata_fn = glob.glob(os.path.join(base_dir, 'acquisition/Images/Index*xml'))[0]\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,replicate_number=False)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "acq_ID = (3, 4)\n",
    "image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "zarr_group = zarr.open(image_dir, mode='r')\n",
    "images = zarr_group.images[0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f7bdcb-1125-44cd-a044-cc0b94826ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 6048, 6048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f866db-a919-4a51-ac5c-0bc9d6290a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024/10/22 03:29:52 PM] Opening HDF file: /mnt/SYNO/macrohet_syno/data/ND0004/labels/cpv3/(3, 4).h5...\n",
      "[INFO][2024/10/22 03:30:11 PM] Loading segmentation (154, 6048, 6048)\n",
      "[INFO][2024/10/22 03:30:11 PM] Closing HDF file: /mnt/SYNO/macrohet_syno/data/ND0004/labels/cpv3/(3, 4).h5\n"
     ]
    }
   ],
   "source": [
    "with btrack.io.HDF5FileHandler(os.path.join(f'/mnt/SYNO/macrohet_syno/data/{expt_ID}/labels/cpv3/{acq_ID}.h5'), #macrohet_seg_model \n",
    "                                           'r', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as reader:\n",
    "                segmentation = reader.segmentation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fb3884a-daac-4a6c-8f48-713cc3891be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6048, 6048)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef9a4779-ec73-4bb5-aca5-4e5cc72790af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'segmentation' at 0x7f93e59e09a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer(title = 'testing nd4 segmentation and tracking')\n",
    "\n",
    "viewer.add_image(images, channel_axis = 0, \n",
    "                 colormap=['magenta', 'green'],\n",
    "                 blending = 'additive', \n",
    "                 contrast_limits=[[0, 1000], [0, 2400]])\n",
    "viewer.add_labels(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb05350-c389-49da-9447-4d67fa9549ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee50e449-c7e8-428a-944e-3e4e0a03aab9",
   "metadata": {},
   "source": [
    "# Testing new approach\n",
    "\n",
    "Segment the top z slice of the green channel... can always expand the masks later on to try and capture the mtb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5042347d-36a9-455e-9659-f9905f68665b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 2, 3, 6048, 6048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zarr_group.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52046cdc-35f6-445e-abaf-5806c39bbb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.72 s, sys: 5.24 s, total: 15 s\n",
      "Wall time: 54.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "segmentation_input = zarr_group.images[:,1,2,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89158251-a504-460d-be47-3d557e547ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61f55ff4-d67f-4eea-a0f6-14bd2705c656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'segmentation_input' at 0x7f93e45de170>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(segmentation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fb57915-fd63-4a8d-9fb7-fd33d80921c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 15:46:41.030031: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-22 15:46:41.060827: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 registered models for 'StarDist2D':\n",
      "\n",
      "Name                  Alias(es)\n",
      "────                  ─────────\n",
      "'2D_versatile_fluo'   'Versatile (fluorescent nuclei)'\n",
      "'2D_versatile_he'     'Versatile (H&E nuclei)'\n",
      "'2D_paper_dsb2018'    'DSB 2018 (from StarDist 2D paper)'\n",
      "'2D_demo'             None\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "from stardist.models import StarDist2D\n",
    "\n",
    "# prints a list of available models\n",
    "StarDist2D.from_pretrained()\n",
    "\n",
    "# creates a pretrained model\n",
    "model = StarDist2D.from_pretrained('2D_versatile_fluo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0e819c3-5251-4498-a395-804d4077b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.utils import normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bfc2615-3d72-4f89-b83b-d5a4617c64a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method _predict_instances_generator in module stardist.models.base:\n",
      "\n",
      "_predict_instances_generator(img, axes=None, normalizer=None, sparse=True, prob_thresh=None, nms_thresh=None, scale=None, n_tiles=None, show_tile_progress=True, verbose=False, return_labels=True, predict_kwargs=None, nms_kwargs=None, overlap_label=None, return_predict=False) method of stardist.models.model2d.StarDist2D instance\n",
      "    Predict instance segmentation from input image.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    img : :class:`numpy.ndarray`\n",
      "        Input image\n",
      "    axes : str or None\n",
      "        Axes of the input ``img``.\n",
      "        ``None`` denotes that axes of img are the same as denoted in the config.\n",
      "    normalizer : :class:`csbdeep.data.Normalizer` or None\n",
      "        (Optional) normalization of input image before prediction.\n",
      "        Note that the default (``None``) assumes ``img`` to be already normalized.\n",
      "    sparse: bool\n",
      "        If true, aggregate probabilities/distances sparsely during tiled\n",
      "        prediction to save memory (recommended).\n",
      "    prob_thresh : float or None\n",
      "        Consider only object candidates from pixels with predicted object probability\n",
      "        above this threshold (also see `optimize_thresholds`).\n",
      "    nms_thresh : float or None\n",
      "        Perform non-maximum suppression that considers two objects to be the same\n",
      "        when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).\n",
      "    scale: None or float or iterable\n",
      "        Scale the input image internally by this factor and rescale the output accordingly.\n",
      "        All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.\n",
      "        Alternatively, multiple scale values (compatible with input `axes`) can be used\n",
      "        for more fine-grained control (scale values for non-spatial axes must be 1).\n",
      "    n_tiles : iterable or None\n",
      "        Out of memory (OOM) errors can occur if the input image is too large.\n",
      "        To avoid this problem, the input image is broken up into (overlapping) tiles\n",
      "        that are processed independently and re-assembled.\n",
      "        This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).\n",
      "        ``None`` denotes that no tiling should be used.\n",
      "    show_tile_progress: bool\n",
      "        Whether to show progress during tiled prediction.\n",
      "    verbose: bool\n",
      "        Whether to print some info messages.\n",
      "    return_labels: bool\n",
      "        Whether to create a label image, otherwise return None in its place.\n",
      "    predict_kwargs: dict\n",
      "        Keyword arguments for ``predict`` function of Keras model.\n",
      "    nms_kwargs: dict\n",
      "        Keyword arguments for non-maximum suppression.\n",
      "    overlap_label: scalar or None\n",
      "        if not None, label the regions where polygons overlap with that value\n",
      "    return_predict: bool\n",
      "        Also return the outputs of :func:`predict` (in a separate tuple)\n",
      "        If True, implies sparse = False\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`)\n",
      "        Returns a tuple of the label instances image and also\n",
      "        a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.predict_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d058a39c-122a-480e-a04f-412544e7a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 45s, sys: 695 ms, total: 8min 46s\n",
      "Wall time: 22.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels [4]' at 0x7f9325773970>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "labels, _ = model.predict_instances(normalize(segmentation_input[0]), scale = 0.5, prob_thresh = 0.3\n",
    "                        )\n",
    "\n",
    "viewer.add_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6012a5de-9a5d-468d-8caa-ba14648be696",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(title = 'testing nd4 seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50188575-0a77-4dfc-b973-fbf8e12d5248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'labels' at 0x7f93258eb400>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bac0440-29d1-4fd4-a7a7-3d32b05678fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image' at 0x7f938c33b190>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(normalize(segmentation_input[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3491ee-1f62-4ca5-8fc7-b9a95d2e54f9",
   "metadata": {},
   "source": [
    "### Do not think Stardist is best suited to this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f70f63-06b6-4930-a9f9-3ccf84b123b2",
   "metadata": {},
   "source": [
    "# Trying Cellpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd4441ae-3295-4c31-8530-a14ec2069546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Wed_Nov_22_10:17:15_PST_2023\n",
      "Cuda compilation tools, release 12.3, V12.3.107\n",
      "Build cuda_12.3.r12.3/compiler.33567101_0\n",
      "Tue Oct 22 16:02:55 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:65:00.0  On |                  Off |\n",
      "| 30%   42C    P8             36W /  300W |   17832MiB /  49140MiB |     22%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2523      G   /usr/lib/xorg/Xorg                            453MiB |\n",
      "|    0   N/A  N/A      3966      G   /usr/bin/gnome-shell                          248MiB |\n",
      "|    0   N/A  N/A    427336      G   ...AAAAAAAACAAAAAAAAAA= --shared-files         61MiB |\n",
      "|    0   N/A  N/A   1348966      G   ...seed-version=20240827-180123.409000        162MiB |\n",
      "|    0   N/A  N/A   1424472      G   ...miniconda3/envs/godspeed/bin/python      16470MiB |\n",
      "|    0   N/A  N/A   1428836      G   ...miniconda3/envs/godspeed/bin/python        369MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "model = models.Cellpose(gpu=True, model_type='cyto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bd90a2d-8907-47f4-9868-5ff196327435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 s, sys: 12.1 s, total: 36.5 s\n",
      "Wall time: 34.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masks' at 0x7f957b21b8b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "masks, flows, styles, diams = model.eval(normalize(segmentation_input[0]), diameter=130, channels=[0,0],\n",
    "                                             # flow_threshold=flow_threshold, cellprob_threshold=0\n",
    "                                          )   \n",
    "viewer.add_labels(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9c58662-3328-4e2f-b767-3c1a640ec220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 s, sys: 14.3 s, total: 38.7 s\n",
      "Wall time: 36.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masks [4]' at 0x7f957b2ddba0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "masks, flows, styles, diams = model.eval(segmentation_input[0], \n",
    "                                         diameter=150, \n",
    "                                         channels=[0,0],\n",
    "                                         # flow_threshold=0.2\n",
    "                                             # flow_threshold=flow_threshold, cellprob_threshold=0\n",
    "                                          )   \n",
    "viewer.add_labels(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1de9f0e-cd51-48ef-9dc3-2f07414d0762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'segmentation' at 0x7f956a4a2620>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06f037c2-c6a8-4b14-9389-6990dfc4fd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image [3]' at 0x7f957b685c90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(zarr_group.images[0,1,1\n",
    "                ,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96a567e8-d4c6-4d24-af88-40670d3d8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa599ab6-8d62-40bf-a7b6-eb9bd3b2167c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665efce01ebb4b71b9d3c1f4e8bd42b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_stack = []\n",
    "for frame in tqdm(segmentation_input, total = len(segmentation_input)):\n",
    "    masks, flows, styles, diams = model.eval(frame, \n",
    "                                         diameter=150, \n",
    "                                         channels=[0,0],)\n",
    "\n",
    "    mask_stack.append(masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69bc0876-a990-4158-b6cd-e62e16433124",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellpose_segmentation = np.stack(mask_stack, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c4769f3-2d37-4475-8350-fc06947c9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the NumPy array to a file\n",
    "np.save('/mnt/SYNO/macrohet_syno/temp_cellpose_masks.npy', cellpose_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c67599e-86ff-42bd-a710-9cd880a4e3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'cellpose_segmentation' at 0x7f9583b2f0a0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(cellpose_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0f5d555-3c4c-4478-9ef3-c15f51eed947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'segmentation_input' at 0x7f957b65df90>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(segmentation_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2329dc-8653-49b0-8b7f-ad6485f7d1da",
   "metadata": {},
   "source": [
    "# Trackastra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b78b903d-c6bd-415d-9c5d-a05533f98bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trackastra.model import Trackastra\n",
    "from trackastra.tracking import graph_to_ctc, graph_to_napari_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f628687-8865-4319-8731-fb111b794000",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trackastra.model.model:Loading model state from /home/dayn/.trackastra/.models/general_2d/model.pt\n",
      "INFO:trackastra.model.model_api:Using device cuda\n",
      "INFO:trackastra.model.model_api:Predicting weights for candidate graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dayn/.trackastra/.models/general_2d already downloaded, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trackastra.data.wrfeat:Extracting features from 154 detections\n",
      "INFO:trackastra.data.wrfeat:Using single process for feature extraction\n",
      "Extracting features: 100%|███████████████████████████████████████████████████████████| 154/154 [05:15<00:00,  2.05s/it]\n",
      "INFO:trackastra.model.model_api:Building windows\n",
      "Building windows: 100%|████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 4534.74it/s]\n",
      "INFO:trackastra.model.model_api:Predicting windows\n",
      "Computing associations: 100%|████████████████████████████████████████████████████████| 151/151 [00:45<00:00,  3.33it/s]\n",
      "INFO:trackastra.model.model_api:Running greedy tracker\n",
      "INFO:trackastra.tracking.tracking:Build candidate graph with delta_t=1\n",
      "INFO:trackastra.tracking.tracking:Added 130836 vertices, 139397 edges                                                  \n",
      "INFO:trackastra.tracking.ilp:Using `gt` ILP config.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Solver' object has no attribute 'add_costs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:168\u001b[0m, in \u001b[0;36mTrackastra.track\u001b[0;34m(self, imgs, masks, mode, progbar_class, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack\u001b[39m(\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    161\u001b[0m     imgs: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TrackGraph:\n\u001b[1;32m    167\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(imgs, masks, progbar_class\u001b[38;5;241m=\u001b[39mprogbar_class)\n\u001b[0;32m--> 168\u001b[0m     track_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_from_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m track_graph\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/model/model_api.py:155\u001b[0m, in \u001b[0;36mTrackastra._track_from_predictions\u001b[0;34m(self, predictions, mode, use_distance, max_distance, max_neighbors, delta_t, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124milp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrackastra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01milp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_ilp\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrack_ilp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43milp_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracking mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/tracking/ilp.py:72\u001b[0m, in \u001b[0;36mtrack_ilp\u001b[0;34m(candidate_graph, allow_divisions, ilp_config, params_file, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrack_ilp\u001b[39m(\n\u001b[1;32m     64\u001b[0m     candidate_graph,\n\u001b[1;32m     65\u001b[0m     allow_divisions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     69\u001b[0m ):\n\u001b[1;32m     70\u001b[0m     candidate_graph_motile \u001b[38;5;241m=\u001b[39m motile\u001b[38;5;241m.\u001b[39mTrackGraph(candidate_graph, frame_attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m     ilp, _used_costs \u001b[38;5;241m=\u001b[39m \u001b[43msolve_full_ilp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_graph_motile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_divisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43milp_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     print_solution_stats(ilp, candidate_graph_motile)\n\u001b[1;32m     80\u001b[0m     graph \u001b[38;5;241m=\u001b[39m solution_to_graph(ilp, candidate_graph_motile)\n",
      "File \u001b[0;32m~/miniconda3/envs/godspeed/lib/python3.10/site-packages/trackastra/tracking/ilp.py:112\u001b[0m, in \u001b[0;36msolve_full_ilp\u001b[0;34m(graph, allow_divisions, mode, params_file)\u001b[0m\n\u001b[1;32m    109\u001b[0m used_costs \u001b[38;5;241m=\u001b[39m SimpleNamespace()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# NODES\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_costs\u001b[49m(\n\u001b[1;32m    113\u001b[0m     motile\u001b[38;5;241m.\u001b[39mcosts\u001b[38;5;241m.\u001b[39mNodeSelection(weight\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mnodeW, constant\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mnodeC, attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m used_costs\u001b[38;5;241m.\u001b[39mnodeW \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mnodeW\n\u001b[1;32m    116\u001b[0m used_costs\u001b[38;5;241m.\u001b[39mnodeC \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mnodeC\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Solver' object has no attribute 'add_costs'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load a pretrained model\n",
    "model = Trackastra.from_pretrained(\"general_2d\", device=device)\n",
    "\n",
    "# or from a local folder\n",
    "# model = Trackastra.from_folder('path/my_model_folder/', device=device)\n",
    "\n",
    "# Track the cells\n",
    "track_graph = model.track(segmentation_input, cellpose_segmentation, mode=\"ilp\")  # or mode=\"ilp\", or \"greedy_nodiv\"\n",
    "\n",
    "\n",
    "# Write to cell tracking challenge format\n",
    "ctc_tracks, masks_tracked = graph_to_ctc(\n",
    "      track_graph,\n",
    "      masks,\n",
    "      outdir=\"tracked\",\n",
    ")\n",
    "\n",
    "# Visualise in napari\n",
    "napari_tracks, napari_tracks_graph, _ = graph_to_napari_tracks(track_graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "951ec420-bc1d-460d-bd6b-263ae5cad204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 6048, 6048)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trackastra.model.model:Loading model state from /home/dayn/.trackastra/.models/general_2d/model.pt\n",
      "INFO:trackastra.model.model_api:Using device cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dayn/.trackastra/.models/general_2d already downloaded, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trackastra.model.model_api:Predicting weights for candidate graph\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking with mode greedy_nodiv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trackastra.data.wrfeat:Extracting features from 154 detections\n",
      "INFO:trackastra.data.wrfeat:Using single process for feature extraction\n",
      "INFO:trackastra.model.model_api:Building windows\n",
      "INFO:trackastra.model.model_api:Predicting windows\n",
      "INFO:trackastra.model.model_api:Running greedy tracker\n",
      "INFO:trackastra.tracking.tracking:Build candidate graph with delta_t=1\n",
      "INFO:trackastra.tracking.tracking:Added 130836 vertices, 132759 edges                                                  \n",
      "INFO:trackastra.tracking.tracking:Running greedy tracker\n",
      "Greedily matched edges:  94%|███████████████████████████████████████████▉   | 124265/132759 [00:03<00:00, 32865.63it/s]\n",
      "Converting graph to CTC results: 100%|████████████████████████████████████████████| 6979/6979 [00:13<00:00, 507.00it/s]\n",
      "INFO:napari_ctc_io._writer:Writing CTC format to /home/dayn/analysis/macrohet                                          \n",
      "INFO:napari_ctc_io._writer:Writing CTC format to /home/dayn/analysis/macrohet\n"
     ]
    }
   ],
   "source": [
    "cellpose_segmentation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d819808-ad72-4b5a-8a43-62f2c0f62c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "v = napari.Viewer()\n",
    "v.add_image(imgs)\n",
    "v.add_labels(masks_tracked)\n",
    "v.add_tracks(data=napari_tracks, graph=napari_tracks_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4cd6c31-1c23-4df9-b9fd-746ccb3a3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = viewer.layers['tracks'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d5ea3d8-2338-4ef9-87cb-a54ca7a22f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 5.63499262e+03, 5.98160372e+03],\n",
       "       [1.00000000e+00, 1.00000000e+00, 5.62536602e+03, 5.96917297e+03],\n",
       "       [1.00000000e+00, 2.00000000e+00, 5.61263586e+03, 5.95262619e+03],\n",
       "       ...,\n",
       "       [6.97800000e+03, 1.53000000e+02, 5.03416957e+03, 5.25425019e+03],\n",
       "       [6.97900000e+03, 1.52000000e+02, 5.29644164e+03, 6.23781633e+02],\n",
       "       [6.97900000e+03, 1.53000000e+02, 5.32309206e+03, 6.78151989e+02]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5e152b4-cd9b-4c1b-8acf-43c3c0d8639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "25cd3879-a658-47d6-8378-a0afabb26bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ztracks_df = pd.DataFrame(tracks, columns=['ID', 'T', 'X', 'Y'])\n",
    "ztracks_df.to_csv('/mnt/SYNO/macrohet_syno/data/ND0004/labels/testing_trackastra/ztracks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "godspeed",
   "language": "python",
   "name": "godspeed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
