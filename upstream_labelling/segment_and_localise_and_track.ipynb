{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e295e0",
   "metadata": {},
   "source": [
    "# Segment, localise and track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988f1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA RTX A6000\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.1 GB\n"
     ]
    }
   ],
   "source": [
    "from macrohet import dataio, tile, notify\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from cellpose import models\n",
    "import btrack \n",
    "import torch\n",
    "import os\n",
    "import dask.array as da\n",
    "import glob\n",
    "import zarr\n",
    "import logging\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "# # defining personal trained cellpose model to use\n",
    "# model_path = '/home/dayn/analysis/models/cellpose/PS0000/macrohet_seg'\n",
    "# model = models.CellposeModel(gpu=True, \n",
    "#                              pretrained_model=model_path)\n",
    "\n",
    "# ORRRR test the new cellpose model\n",
    "model = models.Cellpose(gpu=True, model_type='cyto3')\n",
    "\n",
    "# Initialize the logging configuration\n",
    "log_dir = \"logs\"  # Specify the directory where logs will be saved\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s]: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "logging.getLogger('cellpose').setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "# Add a FileHandler to save logs to a file in the specified directory\n",
    "log_file = os.path.join(log_dir, \"assay_processing.log\")\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s [%(levelname)s]: %(message)s\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(file_handler)\n",
    "\n",
    "# Define a function to log progress and potential errors\n",
    "def log_progress(position, message):\n",
    "    logging.info(f\"Position {position}: {message}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76982865",
   "metadata": {},
   "source": [
    "### Define functions to tidy up main block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65275f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds\n",
    "segment_size_thresh = 5000\n",
    "Mtb_load_thresh = 480\n",
    "\n",
    "# define tracking scale factor\n",
    "scale_factor = 1/5.04\n",
    "\n",
    "# define features to use for tracking \n",
    "features = [\n",
    "  \"area\",\n",
    "  \"major_axis_length\",\n",
    "  \"minor_axis_length\",\n",
    "  \"orientation\",\n",
    "  \"mean_intensity\",\n",
    "    ]\n",
    "\n",
    "# define tracker config fn to use, using a prob_not_assign = 0.1\n",
    "config_fn = '/home/dayn/analysis/models/btrack/particle_config_pnassign.json'\n",
    "# define tracker config fn to use\n",
    "# config_fn = '/home/dayn/analysis/btrack/models/particle_config.json'\n",
    "\n",
    "def segment(frame, model = model, channels = [0,0], diameter = 350, #250 #325\n",
    "            min_size = 5000, model_type = 'pretrained'\n",
    "           ):\n",
    "    \n",
    "    if model_type == 'pretrained':\n",
    "        \n",
    "        masks, flows, styles, diams = model.eval(frame, # for default models\n",
    "                                                 channels = channels, \n",
    "                                                 diameter = diameter, \n",
    "                                                 min_size = min_size, \n",
    "                                                 )\n",
    "        \n",
    "        \n",
    "    else:\n",
    "\n",
    "        masks, flows, styles = model.eval(frame, # for personal model\n",
    "                                          channels = channels, \n",
    "                                          diameter = diameter, \n",
    "                                          min_size = min_size, \n",
    "                                          )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def localise(masks, intensity_image, properties=tuple(features), use_weighted_centroid = False):\n",
    "    \n",
    "    # localise objs in images\n",
    "    objects = btrack.utils.segmentation_to_objects(segmentation=masks,\n",
    "                                                   intensity_image=intensity_image, \n",
    "                                                   properties=properties,\n",
    "                                                   scale=(scale_factor,scale_factor),\n",
    "                                                   use_weighted_centroid=use_weighted_centroid, \n",
    "                                                   )\n",
    "                                                   \n",
    "    return objects\n",
    "\n",
    "\n",
    "def track(objects, masks, config_fn, search_radius = 20):\n",
    "\n",
    "    # initialise a tracker session using a context manager\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure(config_fn)\n",
    "        # set max search radius\n",
    "        tracker.max_search_radius = search_radius\n",
    "        # define tracking method\n",
    "        tracker.tracking_updates = [\"MOTION\", \"VISUAL\"]\n",
    "        # redefine features so that both channels are included in track measurements\n",
    "        tracker.features = list(objects[0].properties.keys())\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects)\n",
    "        # set the tracking volume\n",
    "        tracker.volume=((0, masks.shape[-2]*scale_factor), (0, masks.shape[-1]*scale_factor))\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=25)\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "        # store the tracks\n",
    "        tracks = tracker.tracks\n",
    "\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def otsu_threshold_stack(images):\n",
    "    \"\"\"\n",
    "    Function to characterise intra-Mφ Mtb load\n",
    "    Computes Otsu's threshold value and returns a binary segmentation for\n",
    "    each image in a time series of grayscale images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : ndarray\n",
    "        A 3D array of shape (n_images, height, width) containing a time series\n",
    "        of grayscale images.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ndarray\n",
    "        A boolean array of shape (n_images, height, width) containing the\n",
    "        binary segmentation for each image in the time series.\n",
    "    \"\"\"\n",
    "    segmentations = np.zeros(images.shape, dtype=bool)\n",
    "    for i, image in tqdm(enumerate(images), \n",
    "                         total=len(images), \n",
    "                         leave=False, \n",
    "                         desc='Otsu segmenting'):\n",
    "        loaded_image = image.compute().compute()\n",
    "        threshold = threshold_otsu(loaded_image)\n",
    "        segmentations[i] = loaded_image > threshold\n",
    "        \n",
    "    return segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751ef77",
   "metadata": {},
   "source": [
    "### Load experiment of choice\n",
    "\n",
    "The Opera Phenix is a high-throughput confocal microscope that acquires very large 5-dimensional (TCZXY) images over several fields of view in any one experiment. Therefore, a lazy-loading approach is chosen to mosaic, view and annotate these images. This approach depends upon Dask and DaskFusion. The first step is to load the main metadata file (typically called `Index.idx.xml` and located in the main `Images` directory) that contains the image filenames and associated TCXZY information used to organise the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d20db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab24ae0864db46ac95b6c2b8b38ef2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>State</th>\n",
       "      <th>URL</th>\n",
       "      <th>Row</th>\n",
       "      <th>Col</th>\n",
       "      <th>FieldID</th>\n",
       "      <th>PlaneID</th>\n",
       "      <th>TimepointID</th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>FlimID</th>\n",
       "      <th>...</th>\n",
       "      <th>PositionZ</th>\n",
       "      <th>AbsPositionZ</th>\n",
       "      <th>MeasurementTimeOffset</th>\n",
       "      <th>AbsTime</th>\n",
       "      <th>MainExcitationWavelength</th>\n",
       "      <th>MainEmissionWavelength</th>\n",
       "      <th>ObjectiveMagnification</th>\n",
       "      <th>ObjectiveNA</th>\n",
       "      <th>ExposureTime</th>\n",
       "      <th>OrientationMatrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0301K1F1P1R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c01f01p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135243401</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-17T15:13:28.903+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0301K1F1P1R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c01f01p01-ch2sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135243401</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-17T15:13:29.123+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0301K1F1P2R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c01f01p02-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135245398</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-17T15:13:29.467+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0301K1F1P2R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c01f01p02-ch2sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135245398</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-17T15:13:29.7+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0301K1F1P3R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r03c01f01p03-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4E-06</td>\n",
       "      <td>0.135247394</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-17T15:13:30.043+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349267</th>\n",
       "      <td>0612K154F9P1R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p01-ch2sk154fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1350099</td>\n",
       "      <td>275404.583</td>\n",
       "      <td>2024-04-20T19:57:46.98+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349268</th>\n",
       "      <td>0612K154F9P2R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p02-ch1sk154fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135011896</td>\n",
       "      <td>275404.583</td>\n",
       "      <td>2024-04-20T19:57:47.323+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349269</th>\n",
       "      <td>0612K154F9P2R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p02-ch2sk154fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135011896</td>\n",
       "      <td>275404.583</td>\n",
       "      <td>2024-04-20T19:57:47.557+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349270</th>\n",
       "      <td>0612K154F9P3R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p03-ch1sk154fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4E-06</td>\n",
       "      <td>0.135013893</td>\n",
       "      <td>275404.583</td>\n",
       "      <td>2024-04-20T19:57:47.9+01:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349271</th>\n",
       "      <td>0612K154F9P3R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p03-ch2sk154fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4E-06</td>\n",
       "      <td>0.135013893</td>\n",
       "      <td>275404.583</td>\n",
       "      <td>2024-04-20T19:57:48.12+01:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349272 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id State                               URL Row Col  \\\n",
       "0         0301K1F1P1R1    Ok    r03c01f01p01-ch1sk1fk1fl1.tiff   3   1   \n",
       "1         0301K1F1P1R2    Ok    r03c01f01p01-ch2sk1fk1fl1.tiff   3   1   \n",
       "2         0301K1F1P2R1    Ok    r03c01f01p02-ch1sk1fk1fl1.tiff   3   1   \n",
       "3         0301K1F1P2R2    Ok    r03c01f01p02-ch2sk1fk1fl1.tiff   3   1   \n",
       "4         0301K1F1P3R1    Ok    r03c01f01p03-ch1sk1fk1fl1.tiff   3   1   \n",
       "...                ...   ...                               ...  ..  ..   \n",
       "349267  0612K154F9P1R2    Ok  r06c12f09p01-ch2sk154fk1fl1.tiff   6  12   \n",
       "349268  0612K154F9P2R1    Ok  r06c12f09p02-ch1sk154fk1fl1.tiff   6  12   \n",
       "349269  0612K154F9P2R2    Ok  r06c12f09p02-ch2sk154fk1fl1.tiff   6  12   \n",
       "349270  0612K154F9P3R1    Ok  r06c12f09p03-ch1sk154fk1fl1.tiff   6  12   \n",
       "349271  0612K154F9P3R2    Ok  r06c12f09p03-ch2sk154fk1fl1.tiff   6  12   \n",
       "\n",
       "       FieldID PlaneID TimepointID ChannelID FlimID  ... PositionZ  \\\n",
       "0            1       1           0         1      1  ...         0   \n",
       "1            1       1           0         2      1  ...         0   \n",
       "2            1       2           0         1      1  ...     2E-06   \n",
       "3            1       2           0         2      1  ...     2E-06   \n",
       "4            1       3           0         1      1  ...     4E-06   \n",
       "...        ...     ...         ...       ...    ...  ...       ...   \n",
       "349267       9       1         153         2      1  ...         0   \n",
       "349268       9       2         153         1      1  ...     2E-06   \n",
       "349269       9       2         153         2      1  ...     2E-06   \n",
       "349270       9       3         153         1      1  ...     4E-06   \n",
       "349271       9       3         153         2      1  ...     4E-06   \n",
       "\n",
       "       AbsPositionZ MeasurementTimeOffset                        AbsTime  \\\n",
       "0       0.135243401                     0  2024-04-17T15:13:28.903+01:00   \n",
       "1       0.135243401                     0  2024-04-17T15:13:29.123+01:00   \n",
       "2       0.135245398                     0  2024-04-17T15:13:29.467+01:00   \n",
       "3       0.135245398                     0    2024-04-17T15:13:29.7+01:00   \n",
       "4       0.135247394                     0  2024-04-17T15:13:30.043+01:00   \n",
       "...             ...                   ...                            ...   \n",
       "349267    0.1350099            275404.583   2024-04-20T19:57:46.98+01:00   \n",
       "349268  0.135011896            275404.583  2024-04-20T19:57:47.323+01:00   \n",
       "349269  0.135011896            275404.583  2024-04-20T19:57:47.557+01:00   \n",
       "349270  0.135013893            275404.583    2024-04-20T19:57:47.9+01:00   \n",
       "349271  0.135013893            275404.583   2024-04-20T19:57:48.12+01:00   \n",
       "\n",
       "       MainExcitationWavelength MainEmissionWavelength ObjectiveMagnification  \\\n",
       "0                           640                    706                     40   \n",
       "1                           488                    522                     40   \n",
       "2                           640                    706                     40   \n",
       "3                           488                    522                     40   \n",
       "4                           640                    706                     40   \n",
       "...                         ...                    ...                    ...   \n",
       "349267                      488                    522                     40   \n",
       "349268                      640                    706                     40   \n",
       "349269                      488                    522                     40   \n",
       "349270                      640                    706                     40   \n",
       "349271                      488                    522                     40   \n",
       "\n",
       "       ObjectiveNA ExposureTime  \\\n",
       "0              1.1          0.2   \n",
       "1              1.1          0.1   \n",
       "2              1.1          0.2   \n",
       "3              1.1          0.1   \n",
       "4              1.1          0.2   \n",
       "...            ...          ...   \n",
       "349267         1.1          0.1   \n",
       "349268         1.1          0.2   \n",
       "349269         1.1          0.1   \n",
       "349270         1.1          0.2   \n",
       "349271         1.1          0.1   \n",
       "\n",
       "                                        OrientationMatrix  \n",
       "0       [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "1       [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "2       [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "3       [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "4       [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "...                                                   ...  \n",
       "349267  [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "349268  [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "349269  [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "349270  [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "349271  [[0.999619,0,0,-5.1],[0,-0.999619,0,-2.5],[0,0...  \n",
       "\n",
       "[349272 rows x 35 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '/mnt/SYNO/macrohet_syno/data/ND0004/'\n",
    "metadata_fn = os.path.join(base_dir, 'acquisition/Images/Index.idx.xml')\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739b419",
   "metadata": {},
   "source": [
    "### View assay layout and mask information (optional)\n",
    "\n",
    "The Opera Phenix acquires many time lapse series from a range of positions. The first step is to inspect the image metadata, presented in the form of an `Assaylayout/experiment_ID.xml` file, to show which positions correspond to which experimental assays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c540d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n",
      "Extracting metadata complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>ConcentrationEC</th>\n",
       "      <th>Replicate #</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>UNI</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNI</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">4</th>\n",
       "      <th>3</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">5</th>\n",
       "      <th>3</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">6</th>\n",
       "      <th>3</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Strain Compound Concentration ConcentrationEC  Replicate #\n",
       "Row Column                                                           \n",
       "3   1         UNI     CTRL             0             EC0            1\n",
       "    2         UNI     CTRL             0             EC0            2\n",
       "    3          WT     CTRL             0             EC0            1\n",
       "    4          WT     CTRL             0             EC0            2\n",
       "    5          WT      PZA            60            EC50            1\n",
       "    6          WT      PZA            60            EC50            2\n",
       "    7          WT      RIF           0.1            EC50            1\n",
       "    8          WT      RIF           0.1            EC50            2\n",
       "    9          WT      INH          0.04            EC50            1\n",
       "    10         WT      INH          0.04            EC50            2\n",
       "    11         WT      BDQ          0.02            EC50            1\n",
       "    12         WT      BDQ          0.02            EC50            2\n",
       "4   3          WT     CTRL             0             EC0            3\n",
       "    4          WT     CTRL             0             EC0            4\n",
       "    5          WT      PZA           400            EC99            1\n",
       "    6          WT      PZA           400            EC99            2\n",
       "    7          WT      RIF             2            EC99            1\n",
       "    8          WT      RIF             2            EC99            2\n",
       "    9          WT      INH             2            EC99            1\n",
       "    10         WT      INH             2            EC99            2\n",
       "    11         WT      BDQ           2.5            EC99            1\n",
       "    12         WT      BDQ           2.5            EC99            2\n",
       "5   3         RD1     CTRL             0             EC0            1\n",
       "    4         RD1     CTRL             0             EC0            2\n",
       "    5         RD1      PZA            60            EC50            1\n",
       "    6         RD1      PZA            60            EC50            2\n",
       "    7         RD1      RIF           0.1            EC50            1\n",
       "    8         RD1      RIF           0.1            EC50            2\n",
       "    9         RD1      INH          0.04            EC50            1\n",
       "    10        RD1      INH          0.04            EC50            2\n",
       "    11        RD1      BDQ          0.02            EC50            1\n",
       "    12        RD1      BDQ          0.02            EC50            2\n",
       "6   3         RD1     CTRL             0             EC0            3\n",
       "    4         RD1     CTRL             0             EC0            4\n",
       "    5         RD1      PZA           400            EC99            1\n",
       "    6         RD1      PZA           400            EC99            2\n",
       "    7         RD1      RIF             2            EC99            1\n",
       "    8         RD1      RIF             2            EC99            2\n",
       "    9         RD1      INH             2            EC99            1\n",
       "    10        RD1      INH             2            EC99            2\n",
       "    11        RD1      BDQ           2.5            EC99            1\n",
       "    12        RD1      BDQ           2.5            EC99            2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "assay_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45221981",
   "metadata": {},
   "source": [
    "# Segment, localise and track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451353a1-ce0a-46d6-aef0-377f9c3a017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_channel = 0\n",
    "gfp_channel = 1\n",
    "manual_mtb_thresh_channel = 2\n",
    "output_dirname = 'cpv3' #'cpv3_smaller_diam' #'cpv3'\n",
    "# make output directory and subdirs \n",
    "os.makedirs(os.path.join(base_dir, f'labels/{output_dirname}/backup'), exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d746c3b-a9b8-49a7-9f80-81501d8ef9a5",
   "metadata": {},
   "source": [
    "# Iterate over all positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7290f4e4-3031-418e-aa6d-ef532d0a2af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2948ff33e443e5974ba66630cb7bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress through positions:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Position (3, 1): Starting new acquisition\n",
      "INFO:root:Position (3, 1): Skipping already processed\n",
      "INFO:root:Position (3, 2): Starting new acquisition\n",
      "INFO:root:Position (3, 2): Skipping already processed\n",
      "INFO:root:Position (3, 3): Starting new acquisition\n",
      "INFO:root:Position (3, 3): Skipping already processed\n",
      "INFO:root:Position (3, 4): Starting new acquisition\n",
      "INFO:root:Position (3, 4): Skipping already processed\n",
      "INFO:root:Position (3, 5): Starting new acquisition\n",
      "INFO:root:Position (3, 5): Skipping already processed\n",
      "INFO:root:Position (3, 6): Starting new acquisition\n",
      "INFO:root:Position (3, 6): Skipping already processed\n",
      "INFO:root:Position (3, 7): Starting new acquisition\n",
      "INFO:root:Position (3, 7): Skipping already processed\n",
      "INFO:root:Position (3, 8): Starting new acquisition\n",
      "INFO:root:Position (3, 8): Skipping already processed\n",
      "INFO:root:Position (3, 9): Starting new acquisition\n",
      "INFO:root:Position (3, 9): Skipping already processed\n",
      "INFO:root:Position (3, 10): Starting new acquisition\n",
      "INFO:root:Position (3, 10): Skipping already processed\n",
      "INFO:root:Position (3, 11): Starting new acquisition\n",
      "INFO:root:Position (3, 11): Skipping already processed\n",
      "INFO:root:Position (3, 12): Starting new acquisition\n",
      "INFO:root:Position (3, 12): Skipping already processed\n",
      "INFO:root:Position (4, 3): Starting new acquisition\n",
      "INFO:root:Position (4, 3): Skipping already processed\n",
      "INFO:root:Position (4, 4): Starting new acquisition\n",
      "INFO:root:Position (4, 4): Skipping already processed\n",
      "INFO:root:Position (4, 5): Starting new acquisition\n",
      "INFO:root:Position (4, 5): Skipping already processed\n",
      "INFO:root:Position (4, 6): Starting new acquisition\n",
      "INFO:root:Position (4, 6): Skipping already processed\n",
      "INFO:root:Position (4, 7): Starting new acquisition\n",
      "INFO:root:Position (4, 7): Skipping already processed\n",
      "INFO:root:Position (4, 8): Starting new acquisition\n",
      "INFO:root:Position (4, 8): Skipping already processed\n",
      "INFO:root:Position (4, 9): Starting new acquisition\n",
      "INFO:root:Position (4, 9): Skipping already processed\n",
      "INFO:root:Position (4, 10): Starting new acquisition\n",
      "INFO:root:Position (4, 10): Skipping already processed\n",
      "INFO:root:Position (4, 11): Starting new acquisition\n",
      "INFO:root:Position (4, 11): Skipping already processed\n",
      "INFO:root:Position (4, 12): Starting new acquisition\n",
      "INFO:root:Position (4, 12): Images loaded and stacked\n",
      "INFO:root:Position (4, 12): Starting segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce5beea3888485f8178a4726c613cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Segmenting:   0%|          | 0/154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Position (4, 12): Processing failed: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacty of 47.43 GiB of which 240.12 MiB is free. Process 8469 has 34.70 GiB memory in use. Including non-PyTorch memory, this process has 11.66 GiB memory in use. Of the allocated memory 11.08 GiB is allocated by PyTorch, and 262.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "INFO:root:Position (5, 3): Starting new acquisition\n"
     ]
    }
   ],
   "source": [
    "# Inside your loop, use the log_progress function to log progress and errors\n",
    "for (row, column), info in tqdm(assay_layout.iterrows(), desc='Progress through positions', total=len(assay_layout)):\n",
    "    try:\n",
    "        acq_ID = (row, column)\n",
    "        log_progress(acq_ID, \"Starting new acquisition\")\n",
    "        \n",
    "        # if info['Strain'] == 'UNI':\n",
    "        #     log_progress(acq_ID, \"Skipping uninfected acquisition for now\")\n",
    "        #     continue\n",
    "        # if acq_ID in already_processed_acq_IDs:\n",
    "        #     log_progress(acq_ID, \"Skipping already processed\")\n",
    "        #     continue\n",
    "        if os.path.exists(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}.h5')):\n",
    "            log_progress(acq_ID, \"Skipping already processed\")\n",
    "            continue\n",
    "\n",
    "        # process images using zarr\n",
    "        image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "        zarr_store = zarr.open(image_dir, mode='r')\n",
    "        images = zarr_store.images\n",
    "        # create a max projection\n",
    "        images = np.max(images, axis = 2)\n",
    "        \n",
    "        log_progress(acq_ID, \"Images loaded and stacked\")\n",
    "        \n",
    "        # check if already segmented using m2 model\n",
    "        #     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}.h5')):\n",
    "        #         continue\n",
    "        #     else:\n",
    "        log_progress(acq_ID, \"Starting segmentation\")\n",
    "        \n",
    "        #     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5')):\n",
    "        #         with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5'), \n",
    "        #                                        'r', \n",
    "        #                                        obj_type='obj_type_1'\n",
    "        #                                        ) as reader:\n",
    "        # #             writer.write_objects(objects)\n",
    "        #             # writer.write_tracks(tracks)\n",
    "        #             masks = reader.segmentation\n",
    "        #         log_progress(acq_ID, \"Loaded previously calculated segmentation\")\n",
    "        #     else:\n",
    "        # segment images from gfp channel only\n",
    "        masks = np.stack([segment(frame) \n",
    "                          for frame in tqdm(images[:,gfp_channel,...],  # segmenting the GFP channel \n",
    "                                            desc = 'Segmenting')])\n",
    "        \n",
    "        log_progress(acq_ID, \"Finished segmentation\")\n",
    "        \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}_cpv3_mask_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "        #             writer.write_objects(objects)\n",
    "                # writer.write_tracks(tracks)\n",
    "                writer.write_segmentation(masks)\n",
    "            \n",
    "        log_progress(acq_ID, \"Saved out masks\")  \n",
    "        \n",
    "        log_progress(acq_ID, \"Measuring Mtb area\")       \n",
    "        \n",
    "        # characterise Mtb growth using Otsu segmentation\n",
    "        # otsu_mtb = otsu_threshold(images[:,1,...]) # time consuming and non-deterministic when compared to hardcoded, could result in different thresholds for same image? \n",
    "        # characterise Mtb growth using hardcoded threshold :S\n",
    "        manual_mtb_thresh = np.where(images[:,mtb_channel,...] >= Mtb_load_thresh, True, False)\n",
    "        log_progress(acq_ID, \"Creating intensity image for localisation\")  \n",
    "        # reshape intensity image to be gfp, rfp on last axis for regionprops\n",
    "        intensity_image = np.stack([images[:,0,...], \n",
    "                                    images[:,1,...],  \n",
    "        #                                 otsu_mtb, \n",
    "                                    manual_mtb_thresh], axis = -1)\n",
    "        log_progress(acq_ID, \"Localising objects\")  \n",
    "        # localise objects\n",
    "        objects = localise(masks, \n",
    "                           intensity_image, \n",
    "                           )\n",
    "        log_progress(acq_ID, \"Filtering small objects\")  \n",
    "        # filter out small objects\n",
    "        objects = [o for o in objects if o.properties['area'] > segment_size_thresh]\n",
    "        \n",
    "        log_progress(acq_ID, \"Adding infection labels to objects\")  \n",
    "        # add label for infection\n",
    "        for obj in objects:\n",
    "            obj.properties = ({\"Infected\": True} \n",
    "                                if obj.properties['mean_intensity'][manual_mtb_thresh_channel] > 0 # index 2 for manual mtb channel \n",
    "                                else {\"Infected\": False})\n",
    "            obj.properties = ({\"Mtb area px\": obj.properties['mean_intensity'][manual_mtb_thresh_channel]*obj.properties['area']})\n",
    "        \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/backup/{row, column}_cpv3_objects_backup.h5'), \n",
    "                                                   'w', \n",
    "                                                   obj_type='obj_type_1'\n",
    "                                                   ) as writer:\n",
    "                        writer.write_objects(objects)\n",
    "                        # writer.write_tracks(tracks)\n",
    "        \n",
    "        log_progress(acq_ID, \"Beginning tracking\")  \n",
    "        # track on upscaled config fn\n",
    "        tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "        log_progress(acq_ID, \"Saving tracking\")  \n",
    "        # save out \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/backup/{row, column}_cpv3_tracks_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "        #             writer.write_objects(objects)\n",
    "                writer.write_tracks(tracks)\n",
    "                # writer.write_segmentation(masks)\n",
    "        # Log successful completion\n",
    "        \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/{output_dirname}/{row, column}.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "                    writer.write_tracks(tracks)\n",
    "                    writer.write_segmentation(masks)\n",
    "        # Log successful completion\n",
    "        log_progress(acq_ID, \"Processing completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log errors\n",
    "        log_progress(acq_ID, f\"Processing failed: {str(e)}\")\n",
    "\n",
    "# You can also log information before and after the loop\n",
    "logging.info(\"Processing completed\")\n",
    "\n",
    "# Notify if required\n",
    "notify.send_sms(\"Processing completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22fb78-7663-44e7-8035-978d9c5c5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg",
   "language": "python",
   "name": "egg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
