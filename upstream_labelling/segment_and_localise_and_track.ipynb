{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e295e0",
   "metadata": {},
   "source": [
    "# Segment, localise and track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988f1019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "NVIDIA RTX A6000\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellpose.core:** TORCH CUDA version installed and working. **\n",
      "INFO:cellpose.core:>>>> using GPU\n",
      "INFO:cellpose.models:>> cyto3 << model set to be used\n",
      "INFO:cellpose.models:>>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    }
   ],
   "source": [
    "from macrohet import dataio, tile, notify\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from cellpose import models\n",
    "import btrack \n",
    "import torch\n",
    "import os\n",
    "import dask.array as da\n",
    "import glob\n",
    "import zarr\n",
    "import logging\n",
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "# # defining personal trained cellpose model to use\n",
    "# model_path = '/home/dayn/analysis/models/cellpose/PS0000/macrohet_seg'\n",
    "# model = models.CellposeModel(gpu=True, \n",
    "#                              pretrained_model=model_path)\n",
    "\n",
    "# ORRRR test the new cellpose model\n",
    "model = models.Cellpose(gpu=True, model_type='cyto3')\n",
    "\n",
    "# Initialize the logging configuration\n",
    "log_dir = \"logs\"  # Specify the directory where logs will be saved\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s]: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "# Add a FileHandler to save logs to a file in the specified directory\n",
    "log_file = os.path.join(log_dir, \"assay_processing.log\")\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s [%(levelname)s]: %(message)s\")\n",
    "file_handler.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(file_handler)\n",
    "\n",
    "# Define a function to log progress and potential errors\n",
    "def log_progress(position, message):\n",
    "    logging.info(f\"Position {position}: {message}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76982865",
   "metadata": {},
   "source": [
    "### Define functions to tidy up main block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65275f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define thresholds\n",
    "segment_size_thresh = 5000\n",
    "Mtb_load_thresh = 480\n",
    "\n",
    "# define tracking scale factor\n",
    "scale_factor = 1/5.04\n",
    "\n",
    "# define features to use for tracking \n",
    "features = [\n",
    "  \"area\",\n",
    "  \"major_axis_length\",\n",
    "  \"minor_axis_length\",\n",
    "  \"orientation\",\n",
    "  \"mean_intensity\",\n",
    "    ]\n",
    "\n",
    "# define tracker config fn to use, using a prob_not_assign = 0.1\n",
    "config_fn = '/home/dayn/analysis/models/btrack/particle_config_pnassign.json'\n",
    "# define tracker config fn to use\n",
    "# config_fn = '/home/dayn/analysis/btrack/models/particle_config.json'\n",
    "\n",
    "def segment(frame, model = model, channels = [0,0], diameter = 350,#325\n",
    "            min_size = 5000, model_type = 'pretrained'\n",
    "           ):\n",
    "    \n",
    "    if model_type == 'pretrained':\n",
    "        \n",
    "        masks, flows, styles = model.eval(frame, # for default model\n",
    "                                          channels = channels, \n",
    "                                          diameter = diameter, \n",
    "                                          min_size = min_size, \n",
    "                                          )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        masks, flows, styles, diams = model.eval(frame, # for personal model\n",
    "                                                 channels = channels, \n",
    "                                                 diameter = diameter, \n",
    "                                                 min_size = min_size, \n",
    "                                                 )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def localise(masks, intensity_image, properties=tuple(features), use_weighted_centroid = False):\n",
    "    \n",
    "    # localise objs in images\n",
    "    objects = btrack.utils.segmentation_to_objects(segmentation=masks,\n",
    "                                                   intensity_image=intensity_image, \n",
    "                                                   properties=properties,\n",
    "                                                   scale=(scale_factor,scale_factor),\n",
    "                                                   use_weighted_centroid=use_weighted_centroid, \n",
    "                                                   )\n",
    "                                                   \n",
    "    return objects\n",
    "\n",
    "\n",
    "def track(objects, masks, config_fn, search_radius = 20):\n",
    "\n",
    "    # initialise a tracker session using a context manager\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure(config_fn)\n",
    "        # set max search radius\n",
    "        tracker.max_search_radius = search_radius\n",
    "        # define tracking method\n",
    "        tracker.tracking_updates = [\"MOTION\", \"VISUAL\"]\n",
    "        # redefine features so that both channels are included in track measurements\n",
    "        tracker.features = list(objects[0].properties.keys())\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects)\n",
    "        # set the tracking volume\n",
    "        tracker.volume=((0, masks.shape[-2]*scale_factor), (0, masks.shape[-1]*scale_factor))\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=25)\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "        # store the tracks\n",
    "        tracks = tracker.tracks\n",
    "\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def otsu_threshold_stack(images):\n",
    "    \"\"\"\n",
    "    Function to characterise intra-Mφ Mtb load\n",
    "    Computes Otsu's threshold value and returns a binary segmentation for\n",
    "    each image in a time series of grayscale images.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : ndarray\n",
    "        A 3D array of shape (n_images, height, width) containing a time series\n",
    "        of grayscale images.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    ndarray\n",
    "        A boolean array of shape (n_images, height, width) containing the\n",
    "        binary segmentation for each image in the time series.\n",
    "    \"\"\"\n",
    "    segmentations = np.zeros(images.shape, dtype=bool)\n",
    "    for i, image in tqdm(enumerate(images), \n",
    "                         total=len(images), \n",
    "                         leave=False, \n",
    "                         desc='Otsu segmenting'):\n",
    "        loaded_image = image.compute().compute()\n",
    "        threshold = threshold_otsu(loaded_image)\n",
    "        segmentations[i] = loaded_image > threshold\n",
    "        \n",
    "    return segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3751ef77",
   "metadata": {},
   "source": [
    "### Load experiment of choice\n",
    "\n",
    "The Opera Phenix is a high-throughput confocal microscope that acquires very large 5-dimensional (TCZXY) images over several fields of view in any one experiment. Therefore, a lazy-loading approach is chosen to mosaic, view and annotate these images. This approach depends upon Dask and DaskFusion. The first step is to load the main metadata file (typically called `Index.idx.xml` and located in the main `Images` directory) that contains the image filenames and associated TCXZY information used to organise the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d20db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b29f7fb169a42a4afa3206be2a2e84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>State</th>\n",
       "      <th>URL</th>\n",
       "      <th>Row</th>\n",
       "      <th>Col</th>\n",
       "      <th>FieldID</th>\n",
       "      <th>PlaneID</th>\n",
       "      <th>TimepointID</th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>FlimID</th>\n",
       "      <th>...</th>\n",
       "      <th>PositionZ</th>\n",
       "      <th>AbsPositionZ</th>\n",
       "      <th>MeasurementTimeOffset</th>\n",
       "      <th>AbsTime</th>\n",
       "      <th>MainExcitationWavelength</th>\n",
       "      <th>MainEmissionWavelength</th>\n",
       "      <th>ObjectiveMagnification</th>\n",
       "      <th>ObjectiveNA</th>\n",
       "      <th>ExposureTime</th>\n",
       "      <th>OrientationMatrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0103K1F1P1R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r01c03f01p01-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2E-06</td>\n",
       "      <td>0.135466397</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-30T17:22:09.49+00:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0103K1F1P1R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r01c03f01p01-ch2sk1fk1fl1.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2E-06</td>\n",
       "      <td>0.135466397</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-30T17:22:09.723+00:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0103K1F1P2R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r01c03f01p02-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135468394</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-30T17:22:10.067+00:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0103K1F1P2R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r01c03f01p02-ch2sk1fk1fl1.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135468394</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-30T17:22:10.287+00:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0103K1F1P3R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r01c03f01p03-ch1sk1fk1fl1.tiff</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135470405</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-11-30T17:22:10.627+00:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388615</th>\n",
       "      <td>0612K150F9P1R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p01-ch2sk150fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2E-06</td>\n",
       "      <td>0.1351538</td>\n",
       "      <td>268191.66</td>\n",
       "      <td>2023-12-03T20:06:16.08+00:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388616</th>\n",
       "      <td>0612K150F9P2R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p02-ch1sk150fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135155797</td>\n",
       "      <td>268191.66</td>\n",
       "      <td>2023-12-03T20:06:16.423+00:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388617</th>\n",
       "      <td>0612K150F9P2R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p02-ch2sk150fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135155797</td>\n",
       "      <td>268191.66</td>\n",
       "      <td>2023-12-03T20:06:16.657+00:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388618</th>\n",
       "      <td>0612K150F9P3R1</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p03-ch1sk150fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135157794</td>\n",
       "      <td>268191.66</td>\n",
       "      <td>2023-12-03T20:06:17+00:00</td>\n",
       "      <td>640</td>\n",
       "      <td>706</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388619</th>\n",
       "      <td>0612K150F9P3R2</td>\n",
       "      <td>Ok</td>\n",
       "      <td>r06c12f09p03-ch2sk150fk1fl1.tiff</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2E-06</td>\n",
       "      <td>0.135157794</td>\n",
       "      <td>268191.66</td>\n",
       "      <td>2023-12-03T20:06:17.217+00:00</td>\n",
       "      <td>488</td>\n",
       "      <td>522</td>\n",
       "      <td>40</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388620 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id State                               URL Row Col  \\\n",
       "0         0103K1F1P1R1    Ok    r01c03f01p01-ch1sk1fk1fl1.tiff   1   3   \n",
       "1         0103K1F1P1R2    Ok    r01c03f01p01-ch2sk1fk1fl1.tiff   1   3   \n",
       "2         0103K1F1P2R1    Ok    r01c03f01p02-ch1sk1fk1fl1.tiff   1   3   \n",
       "3         0103K1F1P2R2    Ok    r01c03f01p02-ch2sk1fk1fl1.tiff   1   3   \n",
       "4         0103K1F1P3R1    Ok    r01c03f01p03-ch1sk1fk1fl1.tiff   1   3   \n",
       "...                ...   ...                               ...  ..  ..   \n",
       "388615  0612K150F9P1R2    Ok  r06c12f09p01-ch2sk150fk1fl1.tiff   6  12   \n",
       "388616  0612K150F9P2R1    Ok  r06c12f09p02-ch1sk150fk1fl1.tiff   6  12   \n",
       "388617  0612K150F9P2R2    Ok  r06c12f09p02-ch2sk150fk1fl1.tiff   6  12   \n",
       "388618  0612K150F9P3R1    Ok  r06c12f09p03-ch1sk150fk1fl1.tiff   6  12   \n",
       "388619  0612K150F9P3R2    Ok  r06c12f09p03-ch2sk150fk1fl1.tiff   6  12   \n",
       "\n",
       "       FieldID PlaneID TimepointID ChannelID FlimID  ... PositionZ  \\\n",
       "0            1       1           0         1      1  ...    -2E-06   \n",
       "1            1       1           0         2      1  ...    -2E-06   \n",
       "2            1       2           0         1      1  ...         0   \n",
       "3            1       2           0         2      1  ...         0   \n",
       "4            1       3           0         1      1  ...     2E-06   \n",
       "...        ...     ...         ...       ...    ...  ...       ...   \n",
       "388615       9       1         149         2      1  ...    -2E-06   \n",
       "388616       9       2         149         1      1  ...         0   \n",
       "388617       9       2         149         2      1  ...         0   \n",
       "388618       9       3         149         1      1  ...     2E-06   \n",
       "388619       9       3         149         2      1  ...     2E-06   \n",
       "\n",
       "       AbsPositionZ MeasurementTimeOffset                        AbsTime  \\\n",
       "0       0.135466397                     0   2023-11-30T17:22:09.49+00:00   \n",
       "1       0.135466397                     0  2023-11-30T17:22:09.723+00:00   \n",
       "2       0.135468394                     0  2023-11-30T17:22:10.067+00:00   \n",
       "3       0.135468394                     0  2023-11-30T17:22:10.287+00:00   \n",
       "4       0.135470405                     0  2023-11-30T17:22:10.627+00:00   \n",
       "...             ...                   ...                            ...   \n",
       "388615    0.1351538             268191.66   2023-12-03T20:06:16.08+00:00   \n",
       "388616  0.135155797             268191.66  2023-12-03T20:06:16.423+00:00   \n",
       "388617  0.135155797             268191.66  2023-12-03T20:06:16.657+00:00   \n",
       "388618  0.135157794             268191.66      2023-12-03T20:06:17+00:00   \n",
       "388619  0.135157794             268191.66  2023-12-03T20:06:17.217+00:00   \n",
       "\n",
       "       MainExcitationWavelength MainEmissionWavelength ObjectiveMagnification  \\\n",
       "0                           640                    706                     40   \n",
       "1                           488                    522                     40   \n",
       "2                           640                    706                     40   \n",
       "3                           488                    522                     40   \n",
       "4                           640                    706                     40   \n",
       "...                         ...                    ...                    ...   \n",
       "388615                      488                    522                     40   \n",
       "388616                      640                    706                     40   \n",
       "388617                      488                    522                     40   \n",
       "388618                      640                    706                     40   \n",
       "388619                      488                    522                     40   \n",
       "\n",
       "       ObjectiveNA ExposureTime  \\\n",
       "0              1.1          0.2   \n",
       "1              1.1          0.1   \n",
       "2              1.1          0.2   \n",
       "3              1.1          0.1   \n",
       "4              1.1          0.2   \n",
       "...            ...          ...   \n",
       "388615         1.1          0.1   \n",
       "388616         1.1          0.2   \n",
       "388617         1.1          0.1   \n",
       "388618         1.1          0.2   \n",
       "388619         1.1          0.1   \n",
       "\n",
       "                                        OrientationMatrix  \n",
       "0       [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "1       [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "2       [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "3       [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "4       [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "...                                                   ...  \n",
       "388615  [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "388616  [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "388617  [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "388618  [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "388619  [[1.000989,0,0,10.0],[0,-1.000989,0,-6.8],[0,0...  \n",
       "\n",
       "[388620 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = '/mnt/SYNO/macrohet_syno/ND0002/'\n",
    "metadata_fn = os.path.join(base_dir, 'acquisition/Images/Index.idx.xml')\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739b419",
   "metadata": {},
   "source": [
    "### View assay layout and mask information (optional)\n",
    "\n",
    "The Opera Phenix acquires many time lapse series from a range of positions. The first step is to inspect the image metadata, presented in the form of an `Assaylayout/experiment_ID.xml` file, to show which positions correspond to which experimental assays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c540d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n",
      "Extracting metadata complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>ConcentrationEC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row</th>\n",
       "      <th>Column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">3</th>\n",
       "      <th>1</th>\n",
       "      <td>UNI</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNI</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">4</th>\n",
       "      <th>3</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WT</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WT</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WT</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WT</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WT</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">5</th>\n",
       "      <th>3</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>60</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>0.04</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>0.02</td>\n",
       "      <td>EC50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">6</th>\n",
       "      <th>3</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RD1</td>\n",
       "      <td>CTRL</td>\n",
       "      <td>0</td>\n",
       "      <td>EC0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RD1</td>\n",
       "      <td>PZA</td>\n",
       "      <td>400</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RD1</td>\n",
       "      <td>RIF</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RD1</td>\n",
       "      <td>INH</td>\n",
       "      <td>2</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RD1</td>\n",
       "      <td>BDQ</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EC99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Strain Compound Concentration ConcentrationEC\n",
       "Row Column                                              \n",
       "3   1         UNI     CTRL             0             EC0\n",
       "    2         UNI     CTRL             0             EC0\n",
       "    3          WT     CTRL             0             EC0\n",
       "    4          WT     CTRL             0             EC0\n",
       "    5          WT      PZA            60            EC50\n",
       "    6          WT      PZA            60            EC50\n",
       "    7          WT      RIF           0.1            EC50\n",
       "    8          WT      RIF           0.1            EC50\n",
       "    9          WT      INH          0.04            EC50\n",
       "    10         WT      INH          0.04            EC50\n",
       "    11         WT      BDQ          0.02            EC50\n",
       "    12         WT      BDQ          0.02            EC50\n",
       "4   3          WT     CTRL             0             EC0\n",
       "    4          WT     CTRL             0             EC0\n",
       "    5          WT      PZA           400            EC99\n",
       "    6          WT      PZA           400            EC99\n",
       "    7          WT      RIF             2            EC99\n",
       "    8          WT      RIF             2            EC99\n",
       "    9          WT      INH             2            EC99\n",
       "    10         WT      INH             2            EC99\n",
       "    11         WT      BDQ           2.5            EC99\n",
       "    12         WT      BDQ           2.5            EC99\n",
       "5   3         RD1     CTRL             0             EC0\n",
       "    4         RD1     CTRL             0             EC0\n",
       "    5         RD1      PZA            60            EC50\n",
       "    6         RD1      PZA            60            EC50\n",
       "    7         RD1      RIF           0.1            EC50\n",
       "    8         RD1      RIF           0.1            EC50\n",
       "    9         RD1      INH          0.04            EC50\n",
       "    10        RD1      INH          0.04            EC50\n",
       "    11        RD1      BDQ          0.02            EC50\n",
       "    12        RD1      BDQ          0.02            EC50\n",
       "6   3         RD1     CTRL             0             EC0\n",
       "    4         RD1     CTRL             0             EC0\n",
       "    5         RD1      PZA           400            EC99\n",
       "    6         RD1      PZA           400            EC99\n",
       "    7         RD1      RIF             2            EC99\n",
       "    8         RD1      RIF             2            EC99\n",
       "    9         RD1      INH             2            EC99\n",
       "    10        RD1      INH             2            EC99\n",
       "    11        RD1      BDQ           2.5            EC99\n",
       "    12        RD1      BDQ           2.5            EC99"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "assay_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a843967-19c1-4f33-9bf8-a4d331c520eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_processed_acq_IDs = [(3, 4), (4, 3), (4, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9),\n",
    "       (3, 10), (3, 11), (3, 12), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9),\n",
    "       (4, 10), (3, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45221981",
   "metadata": {},
   "source": [
    "# Segment, localise and track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451353a1-ce0a-46d6-aef0-377f9c3a017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_channel = 0\n",
    "gfp_channel = 1\n",
    "manual_mtb_thresh_channel = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dedb723-dcbb-4985-8d0a-ab91c2be58ce",
   "metadata": {},
   "source": [
    "# Test if i have the capacity to stack these channels together like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7290f4e4-3031-418e-aa6d-ef532d0a2af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fd47aeff5b4a05af9ad08e44698b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress through positions:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Position (3, 1): Starting new acquisition\n",
      "INFO:root:Position (3, 1): Images loaded and stacked\n",
      "INFO:root:Position (3, 1): Starting segmentation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5ae01c47604424a1da5422b350334e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Segmenting:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellpose.models:~~~ FINDING MASKS ~~~\n",
      "INFO:cellpose.models:>>>> TOTAL TIME 60.01 sec\n",
      "INFO:root:Position (3, 1): Processing failed: too many values to unpack (expected 3)\n",
      "INFO:root:Position (3, 2): Starting new acquisition\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# create a max projection\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m log_progress(acq_ID, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages loaded and stacked\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2810\u001b[0m, in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2697\u001b[0m \u001b[38;5;124;03mReturn the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2698\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;124;03m5\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/core.py:623\u001b[0m, in \u001b[0;36mArray.__array__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 623\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args:\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/core.py:844\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 844\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_basic_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/core.py:970\u001b[0m, in \u001b[0;36mArray.get_basic_selection\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_basic_selection_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/core.py:1012\u001b[0m, in \u001b[0;36mArray._get_basic_selection_nd\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m   1010\u001b[0m indexer \u001b[38;5;241m=\u001b[39m BasicIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/core.py:1388\u001b[0m, in \u001b[0;36mArray._get_selection\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n\u001b[0;32m-> 1388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_getitems\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlout_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape:\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/core.py:2224\u001b[0m, in \u001b[0;36mArray._chunk_getitems\u001b[0;34m(self, lchunk_coords, lchunk_selection, out, lout_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   2223\u001b[0m         contexts \u001b[38;5;241m=\u001b[39m ConstantMap(ckeys, constant\u001b[38;5;241m=\u001b[39mContext(meta_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array))\n\u001b[0;32m-> 2224\u001b[0m     cdatas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ckey, chunk_select, out_select \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ckeys, lchunk_selection, lout_selection):\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/_storage/store.py:160\u001b[0m, in \u001b[0;36mBaseStore.getitems\u001b[0;34m(self, keys, contexts)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve data from multiple keys.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03mkeys and/or to utilize the contexts.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/_storage/store.py:160\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve data from multiple keys.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03mkeys and/or to utilize the contexts.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/storage.py:1111\u001b[0m, in \u001b[0;36mDirectoryStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/egg/lib/python3.9/site-packages/zarr/storage.py:1086\u001b[0m, in \u001b[0;36mDirectoryStore._fromfile\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m     images \u001b[38;5;241m=\u001b[39m zarr_store\u001b[38;5;241m.\u001b[39mimages\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# create a max projection\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     log_progress(acq_ID, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages loaded and stacked\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# check if already segmented using m2 model\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}.h5')):\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#         continue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#     else:\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inside your loop, use the log_progress function to log progress and errors\n",
    "for (row, column), info in tqdm(assay_layout.iterrows(), desc='Progress through positions', total=len(assay_layout)):\n",
    "    try:\n",
    "        acq_ID = (row, column)\n",
    "        log_progress(acq_ID, \"Starting new acquisition\")\n",
    "        \n",
    "        # if info['Strain'] == 'UNI':\n",
    "        #     log_progress(acq_ID, \"Skipping uninfected acquisition for now\")\n",
    "        #     continue\n",
    "        # if acq_ID in already_processed_acq_IDs:\n",
    "        #     log_progress(acq_ID, \"Skipping already processed\")\n",
    "        #     continue\n",
    "        # if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_warea.h5')):\n",
    "        #     log_progress(acq_ID, \"Skipping already processed\")\n",
    "        #     continue\n",
    "\n",
    "        # process images using zarr\n",
    "        image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "        zarr_store = zarr.open(image_dir, mode='r')\n",
    "        images = zarr_store.images\n",
    "        # create a max projection\n",
    "        images = np.max(images, axis = 2)\n",
    "        \n",
    "        log_progress(acq_ID, \"Images loaded and stacked\")\n",
    "\n",
    "        # check if already segmented using m2 model\n",
    "    #     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}.h5')):\n",
    "    #         continue\n",
    "    #     else:\n",
    "        log_progress(acq_ID, \"Starting segmentation\")\n",
    "\n",
    "    #     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5')):\n",
    "    #         with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5'), \n",
    "    #                                        'r', \n",
    "    #                                        obj_type='obj_type_1'\n",
    "    #                                        ) as reader:\n",
    "    # #             writer.write_objects(objects)\n",
    "    #             # writer.write_tracks(tracks)\n",
    "    #             masks = reader.segmentation\n",
    "    #         log_progress(acq_ID, \"Loaded previously calculated segmentation\")\n",
    "    #     else:\n",
    "        # segment images from gfp channel only\n",
    "        masks = np.stack([segment(frame) \n",
    "                          for frame in tqdm(images[:,gfp_channel,...],  # segmenting the GFP channel \n",
    "                                            desc = 'Segmenting')])\n",
    "\n",
    "        log_progress(acq_ID, \"Finished segmentation\")\n",
    "        \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_mask_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "    #             writer.write_objects(objects)\n",
    "                # writer.write_tracks(tracks)\n",
    "                writer.write_segmentation(masks)\n",
    "            \n",
    "        log_progress(acq_ID, \"Saved out masks\")  \n",
    "        \n",
    "        log_progress(acq_ID, \"Measuring Mtb area\")       \n",
    "        \n",
    "        # characterise Mtb growth using Otsu segmentation\n",
    "        # otsu_mtb = otsu_threshold(images[:,1,...]) # time consuming and non-deterministic when compared to hardcoded, could result in different thresholds for same image? \n",
    "        # characterise Mtb growth using hardcoded threshold :S\n",
    "        manual_mtb_thresh = np.where(images[:,mtb_channel,...] >= Mtb_load_thresh, True, False)\n",
    "        log_progress(acq_ID, \"Creating intensity image for localisation\")  \n",
    "        # reshape intensity image to be gfp, rfp on last axis for regionprops\n",
    "        intensity_image = np.stack([images[:,0,...], \n",
    "                                    images[:,1,...],  \n",
    "    #                                 otsu_mtb, \n",
    "                                    manual_mtb_thresh], axis = -1)\n",
    "        log_progress(acq_ID, \"Localising objects\")  \n",
    "        # localise objects\n",
    "        objects = localise(masks, \n",
    "                           intensity_image, \n",
    "                           )\n",
    "        log_progress(acq_ID, \"Filtering small objects\")  \n",
    "        # filter out small objects\n",
    "        objects = [o for o in objects if o.properties['area'] > segment_size_thresh]\n",
    "\n",
    "        log_progress(acq_ID, \"Adding infection labels to objects\")  \n",
    "        # add label for infection\n",
    "        for obj in objects:\n",
    "            obj.properties = ({\"Infected\": True} \n",
    "                                if obj.properties['mean_intensity'][manual_mtb_thresh_channel] > 0 # index 2 for manual mtb channel \n",
    "                                else {\"Infected\": False})\n",
    "            obj.properties = ({\"Mtb area px\": obj.properties['mean_intensity'][manual_mtb_thresh_channel]*obj.properties['area']})\n",
    "\n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_objects_backup.h5'), \n",
    "                                                   'w', \n",
    "                                                   obj_type='obj_type_1'\n",
    "                                                   ) as writer:\n",
    "                        writer.write_objects(objects)\n",
    "                        # writer.write_tracks(tracks)\n",
    "        \n",
    "        log_progress(acq_ID, \"Beginning tracking\")  \n",
    "        # track on upscaled config fn\n",
    "        tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "        log_progress(acq_ID, \"Saving tracking\")  \n",
    "        # save out \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_tracks_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "    #             writer.write_objects(objects)\n",
    "                writer.write_tracks(tracks)\n",
    "                # writer.write_segmentation(masks)\n",
    "        # Log successful completion\n",
    "\n",
    "        with btrack.io.HDF5FileHandler(f'{row, column}_cpv3_full_backup.h5', \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "                    writer.write_tracks(tracks)\n",
    "                    writer.write_objects(objects)\n",
    "                    writer.write_segmentation(masks)\n",
    "        # Log successful completion\n",
    "        log_progress(acq_ID, \"Processing completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log errors\n",
    "        log_progress(acq_ID, f\"Processing failed: {str(e)}\")\n",
    "\n",
    "# You can also log information before and after the loop\n",
    "logging.info(\"Processing completed\")\n",
    "\n",
    "# Notify if required\n",
    "notify.send_sms(\"Processing completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ca604-b931-4c2b-a542-40af5bb4f4a4",
   "metadata": {},
   "source": [
    "# And now try and redo ps00000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ab692-2e94-46f3-b6f1-8a2a9581ff19",
   "metadata": {},
   "source": [
    "### Load experiment of choice\n",
    "\n",
    "The Opera Phenix is a high-throughput confocal microscope that acquires very large 5-dimensional (TCZXY) images over several fields of view in any one experiment. Therefore, a lazy-loading approach is chosen to mosaic, view and annotate these images. This approach depends upon Dask and DaskFusion. The first step is to load the main metadata file (typically called `Index.idx.xml` and located in the main `Images` directory) that contains the image filenames and associated TCXZY information used to organise the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb2069-1d41-46cc-bc8e-29f8d6ff6f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/mnt/DATA/macrohet/PS0000/'\n",
    "metadata_fn = os.path.join(base_dir, 'acquisition/Images/Index.idx.xml')\n",
    "metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56301e5b-bbfa-45e7-9c14-d04f3b62dc89",
   "metadata": {},
   "source": [
    "### View assay layout and mask information (optional)\n",
    "\n",
    "The Opera Phenix acquires many time lapse series from a range of positions. The first step is to inspect the image metadata, presented in the form of an `Assaylayout/experiment_ID.xml` file, to show which positions correspond to which experimental assays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06888b8-1390-4372-b981-59226b34f1f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,)# mask_exist=True,  image_dir = image_dir, image_metadata = metadata)\n",
    "assay_layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a17cfb-8ee0-4464-8127-7d8f45925ab3",
   "metadata": {},
   "source": [
    "# Segment, localise and track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c5d2b-0b0b-4354-8ccc-71c0682c7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtb_channel = 1\n",
    "gfp_channel = 2\n",
    "manual_mtb_thresh_channel = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e12ed-8c64-405e-b481-a59d745f5963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inside your loop, use the log_progress function to log progress and errors\n",
    "for (row, column), info in tqdm(assay_layout.iterrows(), desc='Progress through positions', total=len(assay_layout)):\n",
    "    try:\n",
    "        acq_ID = (row, column)\n",
    "        log_progress(acq_ID, \"Starting new acquisition\")\n",
    "        \n",
    "        # if info['Strain'] == 'UNI':\n",
    "        #     log_progress(acq_ID, \"Skipping uninfected acquisition for now\")\n",
    "        #     continue\n",
    "        # if acq_ID in already_processed_acq_IDs:\n",
    "        #     log_progress(acq_ID, \"Skipping already processed\")\n",
    "        #     continue\n",
    "        if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_warea.h5')):\n",
    "            log_progress(acq_ID, \"Skipping already processed\")\n",
    "            continue\n",
    "\n",
    "        # process images using zarr\n",
    "        # image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "        # zarr_store = zarr.open(image_dir, mode='r')\n",
    "        # images = zarr_store.images\n",
    "        # # create a max projection\n",
    "        # images = np.max(images, axis = 2)\n",
    "\n",
    "        image_dir = os.path.join(base_dir, 'acquisition/Images')\n",
    "        images = tile.compile_mosaic(image_dir, \n",
    "                                     metadata, \n",
    "                                     row, column, \n",
    "                                     # subset_field_IDs=['16', '17',  '20', '21'], \n",
    "                                     # n_tile_rows = 2, n_tile_cols = 2,\n",
    "                                     set_plane='max_proj'\n",
    "                                     # set_channel=1,\n",
    "                                     # set_time = 1,\n",
    "        #                             input_transforms = [input_transforms]\n",
    "                                    ).compute().compute()\n",
    "        images = images[:,:,0,...]\n",
    "        \n",
    "        log_progress(acq_ID, \"Images loaded and stacked\")\n",
    "\n",
    "        # check if already segmented using m2 model\n",
    "    #     if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}.h5')):\n",
    "    #         continue\n",
    "    #     else:\n",
    "        log_progress(acq_ID, \"Starting segmentation\")\n",
    "\n",
    "        if os.path.exists(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5')):\n",
    "            with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5'), \n",
    "                                           'r', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as reader:\n",
    "    #             writer.write_objects(objects)\n",
    "                # writer.write_tracks(tracks)\n",
    "                masks = reader.segmentation\n",
    "            log_progress(acq_ID, \"Loaded previously calculated segmentation\")\n",
    "        else:\n",
    "            # segment images from gfp channel only\n",
    "            masks = np.stack([segment(frame) \n",
    "                              for frame in tqdm(images[:,gfp_channel,...],  # segmenting the GFP channel \n",
    "                                                desc = 'Segmenting')])\n",
    "\n",
    "            log_progress(acq_ID, \"Finished segmentation\")\n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_seg_backup.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "    #             writer.write_objects(objects)\n",
    "                # writer.write_tracks(tracks)\n",
    "                writer.write_segmentation(masks)\n",
    "        log_progress(acq_ID, \"Saved out masks\")  \n",
    "        log_progress(acq_ID, \"Measuring Mtb area\")       \n",
    "        # characterise Mtb growth using Otsu segmentation\n",
    "        # otsu_mtb = otsu_threshold(images[:,1,...]) # time consuming and non-deterministic when compared to hardcoded, could result in different thresholds for same image? \n",
    "        # characterise Mtb growth using hardcoded threshold :S\n",
    "        manual_mtb_thresh = np.where(images[:,mtb_channel,...] >= Mtb_load_thresh, 1, 0)\n",
    "        log_progress(acq_ID, \"Creating intensity image for localisation\")  \n",
    "        # reshape intensity image to be gfp, rfp on last axis for regionprops\n",
    "        intensity_image = np.stack([images[:,0,...], \n",
    "                                    images[:,1,...],  \n",
    "    #                                 otsu_mtb, \n",
    "                                    manual_mtb_thresh], axis = -1)\n",
    "        log_progress(acq_ID, \"Localising objects\")  \n",
    "        # localise objects\n",
    "        objects = localise(masks, \n",
    "                           intensity_image, \n",
    "                           )\n",
    "        log_progress(acq_ID, \"Filtering small objects\")  \n",
    "        # filter out small objects\n",
    "        objects = [o for o in objects if o.properties['area'] > segment_size_thresh]\n",
    "\n",
    "        log_progress(acq_ID, \"Adding infection labels to objects\")  \n",
    "        # add label for infection\n",
    "        for obj in objects:\n",
    "            obj.properties = ({\"Infected\": True} \n",
    "                                if obj.properties['mean_intensity'][manual_mtb_thresh_channel] > 0 # index 2 for manual mtb channel \n",
    "                                else {\"Infected\": False})\n",
    "\n",
    "        log_progress(acq_ID, \"Beginning tracking\")  \n",
    "        # track on upscaled config fn\n",
    "        tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "        log_progress(acq_ID, \"Saving tracking\")  \n",
    "        # save out \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/macrohet_seg_model/{row, column}_first_pass_warea.h5'), \n",
    "                                           'w', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as writer:\n",
    "    #             writer.write_objects(objects)\n",
    "                writer.write_tracks(tracks)\n",
    "                writer.write_segmentation(masks)\n",
    "        # Log successful completion\n",
    "        log_progress(acq_ID, \"Processing completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log errors\n",
    "        log_progress(acq_ID, f\"Processing failed: {str(e)}\")\n",
    "\n",
    "# You can also log information before and after the loop\n",
    "logging.info(\"Processing completed\")\n",
    "\n",
    "# Notify if required\n",
    "# notify.send_sms(\"Processing completed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg",
   "language": "python",
   "name": "egg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
