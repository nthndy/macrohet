{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7c7V4yEqDc_"
   },
   "source": [
    "# Training a Cellpose model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvyuR08OZfw4"
   },
   "source": [
    "We will first install cellpose 2.0, check the GPU is working, and get your models and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt8hgC7rniP8",
    "outputId": "677fa3d0-952f-4490-f5bb-4ef1ad0b0469"
   },
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "from glob import glob\n",
    "import napari\n",
    "from natsort import natsorted\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/mnt/DATA/macrohet/upstream_development/segmentation/cellpose_training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQI4aUxCjz3n",
    "outputId": "804d0459-b120-4298-9b4c-87a9ca26401c"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_dir = os.path.join(base_dir, 'training_dir')\n",
    "ch1, ch2 = 0,0 # 'Grayscale', None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files # using their function \n",
    "output = io.load_train_test_data(train_dir=test_dir, test_dir=None, mask_filter='_gt_inst_masks')\n",
    "train_data, train_labels, fns, test_data, test_labels, _ = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_data\n",
    "test_labels = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdH0j8-L6FuB"
   },
   "source": [
    "## Evaluate on test data (optional)\n",
    "\n",
    "If you have test data, check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# defining pretrained cellpose model to use\n",
    "model = models.Cellpose(\n",
    "                        gpu=True, \n",
    "                        model_type='cyto', \n",
    "                        net_avg=True, \n",
    "#                         device=torch.device('cuda')\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run model on test images\n",
    "masks = [model.eval(test_data[i], \n",
    "                   channels=[ch1, ch2],\n",
    "                   diameter=325, progress=True)[0]\n",
    "        for i in tqdm(range(len(test_data)))]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               \n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aji = metrics.aggregated_jaccard_index(test_labels, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{aji.mean():.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap, aji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()\n",
    "for i in range(len(np.stack(test_data, axis = 0))):\n",
    "    v.add_image(np.stack(test_data, axis = 0)[i], colormap='green', contrast_limits=(0,6000))\n",
    "# v.add_labels(masks, num_colors=1)\n",
    "    v.add_labels(np.stack(test_labels, axis = 0)[i], num_colors=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()\n",
    "\n",
    "v.add_image(np.stack(test_data, axis = 0), colormap='green', contrast_limits=(0,6000))\n",
    "v.add_labels(np.stack(masks, axis =0), num_colors = 1)\n",
    "v.add_labels(np.stack(test_labels, axis = 0), num_colors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdH0j8-L6FuB"
   },
   "source": [
    "## Evaluate on test data for my model (optional)\n",
    "\n",
    "testing on model v1 which had 7 out of 8 training images, testing on latest gt image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = '/mnt/DATA/macrohet/upstream_development/segmentation/cellpose_training/models/models/macrohet_seg'\n",
    "model = models.CellposeModel(gpu=True, \n",
    "                             pretrained_model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns.pop(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.pop(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run model on test images\n",
    "masks = [model.eval(test_data, \n",
    "                   channels=[ch1, ch2],\n",
    "                   progress=True)[0]\n",
    "        for i in tqdm(range(len(test_data)))]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.pop(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               \n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.load('masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=np.load('test_labels.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aji = metrics.aggregated_jaccard_index(test_labels, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{aji.mean():.3f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap, aji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()\n",
    "for i in range(len(np.stack(test_data, axis = 0))):\n",
    "    v.add_image(np.stack(test_data, axis = 0)[i], colormap='green', contrast_limits=(0,6000))\n",
    "# v.add_labels(masks, num_colors=1)\n",
    "    v.add_labels(np.stack(test_labels, axis = 0)[i], num_colors=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.Viewer()\n",
    "\n",
    "v.add_image(np.stack(test_data, axis = 0), colormap='green', contrast_limits=(0,6000))\n",
    "v.add_labels(np.stack(masks, axis =0), num_colors = 1)\n",
    "v.add_labels(np.stack(test_labels, axis = 0), num_colors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 250 epochs on latest model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0AGsH5p6K6S",
    "outputId": "3f67063a-2197-4ec2-8619-0b52c98fd0ee"
   },
   "outputs": [],
   "source": [
    "# get files (during training, test_data is transformed so we will load it again)\n",
    "# output = io.load_train_test_data(test_dir, mask_filter='_seg.npy')\n",
    "# test_data = [io.imread(fn) for fn in natsorted(glob(os.path.join(test_dir, 'raw_images/')))]\n",
    "# test_labels = [io.imread(fn) for fn in natsorted(glob(os.path.join(test_dir, 'ground_truth_inst/*')))]\n",
    "test_data = [io.imread('/mnt/DATA/macrohet/upstream_development/segmentation/cellpose_training/test_dir/raw_images/r06c09f0*p0*-ch1sk1fk1fl1.tiff')]\n",
    "test_labels = [io.imread('/mnt/DATA/macrohet/upstream_development/segmentation/cellpose_training/test_dir/ground_truth_inst/gt_inst_r06c09f0*p0*-ch1sk1fk1fl1.tiff')]\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, \n",
    "                   channels=[chan, chan2],\n",
    "                   diameter=diam_labels)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10k epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0AGsH5p6K6S",
    "outputId": "3f67063a-2197-4ec2-8619-0b52c98fd0ee"
   },
   "outputs": [],
   "source": [
    "# get files (during training, test_data is transformed so we will load it again)\n",
    "# output = io.load_train_test_data(test_dir, mask_filter='_seg.npy')\n",
    "# test_data = [io.imread(fn) for fn in natsorted(glob(os.path.join(test_dir, 'raw_images/')))]\n",
    "# test_labels = [io.imread(fn) for fn in natsorted(glob(os.path.join(test_dir, 'ground_truth_inst/*')))]\n",
    "test_data = [io.imread('/mnt/DATA/macrohet/upstream_development/segmentation/cellpose_training/test_dir/raw_images/r06c09f0*p0*-ch1sk1fk1fl1.tiff')]\n",
    "test_labels = [io.imread('/mnt/DATA/macrohet/upstream_development/segmentation/cellpose_training/test_dir/ground_truth_inst/gt_inst_r06c09f0*p0*-ch1sk1fk1fl1.tiff')]\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, \n",
    "                   channels=[chan, chan2],\n",
    "                   diameter=diam_labels)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_score_dict = {10:0.884, 250:0.899, 10000:0.868}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from macrohet import notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notify.send_sms('training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8tZ8uYR-IFW"
   },
   "source": [
    "plot masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z2ac5gtr-HPq",
    "outputId": "65c96437-85e4-42cf-8d4b-414b6ba98c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "for k,im in enumerate(test_data):\n",
    "    img = im.copy()\n",
    "    plt.subplot(3,len(train_files), k+1)\n",
    "    img = np.vstack((img, np.zeros_like(img)[:1]))\n",
    "#     img = img.transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('image')\n",
    "\n",
    "    plt.subplot(3,len(train_files), len(train_files) + k+1)\n",
    "    plt.imshow(masks[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('predicted labels')\n",
    "\n",
    "    plt.subplot(3,len(train_files), 2*len(train_files) + k+1)\n",
    "    plt.imshow(test_labels[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('true labels')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbVIZbNk5hgR"
   },
   "source": [
    "# Use custom model to segment images\n",
    "\n",
    "Take custom trained model from above, or upload your own model to google drive / colab runtime.\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "vDu4Ixjo588O"
   },
   "outputs": [],
   "source": [
    "# model name and path\n",
    "\n",
    "#@markdown ###Custom model path (full path):\n",
    "\n",
    "model_path = \"human_in_the_loop/train/models/CP_tissuenet\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ###Path to images:\n",
    "\n",
    "dir = \"human_in_the_loop/test\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ###Channel Parameters:\n",
    "\n",
    "Channel_to_use_for_segmentation = \"Green\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "# @markdown If you have a secondary channel that can be used, for instance nuclei, choose it here:\n",
    "\n",
    "Second_segmentation_channel= \"Red\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "\n",
    "# Here we match the channel to number\n",
    "if Channel_to_use_for_segmentation == \"Grayscale\":\n",
    "  chan = 0\n",
    "elif Channel_to_use_for_segmentation == \"Blue\":\n",
    "  chan = 3\n",
    "elif Channel_to_use_for_segmentation == \"Green\":\n",
    "  chan = 2\n",
    "elif Channel_to_use_for_segmentation == \"Red\":\n",
    "  chan = 1\n",
    "\n",
    "\n",
    "if Second_segmentation_channel == \"Blue\":\n",
    "  chan2 = 3\n",
    "elif Second_segmentation_channel == \"Green\":\n",
    "  chan2 = 2\n",
    "elif Second_segmentation_channel == \"Red\":\n",
    "  chan2 = 1\n",
    "elif Second_segmentation_channel == \"None\":\n",
    "  chan2 = 0\n",
    "\n",
    "#@markdown ### Segmentation parameters:\n",
    "\n",
    "#@markdown diameter of cells (set to zero to use diameter from training set):\n",
    "diameter =  0#@param {type:\"number\"}\n",
    "#@markdown threshold on flow error to accept a mask (set higher to get more cells, e.g. in range from (0.1, 3.0), OR set to 0.0 to turn off so no cells discarded):\n",
    "flow_threshold = 0.4 #@param {type:\"slider\", min:0.0, max:3.0, step:0.1}\n",
    "#@markdown threshold on cellprob output to seed cell masks (set lower to include more pixels or higher to include fewer, e.g. in range from (-6, 6)):\n",
    "cellprob_threshold=0 #@param {type:\"slider\", min:-6, max:6, step:1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Axg2YQEpDx0e"
   },
   "source": [
    "if you're using the example test data we'll copy it to a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InyKGtD3D2ZX",
    "outputId": "b1b4ecf3-41a0-4463-8944-afd8200cece0"
   },
   "outputs": [],
   "source": [
    "src = 'human_in_the_loop/test'\n",
    "if dir[:len(src)] == src:\n",
    "    files = io.get_image_files(dir, '_masks')\n",
    "    dir = 'human_in_the_loop/eval/'\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    for f in files:\n",
    "        dst = dir + os.path.split(f)[1]\n",
    "        print(f'{f} > {dst}')\n",
    "        shutil.copyfile(f, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JJ1q0nTBAAR"
   },
   "source": [
    "Here's what the command to train would be on the command line -- make sure if you run this locally to correct the paths for your local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8P5voZOVM-H9",
    "outputId": "a9c9f1fb-7cf9-4676-bc1a-8a261f888274"
   },
   "outputs": [],
   "source": [
    "run_str = f'python -m cellpose --use_gpu --verbose --dir {dir} --pretrained_model {model_path} --chan {chan} --chan2 {chan2} --diameter {diameter} --flow_threshold {flow_threshold} --cellprob_threshold {cellprob_threshold}'\n",
    "print(run_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN3rdsfMBc_8"
   },
   "source": [
    "## run custom model\n",
    "\n",
    "how to run the custom model in a notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCcbs722BYd0",
    "outputId": "b7de466b-4e7a-4585-b1d7-c282593b3fab"
   },
   "outputs": [],
   "source": [
    "# gets image files in dir (ignoring image files ending in _masks)\n",
    "files = io.get_image_files(dir, '_masks')\n",
    "print(files)\n",
    "images = [io.imread(f) for f in files]\n",
    "\n",
    "# declare model\n",
    "model = models.CellposeModel(gpu=True, \n",
    "                             pretrained_model=model_path)\n",
    "\n",
    "# use model diameter if user diameter is 0\n",
    "diameter = model.diam_labels if diameter==0 else diameter\n",
    "\n",
    "# run model on test images\n",
    "masks, flows, styles = model.eval(images, \n",
    "                                  channels=[chan, chan2],\n",
    "                                  diameter=diameter,\n",
    "                                  flow_threshold=flow_threshold,\n",
    "                                  cellprob_threshold=cellprob_threshold\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qj5AIZ825o7P"
   },
   "source": [
    "## save output to *_seg.npy\n",
    "\n",
    "you will see the files save in the Files tab and you can download them from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc7EWe_f5oEH"
   },
   "outputs": [],
   "source": [
    "from cellpose import io\n",
    "\n",
    "io.masks_flows_to_seg(images, \n",
    "                      masks, \n",
    "                      flows, \n",
    "                      diameter*np.ones(len(masks)), \n",
    "                      files, \n",
    "                      [chan, chan2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwoUuuarC9V5"
   },
   "source": [
    "## save output masks to tiffs/pngs or txt files for imageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Da-Rtx09DEZB"
   },
   "outputs": [],
   "source": [
    "io.save_masks(images, \n",
    "              masks, \n",
    "              flows, \n",
    "              files, \n",
    "              channels=[chan, chan2],\n",
    "              png=True, # save masks as PNGs and save example image\n",
    "              tif=True, # save masks as TIFFs\n",
    "              save_txt=True, # save txt outlines for ImageJ\n",
    "              save_flows=False, # save flows as TIFFs\n",
    "              save_outlines=False, # save outlines as TIFFs \n",
    "              )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "PiP9MWN4F3Sx",
    "outputId": "e70088bf-dbb2-4b49-a5df-620c2b253d68"
   },
   "outputs": [],
   "source": [
    "f = files[0]\n",
    "plt.figure(figsize=(12,4), dpi=300)\n",
    "plt.imshow(io.imread(os.path.splitext(f)[0] + '_cp_output.png'))\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
