{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1087c1-7c67-4057-b7d5-63e60a04890c",
   "metadata": {},
   "source": [
    "# Labelling review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000ae776-140c-4cc7-8c7e-c55cfa362062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import btrack\n",
    "import napari\n",
    "import glob\n",
    "import zarr\n",
    "import numpy as np\n",
    "\n",
    "from macrohet import dataio, visualise\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6442720a-ce24-4bb3-b539-935e5cad1400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.1.dev129'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btrack.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2608883-c130-420b-ad65-eb394b96d932",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19a9f6b-5a0e-47ce-8abe-dd80acd13bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(objects, masks, config_fn, search_radius = 20):\n",
    "\n",
    "    # initialise a tracker session using a context manager\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure(config_fn)\n",
    "        # set max search radius\n",
    "        tracker.max_search_radius = search_radius\n",
    "        # define tracking method\n",
    "        tracker.tracking_updates = [\"MOTION\", \"VISUAL\"]\n",
    "        # redefine features so that both channels are included in track measurements\n",
    "        tracker.features = list(objects[0].properties.keys())\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects)\n",
    "        # set the tracking volume\n",
    "        tracker.volume=((0, masks.shape[-2]*scale_factor), (0, masks.shape[-1]*scale_factor))\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=25)\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "        # store the tracks\n",
    "        tracks = tracker.tracks\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e049967-f8b0-48c0-8434-e8650f75c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewer_tools(viewer):\n",
    "    \n",
    "    @viewer.bind_key(\"z\", overwrite=True)\n",
    "    def true_track(viewer):\n",
    "        \"\"\"\n",
    "        Marks a track as true based on the cursor position in the Napari viewer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        viewer : napari.viewer.Viewer\n",
    "            The Napari viewer instance.\n",
    "    \n",
    "        \"\"\"\n",
    "        # Scale the coordinates for the tracks layer\n",
    "        scaled_coords = [viewer.cursor.position[0]] + [coord / scale_factor for coord in viewer.cursor.position[1:]]\n",
    "    \n",
    "        # Use scaled coords to extract track ID under cursor\n",
    "        cell_ID = viewer.layers['napari_tracks'].get_value(scaled_coords)\n",
    "    \n",
    "        if not cell_ID:\n",
    "            print('cell ID not found')\n",
    "        else:\n",
    "            # Add track label to track_dict\n",
    "            track_performance_dict[int(cell_ID)] = True\n",
    "    \n",
    "            with open(os.path.join(track_performance_dir, f'{row, column}_track_assessment.json'), \"w\") as file:\n",
    "                json.dump(track_performance_dict, file)\n",
    "    \n",
    "            print(f\"{cell_ID}:True\")\n",
    "    \n",
    "        track = [track for track in tracks if track.ID == cell_ID][0]\n",
    "        points = [[track.t[i], track.y[i] * scale_factor, track.x[i] * scale_factor] for i in range(len(track))]\n",
    "        name = 'true tracks'\n",
    "    \n",
    "        try:\n",
    "            # If the layer exists, add the points\n",
    "            viewer.layers[name].add(points)\n",
    "        except:\n",
    "            # If the layer does not exist, create a new layer\n",
    "            viewer.add_points(points,\n",
    "                              size=33,\n",
    "                              symbol='star',\n",
    "                              face_color='transparent',\n",
    "                              edge_color='white',\n",
    "                              edge_width=0.1,\n",
    "                              name=name,\n",
    "                              opacity=1\n",
    "                              # scale=napari_scale\n",
    "                              )\n",
    "    \n",
    "    \n",
    "    @viewer.bind_key(\"x\", overwrite=True)\n",
    "    def false_track(viewer):\n",
    "        \"\"\"\n",
    "        Marks a track as false based on the cursor position in the Napari viewer.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        viewer : napari.viewer.Viewer\n",
    "            The Napari viewer instance.\n",
    "    \n",
    "        \"\"\"\n",
    "        # Scale the coordinates for the tracks layer\n",
    "        scaled_coords = [viewer.cursor.position[0]] + [coord / scale_factor for coord in viewer.cursor.position[1:]]\n",
    "    \n",
    "        # Use scaled coords to extract track ID under cursor\n",
    "        cell_ID = viewer.layers['napari_tracks'].get_value(scaled_coords)\n",
    "    \n",
    "        if not cell_ID:\n",
    "            print('cell ID not found')\n",
    "        else:\n",
    "            # Add track label to track_dict\n",
    "            track_performance_dict[int(cell_ID)] = False\n",
    "    \n",
    "            with open(os.path.join(track_performance_dir, f'{row, column}_track_assessment.json'), \"w\") as file:\n",
    "                json.dump(track_performance_dict, file)\n",
    "    \n",
    "            print(f\"{cell_ID}:False\")\n",
    "    \n",
    "        track = [track for track in tracks if track.ID == cell_ID][0]\n",
    "        points = [[track.t[i], track.y[i] * scale_factor, track.x[i] * scale_factor] for i in range(len(track))]\n",
    "        name = 'false tracks'\n",
    "    \n",
    "        try:\n",
    "            # If the layer exists, add the points\n",
    "            viewer.layers[name].add(points)\n",
    "        except:\n",
    "            # If the layer does not exist, create a new layer\n",
    "            viewer.add_points(points,\n",
    "                              size=33,\n",
    "                              symbol='x',\n",
    "                              face_color='transparent',\n",
    "                              edge_color='white',\n",
    "                              edge_width=0.1,\n",
    "                              name=name,\n",
    "                              opacity=1\n",
    "                              # scale=napari_scale\n",
    "                              )\n",
    "            \n",
    "    @viewer.bind_key(\"b\", overwrite=True)\n",
    "    def record_true_with_time(viewer):\n",
    "        \"\"\"\n",
    "        Records True along with the time dimension value based on the cursor position in the Napari viewer.\n",
    "        This is so that I can crop certain tracks that are True from the point of time recorded onwards.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        viewer : napari.viewer.Viewer\n",
    "            The Napari viewer instance.\n",
    "    \n",
    "        \"\"\"\n",
    "        # Scale the coordinates for the tracks layer\n",
    "        scaled_coords = [viewer.cursor.position[0]] + [coord / scale_factor for coord in viewer.cursor.position[1:]]\n",
    "    \n",
    "        # Use scaled coords to extract track ID under cursor\n",
    "        cell_ID = viewer.layers['napari_tracks'].get_value(scaled_coords)\n",
    "    \n",
    "        if not cell_ID:\n",
    "            print('cell ID not found')\n",
    "        else:\n",
    "            # Get the current time from the viewer\n",
    "            current_time = viewer.dims.current_step[0]\n",
    "    \n",
    "            # Add (cell_ID, current_time, True) to track_performance_dict\n",
    "            track_performance_dict[int(cell_ID)] = (current_time, True)\n",
    "    \n",
    "            with open(os.path.join(track_performance_dir, f'{row, column}_track_assessment.json'), \"w\") as file:\n",
    "                json.dump(track_performance_dict, file)\n",
    "    \n",
    "            print(f\"{cell_ID}:{current_time}:True\")\n",
    "    \n",
    "        track = [track for track in tracks if track.ID == cell_ID][0]\n",
    "        points = [[track.t[i], track.y[i] * scale_factor, track.x[i] * scale_factor] for i in range(len(track))]\n",
    "        name = 'true tracks'\n",
    "    \n",
    "        try:\n",
    "            # If the layer exists, add the points\n",
    "            viewer.layers[name].add(points)\n",
    "        except:\n",
    "            # If the layer does not exist, create a new layer\n",
    "            viewer.add_points(points,\n",
    "                              size=33,\n",
    "                              symbol='triangle_down',\n",
    "                              face_color='transparent',\n",
    "                              edge_color='white',\n",
    "                              edge_width=0.1,\n",
    "                              name=name,\n",
    "                              opacity=1\n",
    "                              # scale=napari_scale\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f34be5-ca6b-4a2b-8a30-7b75a1fa8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tracking scale factor\n",
    "scale_factor = 1/5.04\n",
    "\n",
    "# define tracker config fn to use, using a prob_not_assign = 0.1\n",
    "config_fn = '/home/dayn/analysis/models/btrack/particle_config_pnassign.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e4ccf-155f-4608-8528-619b3fa365ad",
   "metadata": {},
   "source": [
    "### Define scope of review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2729f6dc-9099-4692-bad7-23c027b4821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expts_to_review = ['ND0002','ND0003']\n",
    "positions_to_review = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb811a91-0037-43b9-94a0-cee9ddaf3348",
   "metadata": {},
   "source": [
    "### Iteratively load images and tracks to review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3c955-23d5-4e80-9541-e5610bbc7635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata XML file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91070816e37248929d10cb0f994003f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata complete!\n",
      "Reading metadata XML file...\n",
      "Extracting metadata complete!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb6ce40f3ff4b8d95c1989c42cf0bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress through positions:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024/03/27 11:56:10 AM] Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 1)_cpv3_mask_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 1)_cpv3_mask_backup.h5...\n",
      "[INFO][2024/03/27 11:56:31 AM] Loading segmentation (150, 6048, 6048)\n",
      "INFO:btrack.io.hdf:Loading segmentation (150, 6048, 6048)\n",
      "[INFO][2024/03/27 11:56:31 AM] Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 1)_cpv3_mask_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 1)_cpv3_mask_backup.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024/03/27 12:00:04 pm] Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 2)_cpv3_mask_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 2)_cpv3_mask_backup.h5...\n",
      "[INFO][2024/03/27 12:00:38 pm] Loading segmentation (150, 6048, 6048)\n",
      "INFO:btrack.io.hdf:Loading segmentation (150, 6048, 6048)\n",
      "[INFO][2024/03/27 12:00:38 pm] Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 2)_cpv3_mask_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 2)_cpv3_mask_backup.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "[INFO][2024/03/27 12:03:39 pm] Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 3)_cpv3_mask_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 3)_cpv3_mask_backup.h5...\n",
      "[INFO][2024/03/27 12:04:12 pm] Loading segmentation (150, 6048, 6048)\n",
      "INFO:btrack.io.hdf:Loading segmentation (150, 6048, 6048)\n",
      "[INFO][2024/03/27 12:04:12 pm] Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 3)_cpv3_mask_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 3)_cpv3_mask_backup.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "[INFO][2024/03/27 12:08:07 pm] Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 4)_cpv3_mask_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 4)_cpv3_mask_backup.h5...\n",
      "[INFO][2024/03/27 12:08:40 pm] Loading segmentation (150, 6048, 6048)\n",
      "INFO:btrack.io.hdf:Loading segmentation (150, 6048, 6048)\n",
      "[INFO][2024/03/27 12:08:40 pm] Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 4)_cpv3_mask_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 4)_cpv3_mask_backup.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "[INFO][2024/03/27 01:44:29 pm] Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 5)_cpv3_mask_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 5)_cpv3_mask_backup.h5...\n",
      "[INFO][2024/03/27 01:45:11 pm] Loading segmentation (150, 6048, 6048)\n",
      "INFO:btrack.io.hdf:Loading segmentation (150, 6048, 6048)\n",
      "[INFO][2024/03/27 01:45:11 pm] Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 5)_cpv3_mask_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 5)_cpv3_mask_backup.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "[INFO][2024/03/27 04:36:25 pm] Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 6)_cpv3_mask_backup.h5...\n",
      "INFO:btrack.io.hdf:Opening HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 6)_cpv3_mask_backup.h5...\n",
      "[INFO][2024/03/27 04:37:16 pm] Loading segmentation (150, 6048, 6048)\n",
      "INFO:btrack.io.hdf:Loading segmentation (150, 6048, 6048)\n",
      "[INFO][2024/03/27 04:37:16 pm] Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 6)_cpv3_mask_backup.h5\n",
      "INFO:btrack.io.hdf:Closing HDF file: /mnt/SYNO/macrohet_syno/ND0002/labels/cpv3/(3, 6)_cpv3_mask_backup.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tracks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n",
      "WARNING: Unrecognized OpenGL version\n",
      "WARNING:vispy:Unrecognized OpenGL version\n"
     ]
    }
   ],
   "source": [
    "for expt_ID in expts_to_review:\n",
    "\n",
    "    base_dir = f'/mnt/SYNO/macrohet_syno/{expt_ID}/'\n",
    "    metadata_fn = os.path.join(base_dir, 'acquisition/Images/Index.idx.xml')\n",
    "    metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "    metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "    assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,)\n",
    "    \n",
    "    for (row, column), info in tqdm(assay_layout.iterrows(), desc='Progress through positions', total=len(assay_layout), leave = False):\n",
    "    \n",
    "        acq_ID = (row, column)\n",
    "    \n",
    "        # process images using zarr\n",
    "        image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "        zarr_store = zarr.open(image_dir, mode='r')\n",
    "        zarr_images = zarr_store.images\n",
    "        \n",
    "        # create a max projection\n",
    "        # %time images = np.max(zarr_images, axis = 2)\n",
    "        # for times sake only load z0\n",
    "        images_z0 = zarr_images[:,:,0,...]\n",
    "        # load objects and segmentation \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_mask_backup.h5'),\n",
    "                                                   'r', \n",
    "                                                   obj_type='obj_type_1'\n",
    "                                                   ) as reader:\n",
    "                            masks = reader.segmentation\n",
    "\n",
    "        if os.path.exists(f'{expt_ID}.{row}.{column}_filtered_napari_tracks.npy'):\n",
    "            print('Loading tracks')\n",
    "            napari_tracks = np.load(f'{expt_ID}.{row}.{column}_filtered_napari_tracks.npy')\n",
    "            \n",
    "        else:\n",
    "            print('Tracking tracks')\n",
    "            with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_objects_backup.h5'),\n",
    "                                                       'r', \n",
    "                                                       obj_type='obj_type_1'\n",
    "                                                       ) as reader:\n",
    "                                objects = reader.objects\n",
    "    \n",
    "            # retrack as fuggin tracks didn't save out\n",
    "            tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "    \n",
    "            # apply length filter for tracks\n",
    "            filtered_tracks = [t for t in tracks if len(t) >= 70]\n",
    "    \n",
    "            # convert to napari format\n",
    "            napari_tracks, _, _ = btrack.utils.tracks_to_napari(filtered_tracks, ndim = 2)\n",
    "            np.save(f'{expt_ID}.{row}.{column}_filtered_napari_tracks.npy', napari_tracks)\n",
    "            np.save(f'{expt_ID}.{row}.{column}_napari_tracks.npy', btrack.utils.tracks_to_napari(tracks, ndim = 2))\n",
    "\n",
    "        # launch  napari viewer\n",
    "        viewer = napari.Viewer(title = f'{expt_ID}, {row, column}')\n",
    "        viewer.add_image(images_z0, channel_axis=1, contrast_limits=[[0,1000], [0, 2000]])\n",
    "        viewer.add_labels(masks)\n",
    "        viewer.add_tracks(napari_tracks, scale = (1/scale_factor, 1/scale_factor))\n",
    "        viewer_tools(viewer)\n",
    "        visualise.add_napari_grid_overlay(viewer)\n",
    "        viewer.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a418b77-e2f5-452c-8f1d-996ed487e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcbcb13-1037-4f24-90b9-8fcc1a526ac7",
   "metadata": {},
   "source": [
    "# Track all pos and save to dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8772f-b0ca-4a1c-a9ad-e3588f706926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# track_dict = {}\n",
    "\n",
    "for expt_ID in expts_to_review:\n",
    "\n",
    "    base_dir = f'/mnt/SYNO/macrohet_syno/{expt_ID}/'\n",
    "    metadata_fn = os.path.join(base_dir, 'acquisition/Images/Index.idx.xml')\n",
    "    metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "    metadata_path = glob.glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "    assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True,)\n",
    "\n",
    "    # track_dict[expt_ID] = {}\n",
    "    \n",
    "    for (row, column), info in tqdm(assay_layout.iterrows(), desc='Progress through positions', total=len(assay_layout), leave = False):\n",
    "\n",
    "        if os.path.exists(f'{expt_ID}.{row}.{column}_filtered_napari_tracks.npy'):\n",
    "            continue\n",
    "        acq_ID = (row, column)\n",
    "    \n",
    "        # process images using zarr\n",
    "        image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "        zarr_store = zarr.open(image_dir, mode='r')\n",
    "        zarr_images = zarr_store.images\n",
    "        \n",
    "        # create a max projection\n",
    "        # %time images = np.max(zarr_images, axis = 2)\n",
    "        # for times sake only load z0\n",
    "        images_z0 = zarr_images[:,:,0,...]\n",
    "\n",
    "        # load objects and segmentation \n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_mask_backup.h5'),\n",
    "                                                   'r', \n",
    "                                                   obj_type='obj_type_1'\n",
    "                                                   ) as reader:\n",
    "                            masks = reader.segmentation\n",
    "        with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_objects_backup.h5'),\n",
    "                                                   'r', \n",
    "                                                   obj_type='obj_type_1'\n",
    "                                                   ) as reader:\n",
    "                            objects = reader.objects\n",
    "\n",
    "        # retrack as fuggin tracks didn't save out\n",
    "        tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "        napari_tracks, _, _ = btrack.utils.tracks_to_napari(tracks, ndim = 2)\n",
    "        np.save(f'{expt_ID}.{row}.{column}_napari_tracks.npy', napari_tracks)\n",
    "\n",
    "        \n",
    "        # # apply length filter for tracks\n",
    "        filtered_tracks = [t for t in tracks if len(t) >= 70]\n",
    "\n",
    "        # # convert to napari format\n",
    "        napari_tracks, _, _ = btrack.utils.tracks_to_napari(filtered_tracks, ndim = 2)\n",
    "        np.save(f'{expt_ID}.{row}.{column}_filtered_napari_tracks.npy', napari_tracks)\n",
    "\n",
    "        # # launch  napari viewer\n",
    "        # viewer = napari.Viewer(title = f'{expt_ID}, {row, column}')\n",
    "        # viewer.add_image(images_z0, channel_axis=1, contrast_limits=[[0,1000], [0, 2000]])\n",
    "        # viewer.add_labels(masks)\n",
    "        # viewer.add_tracks(napari_tracks, scale = (1/scale_factor, 1/scale_factor))\n",
    "        # viewer_tools(viewer)\n",
    "        # visualise.add_napari_grid_overlay(viewer)\n",
    "        # viewer.show(block=True)\n",
    "        # track_dict[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300831e-5768-4c33-a8a2-5d27a48de79b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import zarr\n",
    "import btrack\n",
    "from glob import glob\n",
    "\n",
    "# Assuming dataio, track, config_fn, viewer_tools, visualise, scale_factor are defined elsewhere\n",
    "\n",
    "for expt_ID in expts_to_review:\n",
    "\n",
    "    base_dir = f'/mnt/SYNO/macrohet_syno/{expt_ID}/'\n",
    "    metadata_fn = os.path.join(base_dir, 'acquisition/Images/Index.idx.xml')\n",
    "    metadata = dataio.read_harmony_metadata(metadata_fn)  \n",
    "    metadata_path = glob(os.path.join(base_dir, 'acquisition/Assaylayout/*.xml'))[0]\n",
    "    assay_layout = dataio.read_harmony_metadata(metadata_path, assay_layout=True)\n",
    "\n",
    "    for (row, column), info in tqdm.tqdm(assay_layout.iterrows(), desc='Progress through positions', total=len(assay_layout), leave=False):\n",
    "        try:\n",
    "            if os.path.exists(f'{expt_ID}.{row}.{column}_filtered_napari_tracks.npy'):\n",
    "                continue\n",
    "            acq_ID = (row, column)\n",
    "        \n",
    "            \n",
    "            # Process images using zarr\n",
    "            image_dir = os.path.join(base_dir, f'acquisition/zarr/{acq_ID}.zarr')\n",
    "            zarr_store = zarr.open(image_dir, mode='r')\n",
    "            zarr_images = zarr_store.images  # This is where the AttributeError might occur\n",
    "    \n",
    "            # For times sake only load z0\n",
    "            images_z0 = zarr_images[:,:,0,...]\n",
    "    \n",
    "            \n",
    "            # Continue with processing if no error occurred\n",
    "            # (Your existing code for processing goes here, starting with loading objects and segmentation)\n",
    "             # load objects and segmentation \n",
    "            with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_mask_backup.h5'),\n",
    "                                                       'r', \n",
    "                                                       obj_type='obj_type_1'\n",
    "                                                       ) as reader:\n",
    "                                masks = reader.segmentation\n",
    "            with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/{row, column}_cpv3_objects_backup.h5'),\n",
    "                                                       'r', \n",
    "                                                       obj_type='obj_type_1'\n",
    "                                                       ) as reader:\n",
    "                                objects = reader.objects\n",
    "    \n",
    "            # retrack as fuggin tracks didn't save out\n",
    "            tracks = track(objects, masks, config_fn, search_radius = 20)\n",
    "            napari_tracks, _, _ = btrack.utils.tracks_to_napari(tracks, ndim = 2)\n",
    "            np.save(f'{expt_ID}.{row}.{column}_napari_tracks.npy', napari_tracks)\n",
    "    \n",
    "            \n",
    "            # # apply length filter for tracks\n",
    "            filtered_tracks = [t for t in tracks if len(t) >= 70]\n",
    "    \n",
    "            # # convert to napari format\n",
    "            napari_tracks, _, _ = btrack.utils.tracks_to_napari(filtered_tracks, ndim = 2)\n",
    "            np.save(f'{expt_ID}.{row}.{column}_filtered_napari_tracks.npy', napari_tracks)\n",
    "\n",
    "        except AttributeError as e:\n",
    "                print(f\"Error accessing zarr_images for {expt_ID}, {row}, {column}: {e}\")\n",
    "                continue  # Skip to the next iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc787e-2b9d-45d1-9723-657e6b206562",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari_tracks, _, _ = btrack.utils.tracks_to_napari(tracks, ndim = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ab13c-25f9-4bc5-aaa6-0f4ce471caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari_tracks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c764d-1d0f-4e52-8ae3-f66701791315",
   "metadata": {},
   "source": [
    "### Fixing track IO error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a92264-231c-4e97-a915-567e58cf192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = f'/mnt/SYNO/macrohet_syno/ND0003/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bde0c9-8cc3-40db-9cb9-f29ac5427788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/(6, 12)_cpv3_mask_backup.h5'),\n",
    "                                           'r', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as reader:\n",
    "                    # tracks_loaded = reader.tracks\n",
    "                    masks_loaded = reader.segmentation\n",
    "with btrack.io.HDF5FileHandler(os.path.join(base_dir, f'labels/cpv3/(6, 12)_cpv3_objects_backup.h5'),\n",
    "                                           'r', \n",
    "                                           obj_type='obj_type_1'\n",
    "                                           ) as reader:\n",
    "                    objects_loaded = reader.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f1e648-d52b-4bfb-bfc7-50e573c0c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05587382-1d69-4492-b125-a5bbbab81440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objects_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401a86f-44b0-473d-9c79-19223f66e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = objects_loaded\n",
    "masks = masks_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0274a-1448-4b57-aa8a-30cf22d096ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = track(objects, masks, config_fn, search_radius = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd9d26-650f-433b-9acd-df7b108b3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari_tracks, _, _ = btrack.utils.tracks_to_napari(tracks, ndim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38fb48-5685-4711-87a3-a40227286830",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.io.HDF5FileHandler('test.h5', \n",
    "                               'w', \n",
    "                               obj_type='obj_type_1'\n",
    "                               ) as handler:\n",
    "                    handler.write_tracks(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5c5ff-b511-44b5-a8dd-38b1a360f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a0404-5d64-4535-aac6-1455628508e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = [obj for obj in objects if obj.dummy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d42f68-7318-4ece-b29d-80154da4190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6c4d8-59e4-4db0-92c0-e07d933e3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec17648-dd28-45b5-b71a-76926e9df80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([obj for obj in objects if not obj.dummy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93ce05-b738-40cb-9409-4cc7fd1811e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[0].dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baca8b1-2dcf-4518-8bc9-bcb5c7c0d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.io.HDF5FileHandler('test.h5', \n",
    "                               'r', \n",
    "                               obj_type='obj_type_1'\n",
    "                               ) as reader:\n",
    "                    loaded_tracks = reader.tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2fb783-0aae-40dd-8e6c-32afd7c653d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9463e848-ed33-4eb4-9e76-3cc96e9728dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(title = f'{expt_ID}, {row, column}')\n",
    "\n",
    "viewer.add_image(images_z0, channel_axis=1, contrast_limits=[[0,1000], [0, 2000]])\n",
    "\n",
    "viewer.add_labels(masks_loaded)\n",
    "\n",
    "viewer.add_tracks(napari_tracks, scale = (1/scale_factor, 1/scale_factor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg",
   "language": "python",
   "name": "egg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
